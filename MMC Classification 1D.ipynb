{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ea7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32e9d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 08:45:18.486158: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "'''--------- 1. Data Manipulation ---------'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''--------- 2. Data Preprocessing ---------'''\n",
    "from sklearn.preprocessing import LabelEncoder #Encode Non-numeric Var\n",
    "from sklearn.preprocessing import MinMaxScaler # Feature Scaling\n",
    "from sklearn.model_selection import train_test_split #Train Test Validation Split\n",
    "'''--------- 3. Data Visualization ---------'''\n",
    "import matplotlib.pyplot as plt\n",
    "'''--------- 4. Model Training ---------'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "'''--------- 5. Model Evluation ---------'''\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07327a4a",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "### Dataset 1\n",
    "**About dataset**\n",
    "- 900 ~30 second audio clips gathered from AllMusic API\n",
    "- Annotated into 4 quadrants based on valance and arousal according to Russell's model\n",
    "- Audios are organized in 4 folders (Q1 to Q4)\n",
    "- Equally stratified dataset with each classes 250 songs\n",
    "\n",
    "**Acknowledgements**<br>\n",
    "Source: http://mir.dei.uc.pt/downloads.html\n",
    "\n",
    "**If you use it, please cite the following article(s):**\n",
    "\n",
    "Panda R., Malheiro R. & Paiva R. P. (2018). \"Novel audio features for music emotion recognition\". IEEE Transactions on Affective Computing (IEEE early access). DOI: 10.1109/TAFFC.2018.2820691.\n",
    "\n",
    "Panda R., Malheiro R., Paiva R. P. (2018). \"Musical Texture and Expressivity Features for Music Emotion Recognition\". 19th International Society for Music Information Retrieval Conference -- ISMIR 2018, Paris, France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5fd3ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>scale</th>\n",
       "      <th>key</th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset25/MER25/Q1/MT0009845271.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>C</td>\n",
       "      <td>129.199219</td>\n",
       "      <td>0.122140</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.401058</td>\n",
       "      <td>0.082307</td>\n",
       "      <td>2642.221588</td>\n",
       "      <td>271537.203181</td>\n",
       "      <td>...</td>\n",
       "      <td>62.597446</td>\n",
       "      <td>-5.950494</td>\n",
       "      <td>48.630459</td>\n",
       "      <td>1.334569</td>\n",
       "      <td>50.004402</td>\n",
       "      <td>-5.540088</td>\n",
       "      <td>64.204506</td>\n",
       "      <td>1.117945</td>\n",
       "      <td>66.048088</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset25/MER25/Q1/MT0012742379.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>123.046875</td>\n",
       "      <td>0.083209</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.345329</td>\n",
       "      <td>0.090639</td>\n",
       "      <td>1801.451903</td>\n",
       "      <td>139289.262872</td>\n",
       "      <td>...</td>\n",
       "      <td>94.285316</td>\n",
       "      <td>2.379663</td>\n",
       "      <td>45.529087</td>\n",
       "      <td>-0.897912</td>\n",
       "      <td>63.964500</td>\n",
       "      <td>2.081507</td>\n",
       "      <td>75.064636</td>\n",
       "      <td>-6.191793</td>\n",
       "      <td>77.692085</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset25/MER25/Q1/MT0009188643.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>E</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.153985</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.484920</td>\n",
       "      <td>0.081994</td>\n",
       "      <td>3368.652103</td>\n",
       "      <td>605562.058604</td>\n",
       "      <td>...</td>\n",
       "      <td>41.972660</td>\n",
       "      <td>0.604512</td>\n",
       "      <td>55.172565</td>\n",
       "      <td>5.850554</td>\n",
       "      <td>55.045155</td>\n",
       "      <td>-1.423651</td>\n",
       "      <td>46.238407</td>\n",
       "      <td>3.996233</td>\n",
       "      <td>56.848827</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset25/MER25/Q1/MT0011560587.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>172.265625</td>\n",
       "      <td>0.149997</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.312995</td>\n",
       "      <td>0.086087</td>\n",
       "      <td>1318.592756</td>\n",
       "      <td>189719.701093</td>\n",
       "      <td>...</td>\n",
       "      <td>60.148708</td>\n",
       "      <td>-3.539526</td>\n",
       "      <td>72.778801</td>\n",
       "      <td>-4.562426</td>\n",
       "      <td>86.510620</td>\n",
       "      <td>-4.923912</td>\n",
       "      <td>70.068069</td>\n",
       "      <td>-8.135331</td>\n",
       "      <td>110.109657</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset25/MER25/Q1/MT0001605268.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>E</td>\n",
       "      <td>92.285156</td>\n",
       "      <td>0.124284</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.366223</td>\n",
       "      <td>0.086975</td>\n",
       "      <td>2403.937296</td>\n",
       "      <td>546816.767836</td>\n",
       "      <td>...</td>\n",
       "      <td>50.798794</td>\n",
       "      <td>-11.507196</td>\n",
       "      <td>90.738411</td>\n",
       "      <td>0.821440</td>\n",
       "      <td>52.887070</td>\n",
       "      <td>-6.566545</td>\n",
       "      <td>59.563255</td>\n",
       "      <td>1.389795</td>\n",
       "      <td>53.002163</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Dataset25/MER25/Q3/MT0010804974.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>135.999178</td>\n",
       "      <td>0.153649</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.250131</td>\n",
       "      <td>0.098683</td>\n",
       "      <td>856.545811</td>\n",
       "      <td>118651.564210</td>\n",
       "      <td>...</td>\n",
       "      <td>144.309845</td>\n",
       "      <td>-0.304753</td>\n",
       "      <td>160.793076</td>\n",
       "      <td>2.532327</td>\n",
       "      <td>152.150955</td>\n",
       "      <td>2.110771</td>\n",
       "      <td>163.557083</td>\n",
       "      <td>-2.066999</td>\n",
       "      <td>142.535400</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Dataset25/MER25/Q3/MT0000796526.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>B</td>\n",
       "      <td>161.499023</td>\n",
       "      <td>0.086236</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.089179</td>\n",
       "      <td>2152.750986</td>\n",
       "      <td>730050.006374</td>\n",
       "      <td>...</td>\n",
       "      <td>58.887882</td>\n",
       "      <td>-10.346969</td>\n",
       "      <td>113.920319</td>\n",
       "      <td>1.367891</td>\n",
       "      <td>55.805199</td>\n",
       "      <td>-3.380867</td>\n",
       "      <td>84.275322</td>\n",
       "      <td>-2.286275</td>\n",
       "      <td>78.514404</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>Dataset25/MER25/Q3/MT0015664499.mp3</td>\n",
       "      <td>minor</td>\n",
       "      <td>A#</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.107483</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.376557</td>\n",
       "      <td>0.105393</td>\n",
       "      <td>1836.995316</td>\n",
       "      <td>545339.380176</td>\n",
       "      <td>...</td>\n",
       "      <td>44.633171</td>\n",
       "      <td>2.953913</td>\n",
       "      <td>43.044193</td>\n",
       "      <td>4.850079</td>\n",
       "      <td>42.006420</td>\n",
       "      <td>-2.364613</td>\n",
       "      <td>38.483833</td>\n",
       "      <td>2.754930</td>\n",
       "      <td>31.010529</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Dataset25/MER25/Q3/MT0012292188.mp3</td>\n",
       "      <td>minor</td>\n",
       "      <td>G#</td>\n",
       "      <td>107.666016</td>\n",
       "      <td>0.099635</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.370873</td>\n",
       "      <td>0.102202</td>\n",
       "      <td>853.677506</td>\n",
       "      <td>131473.967491</td>\n",
       "      <td>...</td>\n",
       "      <td>57.660786</td>\n",
       "      <td>1.490195</td>\n",
       "      <td>56.502377</td>\n",
       "      <td>-0.173234</td>\n",
       "      <td>52.937866</td>\n",
       "      <td>-0.707987</td>\n",
       "      <td>52.222660</td>\n",
       "      <td>-2.389481</td>\n",
       "      <td>50.750061</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Dataset25/MER25/Q3/MT0004342301.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>117.453835</td>\n",
       "      <td>0.145235</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.298197</td>\n",
       "      <td>0.090131</td>\n",
       "      <td>1561.606293</td>\n",
       "      <td>386055.207888</td>\n",
       "      <td>...</td>\n",
       "      <td>111.426071</td>\n",
       "      <td>9.588392</td>\n",
       "      <td>53.757309</td>\n",
       "      <td>-1.011325</td>\n",
       "      <td>79.747833</td>\n",
       "      <td>10.141459</td>\n",
       "      <td>65.912148</td>\n",
       "      <td>-2.369084</td>\n",
       "      <td>65.630173</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>898 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file  scale key       tempo  rms_mean  \\\n",
       "0    Dataset25/MER25/Q1/MT0009845271.mp3  major   C  129.199219  0.122140   \n",
       "1    Dataset25/MER25/Q1/MT0012742379.mp3  major   A  123.046875  0.083209   \n",
       "2    Dataset25/MER25/Q1/MT0009188643.mp3  major   E   99.384014  0.153985   \n",
       "3    Dataset25/MER25/Q1/MT0011560587.mp3  major   A  172.265625  0.149997   \n",
       "4    Dataset25/MER25/Q1/MT0001605268.mp3  major   E   92.285156  0.124284   \n",
       "..                                   ...    ...  ..         ...       ...   \n",
       "893  Dataset25/MER25/Q3/MT0010804974.mp3  major   A  135.999178  0.153649   \n",
       "894  Dataset25/MER25/Q3/MT0000796526.mp3  major   B  161.499023  0.086236   \n",
       "895  Dataset25/MER25/Q3/MT0015664499.mp3  minor  A#   99.384014  0.107483   \n",
       "896  Dataset25/MER25/Q3/MT0012292188.mp3  minor  G#  107.666016  0.099635   \n",
       "897  Dataset25/MER25/Q3/MT0004342301.mp3  major   G  117.453835  0.145235   \n",
       "\n",
       "      rms_var  chroma_mean  chroma_var  centroid_mean   centroid_var  ...  \\\n",
       "0    0.001837     0.401058    0.082307    2642.221588  271537.203181  ...   \n",
       "1    0.003111     0.345329    0.090639    1801.451903  139289.262872  ...   \n",
       "2    0.001419     0.484920    0.081994    3368.652103  605562.058604  ...   \n",
       "3    0.002240     0.312995    0.086087    1318.592756  189719.701093  ...   \n",
       "4    0.001862     0.366223    0.086975    2403.937296  546816.767836  ...   \n",
       "..        ...          ...         ...            ...            ...  ...   \n",
       "893  0.003739     0.250131    0.098683     856.545811  118651.564210  ...   \n",
       "894  0.002395     0.322800    0.089179    2152.750986  730050.006374  ...   \n",
       "895  0.002811     0.376557    0.105393    1836.995316  545339.380176  ...   \n",
       "896  0.001647     0.370873    0.102202     853.677506  131473.967491  ...   \n",
       "897  0.005659     0.298197    0.090131    1561.606293  386055.207888  ...   \n",
       "\n",
       "     mfcc_var_16  mfcc_mean_17  mfcc_var_17  mfcc_mean_18  mfcc_var_18  \\\n",
       "0      62.597446     -5.950494    48.630459      1.334569    50.004402   \n",
       "1      94.285316      2.379663    45.529087     -0.897912    63.964500   \n",
       "2      41.972660      0.604512    55.172565      5.850554    55.045155   \n",
       "3      60.148708     -3.539526    72.778801     -4.562426    86.510620   \n",
       "4      50.798794    -11.507196    90.738411      0.821440    52.887070   \n",
       "..           ...           ...          ...           ...          ...   \n",
       "893   144.309845     -0.304753   160.793076      2.532327   152.150955   \n",
       "894    58.887882    -10.346969   113.920319      1.367891    55.805199   \n",
       "895    44.633171      2.953913    43.044193      4.850079    42.006420   \n",
       "896    57.660786      1.490195    56.502377     -0.173234    52.937866   \n",
       "897   111.426071      9.588392    53.757309     -1.011325    79.747833   \n",
       "\n",
       "     mfcc_mean_19  mfcc_var_19  mfcc_mean_20  mfcc_var_20   mood  \n",
       "0       -5.540088    64.204506      1.117945    66.048088  happy  \n",
       "1        2.081507    75.064636     -6.191793    77.692085  happy  \n",
       "2       -1.423651    46.238407      3.996233    56.848827  happy  \n",
       "3       -4.923912    70.068069     -8.135331   110.109657  happy  \n",
       "4       -6.566545    59.563255      1.389795    53.002163  happy  \n",
       "..            ...          ...           ...          ...    ...  \n",
       "893      2.110771   163.557083     -2.066999   142.535400    sad  \n",
       "894     -3.380867    84.275322     -2.286275    78.514404    sad  \n",
       "895     -2.364613    38.483833      2.754930    31.010529    sad  \n",
       "896     -0.707987    52.222660     -2.389481    50.750061    sad  \n",
       "897     10.141459    65.912148     -2.369084    65.630173    sad  \n",
       "\n",
       "[898 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset1\n",
    "df1 = pd.read_excel(\"Features1D/Features/Features.xlsx\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c88b98b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 898 entries, 0 to 897\n",
      "Data columns (total 59 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   file           898 non-null    object \n",
      " 1   scale          898 non-null    object \n",
      " 2   key            898 non-null    object \n",
      " 3   tempo          898 non-null    float64\n",
      " 4   rms_mean       898 non-null    float64\n",
      " 5   rms_var        898 non-null    float64\n",
      " 6   chroma_mean    898 non-null    float64\n",
      " 7   chroma_var     898 non-null    float64\n",
      " 8   centroid_mean  898 non-null    float64\n",
      " 9   centroid_var   898 non-null    float64\n",
      " 10  rolloff_mean   898 non-null    float64\n",
      " 11  roll_off_var   898 non-null    float64\n",
      " 12  zcr_mean       898 non-null    float64\n",
      " 13  zcr_var        898 non-null    float64\n",
      " 14  tonnetz_mean   898 non-null    float64\n",
      " 15  tonnetz_var    898 non-null    float64\n",
      " 16  mel_mean       898 non-null    float64\n",
      " 17  mel_var        898 non-null    float64\n",
      " 18  mfcc_mean_1    898 non-null    float64\n",
      " 19  mfcc_var_1     898 non-null    float64\n",
      " 20  mfcc_mean_2    898 non-null    float64\n",
      " 21  mfcc_var_2     898 non-null    float64\n",
      " 22  mfcc_mean_3    898 non-null    float64\n",
      " 23  mfcc_var_3     898 non-null    float64\n",
      " 24  mfcc_mean_4    898 non-null    float64\n",
      " 25  mfcc_var_4     898 non-null    float64\n",
      " 26  mfcc_mean_5    898 non-null    float64\n",
      " 27  mfcc_var_5     898 non-null    float64\n",
      " 28  mfcc_mean_6    898 non-null    float64\n",
      " 29  mfcc_var_6     898 non-null    float64\n",
      " 30  mfcc_mean_7    898 non-null    float64\n",
      " 31  mfcc_var_7     898 non-null    float64\n",
      " 32  mfcc_mean_8    898 non-null    float64\n",
      " 33  mfcc_var_8     898 non-null    float64\n",
      " 34  mfcc_mean_9    898 non-null    float64\n",
      " 35  mfcc_var_9     898 non-null    float64\n",
      " 36  mfcc_mean_10   898 non-null    float64\n",
      " 37  mfcc_var_10    898 non-null    float64\n",
      " 38  mfcc_mean_11   898 non-null    float64\n",
      " 39  mfcc_var_11    898 non-null    float64\n",
      " 40  mfcc_mean_12   898 non-null    float64\n",
      " 41  mfcc_var_12    898 non-null    float64\n",
      " 42  mfcc_mean_13   898 non-null    float64\n",
      " 43  mfcc_var_13    898 non-null    float64\n",
      " 44  mfcc_mean_14   898 non-null    float64\n",
      " 45  mfcc_var_14    898 non-null    float64\n",
      " 46  mfcc_mean_15   898 non-null    float64\n",
      " 47  mfcc_var_15    898 non-null    float64\n",
      " 48  mfcc_mean_16   898 non-null    float64\n",
      " 49  mfcc_var_16    898 non-null    float64\n",
      " 50  mfcc_mean_17   898 non-null    float64\n",
      " 51  mfcc_var_17    898 non-null    float64\n",
      " 52  mfcc_mean_18   898 non-null    float64\n",
      " 53  mfcc_var_18    898 non-null    float64\n",
      " 54  mfcc_mean_19   898 non-null    float64\n",
      " 55  mfcc_var_19    898 non-null    float64\n",
      " 56  mfcc_mean_20   898 non-null    float64\n",
      " 57  mfcc_var_20    898 non-null    float64\n",
      " 58  mood           898 non-null    object \n",
      "dtypes: float64(55), object(4)\n",
      "memory usage: 414.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a41ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>roll_off_var</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean_16</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>8.980000e+02</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>8.980000e+02</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>122.192119</td>\n",
       "      <td>0.140620</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.376747</td>\n",
       "      <td>0.085305</td>\n",
       "      <td>2059.988511</td>\n",
       "      <td>3.909208e+05</td>\n",
       "      <td>4187.814830</td>\n",
       "      <td>1.675962e+06</td>\n",
       "      <td>0.100632</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.790507</td>\n",
       "      <td>64.153565</td>\n",
       "      <td>-2.054695</td>\n",
       "      <td>65.153429</td>\n",
       "      <td>-2.161143</td>\n",
       "      <td>66.155017</td>\n",
       "      <td>-1.077997</td>\n",
       "      <td>68.366924</td>\n",
       "      <td>-2.015693</td>\n",
       "      <td>72.219889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.708462</td>\n",
       "      <td>0.067875</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.093622</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>685.458229</td>\n",
       "      <td>3.273618e+05</td>\n",
       "      <td>1522.875967</td>\n",
       "      <td>1.314115e+06</td>\n",
       "      <td>0.042594</td>\n",
       "      <td>...</td>\n",
       "      <td>5.714870</td>\n",
       "      <td>33.982765</td>\n",
       "      <td>5.854216</td>\n",
       "      <td>37.509313</td>\n",
       "      <td>5.396882</td>\n",
       "      <td>39.399692</td>\n",
       "      <td>5.390178</td>\n",
       "      <td>42.152986</td>\n",
       "      <td>4.876502</td>\n",
       "      <td>47.802374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>75.999540</td>\n",
       "      <td>0.015824</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.131688</td>\n",
       "      <td>0.041983</td>\n",
       "      <td>387.401161</td>\n",
       "      <td>4.007574e+03</td>\n",
       "      <td>523.105966</td>\n",
       "      <td>1.089884e+04</td>\n",
       "      <td>0.019527</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.835148</td>\n",
       "      <td>16.496901</td>\n",
       "      <td>-16.260069</td>\n",
       "      <td>16.212341</td>\n",
       "      <td>-20.297907</td>\n",
       "      <td>15.476705</td>\n",
       "      <td>-17.380840</td>\n",
       "      <td>17.147591</td>\n",
       "      <td>-17.055731</td>\n",
       "      <td>14.376126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>107.666016</td>\n",
       "      <td>0.090460</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.309014</td>\n",
       "      <td>0.081920</td>\n",
       "      <td>1523.621647</td>\n",
       "      <td>1.572228e+05</td>\n",
       "      <td>3064.712155</td>\n",
       "      <td>6.972916e+05</td>\n",
       "      <td>0.066929</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.492516</td>\n",
       "      <td>42.567407</td>\n",
       "      <td>-6.142178</td>\n",
       "      <td>42.141800</td>\n",
       "      <td>-5.623221</td>\n",
       "      <td>41.091060</td>\n",
       "      <td>-4.471170</td>\n",
       "      <td>43.613956</td>\n",
       "      <td>-4.983186</td>\n",
       "      <td>42.542788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>123.046875</td>\n",
       "      <td>0.128408</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.362656</td>\n",
       "      <td>0.087398</td>\n",
       "      <td>2078.002781</td>\n",
       "      <td>2.988196e+05</td>\n",
       "      <td>4289.452270</td>\n",
       "      <td>1.360052e+06</td>\n",
       "      <td>0.095536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.872392</td>\n",
       "      <td>57.365828</td>\n",
       "      <td>-3.344803</td>\n",
       "      <td>55.556923</td>\n",
       "      <td>-1.133976</td>\n",
       "      <td>57.262060</td>\n",
       "      <td>-2.023335</td>\n",
       "      <td>58.444538</td>\n",
       "      <td>-1.465007</td>\n",
       "      <td>59.946037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>135.999178</td>\n",
       "      <td>0.184625</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.437746</td>\n",
       "      <td>0.091539</td>\n",
       "      <td>2546.979116</td>\n",
       "      <td>5.314662e+05</td>\n",
       "      <td>5360.334807</td>\n",
       "      <td>2.263938e+06</td>\n",
       "      <td>0.128580</td>\n",
       "      <td>...</td>\n",
       "      <td>2.426354</td>\n",
       "      <td>77.580990</td>\n",
       "      <td>1.334129</td>\n",
       "      <td>77.358486</td>\n",
       "      <td>1.951706</td>\n",
       "      <td>78.075478</td>\n",
       "      <td>1.448640</td>\n",
       "      <td>83.002417</td>\n",
       "      <td>1.369652</td>\n",
       "      <td>86.225466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>198.768029</td>\n",
       "      <td>0.395023</td>\n",
       "      <td>0.023626</td>\n",
       "      <td>0.656680</td>\n",
       "      <td>0.111998</td>\n",
       "      <td>3703.229757</td>\n",
       "      <td>2.775075e+06</td>\n",
       "      <td>7815.641639</td>\n",
       "      <td>8.834975e+06</td>\n",
       "      <td>0.254733</td>\n",
       "      <td>...</td>\n",
       "      <td>16.275961</td>\n",
       "      <td>435.665466</td>\n",
       "      <td>15.933263</td>\n",
       "      <td>514.815186</td>\n",
       "      <td>12.374401</td>\n",
       "      <td>444.994934</td>\n",
       "      <td>16.365273</td>\n",
       "      <td>588.261475</td>\n",
       "      <td>15.270178</td>\n",
       "      <td>551.592407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tempo    rms_mean     rms_var  chroma_mean  chroma_var  \\\n",
       "count  898.000000  898.000000  898.000000   898.000000  898.000000   \n",
       "mean   122.192119    0.140620    0.003567     0.376747    0.085305   \n",
       "std     20.708462    0.067875    0.003130     0.093622    0.010212   \n",
       "min     75.999540    0.015824    0.000055     0.131688    0.041983   \n",
       "25%    107.666016    0.090460    0.001534     0.309014    0.081920   \n",
       "50%    123.046875    0.128408    0.002628     0.362656    0.087398   \n",
       "75%    135.999178    0.184625    0.004582     0.437746    0.091539   \n",
       "max    198.768029    0.395023    0.023626     0.656680    0.111998   \n",
       "\n",
       "       centroid_mean  centroid_var  rolloff_mean  roll_off_var    zcr_mean  \\\n",
       "count     898.000000  8.980000e+02    898.000000  8.980000e+02  898.000000   \n",
       "mean     2059.988511  3.909208e+05   4187.814830  1.675962e+06    0.100632   \n",
       "std       685.458229  3.273618e+05   1522.875967  1.314115e+06    0.042594   \n",
       "min       387.401161  4.007574e+03    523.105966  1.089884e+04    0.019527   \n",
       "25%      1523.621647  1.572228e+05   3064.712155  6.972916e+05    0.066929   \n",
       "50%      2078.002781  2.988196e+05   4289.452270  1.360052e+06    0.095536   \n",
       "75%      2546.979116  5.314662e+05   5360.334807  2.263938e+06    0.128580   \n",
       "max      3703.229757  2.775075e+06   7815.641639  8.834975e+06    0.254733   \n",
       "\n",
       "       ...  mfcc_mean_16  mfcc_var_16  mfcc_mean_17  mfcc_var_17  \\\n",
       "count  ...    898.000000   898.000000    898.000000   898.000000   \n",
       "mean   ...     -1.790507    64.153565     -2.054695    65.153429   \n",
       "std    ...      5.714870    33.982765      5.854216    37.509313   \n",
       "min    ...    -23.835148    16.496901    -16.260069    16.212341   \n",
       "25%    ...     -5.492516    42.567407     -6.142178    42.141800   \n",
       "50%    ...     -0.872392    57.365828     -3.344803    55.556923   \n",
       "75%    ...      2.426354    77.580990      1.334129    77.358486   \n",
       "max    ...     16.275961   435.665466     15.933263   514.815186   \n",
       "\n",
       "       mfcc_mean_18  mfcc_var_18  mfcc_mean_19  mfcc_var_19  mfcc_mean_20  \\\n",
       "count    898.000000   898.000000    898.000000   898.000000    898.000000   \n",
       "mean      -2.161143    66.155017     -1.077997    68.366924     -2.015693   \n",
       "std        5.396882    39.399692      5.390178    42.152986      4.876502   \n",
       "min      -20.297907    15.476705    -17.380840    17.147591    -17.055731   \n",
       "25%       -5.623221    41.091060     -4.471170    43.613956     -4.983186   \n",
       "50%       -1.133976    57.262060     -2.023335    58.444538     -1.465007   \n",
       "75%        1.951706    78.075478      1.448640    83.002417      1.369652   \n",
       "max       12.374401   444.994934     16.365273   588.261475     15.270178   \n",
       "\n",
       "       mfcc_var_20  \n",
       "count   898.000000  \n",
       "mean     72.219889  \n",
       "std      47.802374  \n",
       "min      14.376126  \n",
       "25%      42.542788  \n",
       "50%      59.946037  \n",
       "75%      86.225466  \n",
       "max     551.592407  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fce297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>roll_off_var</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean_16</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mood</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>120.608432</td>\n",
       "      <td>0.195935</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.485090</td>\n",
       "      <td>0.075074</td>\n",
       "      <td>2584.532564</td>\n",
       "      <td>344406.472181</td>\n",
       "      <td>5237.362224</td>\n",
       "      <td>1.264628e+06</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.930292</td>\n",
       "      <td>44.363887</td>\n",
       "      <td>-1.284212</td>\n",
       "      <td>44.808423</td>\n",
       "      <td>-1.977401</td>\n",
       "      <td>46.113114</td>\n",
       "      <td>0.421466</td>\n",
       "      <td>48.109930</td>\n",
       "      <td>-1.777066</td>\n",
       "      <td>48.157392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>123.450826</td>\n",
       "      <td>0.149859</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.381774</td>\n",
       "      <td>0.086511</td>\n",
       "      <td>2316.987041</td>\n",
       "      <td>412191.587768</td>\n",
       "      <td>4803.631991</td>\n",
       "      <td>1.607647e+06</td>\n",
       "      <td>0.114884</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.783055</td>\n",
       "      <td>60.065572</td>\n",
       "      <td>-1.757794</td>\n",
       "      <td>60.666303</td>\n",
       "      <td>-1.741446</td>\n",
       "      <td>62.121580</td>\n",
       "      <td>-1.139971</td>\n",
       "      <td>67.214375</td>\n",
       "      <td>-1.887622</td>\n",
       "      <td>69.893941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relaxed</th>\n",
       "      <td>122.453003</td>\n",
       "      <td>0.107175</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.318259</td>\n",
       "      <td>0.089239</td>\n",
       "      <td>1663.728268</td>\n",
       "      <td>419919.822595</td>\n",
       "      <td>3368.101718</td>\n",
       "      <td>2.066409e+06</td>\n",
       "      <td>0.074023</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.632271</td>\n",
       "      <td>80.336390</td>\n",
       "      <td>-2.060138</td>\n",
       "      <td>82.309746</td>\n",
       "      <td>-1.813682</td>\n",
       "      <td>86.293389</td>\n",
       "      <td>-1.424376</td>\n",
       "      <td>85.156412</td>\n",
       "      <td>-1.918423</td>\n",
       "      <td>91.165267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>122.267405</td>\n",
       "      <td>0.109595</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.321909</td>\n",
       "      <td>0.090405</td>\n",
       "      <td>1676.990600</td>\n",
       "      <td>387354.481163</td>\n",
       "      <td>3347.637316</td>\n",
       "      <td>1.764555e+06</td>\n",
       "      <td>0.077147</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.816344</td>\n",
       "      <td>71.812074</td>\n",
       "      <td>-3.113996</td>\n",
       "      <td>72.789358</td>\n",
       "      <td>-3.108311</td>\n",
       "      <td>70.056133</td>\n",
       "      <td>-2.169657</td>\n",
       "      <td>72.976734</td>\n",
       "      <td>-2.478521</td>\n",
       "      <td>79.642282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tempo  rms_mean   rms_var  chroma_mean  chroma_var  \\\n",
       "mood                                                               \n",
       "angry    120.608432  0.195935  0.004543     0.485090    0.075074   \n",
       "happy    123.450826  0.149859  0.003879     0.381774    0.086511   \n",
       "relaxed  122.453003  0.107175  0.002817     0.318259    0.089239   \n",
       "sad      122.267405  0.109595  0.003033     0.321909    0.090405   \n",
       "\n",
       "         centroid_mean   centroid_var  rolloff_mean  roll_off_var  zcr_mean  \\\n",
       "mood                                                                          \n",
       "angry      2584.532564  344406.472181   5237.362224  1.264628e+06  0.136600   \n",
       "happy      2316.987041  412191.587768   4803.631991  1.607647e+06  0.114884   \n",
       "relaxed    1663.728268  419919.822595   3368.101718  2.066409e+06  0.074023   \n",
       "sad        1676.990600  387354.481163   3347.637316  1.764555e+06  0.077147   \n",
       "\n",
       "         ...  mfcc_mean_16  mfcc_var_16  mfcc_mean_17  mfcc_var_17  \\\n",
       "mood     ...                                                         \n",
       "angry    ...     -0.930292    44.363887     -1.284212    44.808423   \n",
       "happy    ...     -1.783055    60.065572     -1.757794    60.666303   \n",
       "relaxed  ...     -1.632271    80.336390     -2.060138    82.309746   \n",
       "sad      ...     -2.816344    71.812074     -3.113996    72.789358   \n",
       "\n",
       "         mfcc_mean_18  mfcc_var_18  mfcc_mean_19  mfcc_var_19  mfcc_mean_20  \\\n",
       "mood                                                                          \n",
       "angry       -1.977401    46.113114      0.421466    48.109930     -1.777066   \n",
       "happy       -1.741446    62.121580     -1.139971    67.214375     -1.887622   \n",
       "relaxed     -1.813682    86.293389     -1.424376    85.156412     -1.918423   \n",
       "sad         -3.108311    70.056133     -2.169657    72.976734     -2.478521   \n",
       "\n",
       "         mfcc_var_20  \n",
       "mood                  \n",
       "angry      48.157392  \n",
       "happy      69.893941  \n",
       "relaxed    91.165267  \n",
       "sad        79.642282  \n",
       "\n",
       "[4 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby('mood').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e803fa86",
   "metadata": {},
   "source": [
    "### Dataset 2\n",
    "**About dataset**\n",
    "- 400 ~30 second audio clips gathered from erbal and non-verbal music from different genres of Turkish music\n",
    "- Annotated into 4 quadrants based on valance and arousal according to Russell's model.\n",
    "- Audios are organized in 4 categories - Happy, Sad, Angry, Relax\n",
    "- Equally stratified dataset with each classes 100 songs\n",
    "\n",
    "**Acknowledgements**<br>\n",
    "source:https://www.kaggle.com/datasets/blaler/turkish-music-emotion-dataset\n",
    "\n",
    "**If you use it, please cite the following article(s):**<br>\n",
    "Bilal Er, M., & Aydilek, I. B. (2019). Music emotion recognition by using chroma spectrogram and deep visual features. Journal of Computational Intelligent Systems, 12(2), 1622–1634. International Journal of Computational Intelligence Systems, DOI: [Web Link] https://doi.org/10.2991/ijcis.d.191216.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "926d715e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>scale</th>\n",
       "      <th>key</th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset25/MER_Extra25/happy/ovalar_gurup_yol.mp3</td>\n",
       "      <td>minor</td>\n",
       "      <td>C#</td>\n",
       "      <td>107.666016</td>\n",
       "      <td>0.203715</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.355963</td>\n",
       "      <td>0.087506</td>\n",
       "      <td>2257.202789</td>\n",
       "      <td>3.633545e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>39.745495</td>\n",
       "      <td>-5.036633</td>\n",
       "      <td>51.429291</td>\n",
       "      <td>-3.394783</td>\n",
       "      <td>50.277916</td>\n",
       "      <td>-5.994911</td>\n",
       "      <td>51.078880</td>\n",
       "      <td>-2.758130</td>\n",
       "      <td>67.629799</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset25/MER_Extra25/happy/cekirge_oguz_yilma...</td>\n",
       "      <td>major</td>\n",
       "      <td>D</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.134899</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>0.337127</td>\n",
       "      <td>0.094463</td>\n",
       "      <td>1963.637200</td>\n",
       "      <td>2.299410e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>53.625290</td>\n",
       "      <td>-10.358211</td>\n",
       "      <td>58.315762</td>\n",
       "      <td>-0.972885</td>\n",
       "      <td>80.311607</td>\n",
       "      <td>-4.383526</td>\n",
       "      <td>114.317406</td>\n",
       "      <td>6.196268</td>\n",
       "      <td>106.006302</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset25/MER_Extra25/happy/baran_bayraktar_go...</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>117.453835</td>\n",
       "      <td>0.202237</td>\n",
       "      <td>0.013383</td>\n",
       "      <td>0.377444</td>\n",
       "      <td>0.090938</td>\n",
       "      <td>2558.051976</td>\n",
       "      <td>1.368935e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>51.113770</td>\n",
       "      <td>-2.307574</td>\n",
       "      <td>66.429535</td>\n",
       "      <td>0.962885</td>\n",
       "      <td>38.927681</td>\n",
       "      <td>-3.003113</td>\n",
       "      <td>57.289982</td>\n",
       "      <td>1.009082</td>\n",
       "      <td>73.439346</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset25/MER_Extra25/happy/bu_gece_uyumamisan...</td>\n",
       "      <td>major</td>\n",
       "      <td>F</td>\n",
       "      <td>129.199219</td>\n",
       "      <td>0.077799</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.482537</td>\n",
       "      <td>0.070852</td>\n",
       "      <td>3172.962069</td>\n",
       "      <td>2.144511e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>33.953434</td>\n",
       "      <td>-12.987661</td>\n",
       "      <td>43.694424</td>\n",
       "      <td>3.631064</td>\n",
       "      <td>29.647392</td>\n",
       "      <td>-10.251694</td>\n",
       "      <td>40.205898</td>\n",
       "      <td>-4.413622</td>\n",
       "      <td>40.858986</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset25/MER_Extra25/happy/kim_arar_nilufer.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>F</td>\n",
       "      <td>129.199219</td>\n",
       "      <td>0.134208</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.376593</td>\n",
       "      <td>0.075194</td>\n",
       "      <td>2966.197823</td>\n",
       "      <td>2.636523e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>43.511322</td>\n",
       "      <td>-2.495036</td>\n",
       "      <td>33.745182</td>\n",
       "      <td>0.276652</td>\n",
       "      <td>27.181576</td>\n",
       "      <td>-0.029217</td>\n",
       "      <td>34.924503</td>\n",
       "      <td>3.552903</td>\n",
       "      <td>46.541862</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Dataset25/MER_Extra25/relaxed/sumru_agir_yuruy...</td>\n",
       "      <td>major</td>\n",
       "      <td>D</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>0.142323</td>\n",
       "      <td>0.004840</td>\n",
       "      <td>0.339998</td>\n",
       "      <td>0.095134</td>\n",
       "      <td>1123.696387</td>\n",
       "      <td>5.788810e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>38.897163</td>\n",
       "      <td>8.553452</td>\n",
       "      <td>82.796318</td>\n",
       "      <td>8.461837</td>\n",
       "      <td>67.124542</td>\n",
       "      <td>1.787519</td>\n",
       "      <td>73.779991</td>\n",
       "      <td>-0.676014</td>\n",
       "      <td>55.244400</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Dataset25/MER_Extra25/relaxed/onur_mete_bu_ask...</td>\n",
       "      <td>major</td>\n",
       "      <td>B</td>\n",
       "      <td>135.999178</td>\n",
       "      <td>0.152394</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.326165</td>\n",
       "      <td>0.084352</td>\n",
       "      <td>2107.054510</td>\n",
       "      <td>6.873373e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>42.552208</td>\n",
       "      <td>-2.485002</td>\n",
       "      <td>40.545063</td>\n",
       "      <td>3.581853</td>\n",
       "      <td>51.561790</td>\n",
       "      <td>-2.310211</td>\n",
       "      <td>46.843857</td>\n",
       "      <td>-4.614769</td>\n",
       "      <td>53.502258</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Dataset25/MER_Extra25/relaxed/demir_demircan_a...</td>\n",
       "      <td>major</td>\n",
       "      <td>D</td>\n",
       "      <td>129.199219</td>\n",
       "      <td>0.161983</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.300543</td>\n",
       "      <td>0.089547</td>\n",
       "      <td>1408.713888</td>\n",
       "      <td>5.549858e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>61.977123</td>\n",
       "      <td>-6.842248</td>\n",
       "      <td>49.472839</td>\n",
       "      <td>-4.599386</td>\n",
       "      <td>79.167732</td>\n",
       "      <td>-6.601953</td>\n",
       "      <td>53.350906</td>\n",
       "      <td>-1.959686</td>\n",
       "      <td>81.524139</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Dataset25/MER_Extra25/relaxed/yalin_ki_sen.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>86.132812</td>\n",
       "      <td>0.182141</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.302875</td>\n",
       "      <td>0.094239</td>\n",
       "      <td>1568.452968</td>\n",
       "      <td>1.262180e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>68.513573</td>\n",
       "      <td>-2.284982</td>\n",
       "      <td>64.041695</td>\n",
       "      <td>-6.485914</td>\n",
       "      <td>52.975601</td>\n",
       "      <td>-11.130312</td>\n",
       "      <td>54.331902</td>\n",
       "      <td>-3.631683</td>\n",
       "      <td>62.101868</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Dataset25/MER_Extra25/relaxed/sarp_madem_ortad...</td>\n",
       "      <td>minor</td>\n",
       "      <td>G#</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.078060</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>375.472632</td>\n",
       "      <td>1.150694e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>61.291878</td>\n",
       "      <td>-9.897033</td>\n",
       "      <td>66.397682</td>\n",
       "      <td>-6.967515</td>\n",
       "      <td>64.210945</td>\n",
       "      <td>-5.476778</td>\n",
       "      <td>66.888565</td>\n",
       "      <td>-8.320798</td>\n",
       "      <td>102.913956</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  scale key       tempo  \\\n",
       "0     Dataset25/MER_Extra25/happy/ovalar_gurup_yol.mp3  minor  C#  107.666016   \n",
       "1    Dataset25/MER_Extra25/happy/cekirge_oguz_yilma...  major   D   99.384014   \n",
       "2    Dataset25/MER_Extra25/happy/baran_bayraktar_go...  major   G  117.453835   \n",
       "3    Dataset25/MER_Extra25/happy/bu_gece_uyumamisan...  major   F  129.199219   \n",
       "4     Dataset25/MER_Extra25/happy/kim_arar_nilufer.mp3  major   F  129.199219   \n",
       "..                                                 ...    ...  ..         ...   \n",
       "395  Dataset25/MER_Extra25/relaxed/sumru_agir_yuruy...  major   D  112.347147   \n",
       "396  Dataset25/MER_Extra25/relaxed/onur_mete_bu_ask...  major   B  135.999178   \n",
       "397  Dataset25/MER_Extra25/relaxed/demir_demircan_a...  major   D  129.199219   \n",
       "398     Dataset25/MER_Extra25/relaxed/yalin_ki_sen.mp3  major   A   86.132812   \n",
       "399  Dataset25/MER_Extra25/relaxed/sarp_madem_ortad...  minor  G#   99.384014   \n",
       "\n",
       "     rms_mean   rms_var  chroma_mean  chroma_var  centroid_mean  centroid_var  \\\n",
       "0    0.203715  0.004113     0.355963    0.087506    2257.202789  3.633545e+05   \n",
       "1    0.134899  0.006532     0.337127    0.094463    1963.637200  2.299410e+05   \n",
       "2    0.202237  0.013383     0.377444    0.090938    2558.051976  1.368935e+06   \n",
       "3    0.077799  0.000701     0.482537    0.070852    3172.962069  2.144511e+05   \n",
       "4    0.134208  0.000974     0.376593    0.075194    2966.197823  2.636523e+05   \n",
       "..        ...       ...          ...         ...            ...           ...   \n",
       "395  0.142323  0.004840     0.339998    0.095134    1123.696387  5.788810e+05   \n",
       "396  0.152394  0.003350     0.326165    0.084352    2107.054510  6.873373e+05   \n",
       "397  0.161983  0.002465     0.300543    0.089547    1408.713888  5.549858e+05   \n",
       "398  0.182141  0.003011     0.302875    0.094239    1568.452968  1.262180e+06   \n",
       "399  0.078060  0.000220     0.344734    0.084124     375.472632  1.150694e+04   \n",
       "\n",
       "     ...  mfcc_var_16  mfcc_mean_17  mfcc_var_17  mfcc_mean_18  mfcc_var_18  \\\n",
       "0    ...    39.745495     -5.036633    51.429291     -3.394783    50.277916   \n",
       "1    ...    53.625290    -10.358211    58.315762     -0.972885    80.311607   \n",
       "2    ...    51.113770     -2.307574    66.429535      0.962885    38.927681   \n",
       "3    ...    33.953434    -12.987661    43.694424      3.631064    29.647392   \n",
       "4    ...    43.511322     -2.495036    33.745182      0.276652    27.181576   \n",
       "..   ...          ...           ...          ...           ...          ...   \n",
       "395  ...    38.897163      8.553452    82.796318      8.461837    67.124542   \n",
       "396  ...    42.552208     -2.485002    40.545063      3.581853    51.561790   \n",
       "397  ...    61.977123     -6.842248    49.472839     -4.599386    79.167732   \n",
       "398  ...    68.513573     -2.284982    64.041695     -6.485914    52.975601   \n",
       "399  ...    61.291878     -9.897033    66.397682     -6.967515    64.210945   \n",
       "\n",
       "     mfcc_mean_19  mfcc_var_19  mfcc_mean_20  mfcc_var_20     mood  \n",
       "0       -5.994911    51.078880     -2.758130    67.629799    happy  \n",
       "1       -4.383526   114.317406      6.196268   106.006302    happy  \n",
       "2       -3.003113    57.289982      1.009082    73.439346    happy  \n",
       "3      -10.251694    40.205898     -4.413622    40.858986    happy  \n",
       "4       -0.029217    34.924503      3.552903    46.541862    happy  \n",
       "..            ...          ...           ...          ...      ...  \n",
       "395      1.787519    73.779991     -0.676014    55.244400  relaxed  \n",
       "396     -2.310211    46.843857     -4.614769    53.502258  relaxed  \n",
       "397     -6.601953    53.350906     -1.959686    81.524139  relaxed  \n",
       "398    -11.130312    54.331902     -3.631683    62.101868  relaxed  \n",
       "399     -5.476778    66.888565     -8.320798   102.913956  relaxed  \n",
       "\n",
       "[400 rows x 59 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset2\n",
    "df2 = pd.read_excel(\"Features1D/Features/Features_extra.xlsx\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a463b2c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 59 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   file           400 non-null    object \n",
      " 1   scale          400 non-null    object \n",
      " 2   key            400 non-null    object \n",
      " 3   tempo          400 non-null    float64\n",
      " 4   rms_mean       400 non-null    float64\n",
      " 5   rms_var        400 non-null    float64\n",
      " 6   chroma_mean    400 non-null    float64\n",
      " 7   chroma_var     400 non-null    float64\n",
      " 8   centroid_mean  400 non-null    float64\n",
      " 9   centroid_var   400 non-null    float64\n",
      " 10  rolloff_mean   400 non-null    float64\n",
      " 11  roll_off_var   400 non-null    float64\n",
      " 12  zcr_mean       400 non-null    float64\n",
      " 13  zcr_var        400 non-null    float64\n",
      " 14  tonnetz_mean   400 non-null    float64\n",
      " 15  tonnetz_var    400 non-null    float64\n",
      " 16  mel_mean       400 non-null    float64\n",
      " 17  mel_var        400 non-null    float64\n",
      " 18  mfcc_mean_1    400 non-null    float64\n",
      " 19  mfcc_var_1     400 non-null    float64\n",
      " 20  mfcc_mean_2    400 non-null    float64\n",
      " 21  mfcc_var_2     400 non-null    float64\n",
      " 22  mfcc_mean_3    400 non-null    float64\n",
      " 23  mfcc_var_3     400 non-null    float64\n",
      " 24  mfcc_mean_4    400 non-null    float64\n",
      " 25  mfcc_var_4     400 non-null    float64\n",
      " 26  mfcc_mean_5    400 non-null    float64\n",
      " 27  mfcc_var_5     400 non-null    float64\n",
      " 28  mfcc_mean_6    400 non-null    float64\n",
      " 29  mfcc_var_6     400 non-null    float64\n",
      " 30  mfcc_mean_7    400 non-null    float64\n",
      " 31  mfcc_var_7     400 non-null    float64\n",
      " 32  mfcc_mean_8    400 non-null    float64\n",
      " 33  mfcc_var_8     400 non-null    float64\n",
      " 34  mfcc_mean_9    400 non-null    float64\n",
      " 35  mfcc_var_9     400 non-null    float64\n",
      " 36  mfcc_mean_10   400 non-null    float64\n",
      " 37  mfcc_var_10    400 non-null    float64\n",
      " 38  mfcc_mean_11   400 non-null    float64\n",
      " 39  mfcc_var_11    400 non-null    float64\n",
      " 40  mfcc_mean_12   400 non-null    float64\n",
      " 41  mfcc_var_12    400 non-null    float64\n",
      " 42  mfcc_mean_13   400 non-null    float64\n",
      " 43  mfcc_var_13    400 non-null    float64\n",
      " 44  mfcc_mean_14   400 non-null    float64\n",
      " 45  mfcc_var_14    400 non-null    float64\n",
      " 46  mfcc_mean_15   400 non-null    float64\n",
      " 47  mfcc_var_15    400 non-null    float64\n",
      " 48  mfcc_mean_16   400 non-null    float64\n",
      " 49  mfcc_var_16    400 non-null    float64\n",
      " 50  mfcc_mean_17   400 non-null    float64\n",
      " 51  mfcc_var_17    400 non-null    float64\n",
      " 52  mfcc_mean_18   400 non-null    float64\n",
      " 53  mfcc_var_18    400 non-null    float64\n",
      " 54  mfcc_mean_19   400 non-null    float64\n",
      " 55  mfcc_var_19    400 non-null    float64\n",
      " 56  mfcc_mean_20   400 non-null    float64\n",
      " 57  mfcc_var_20    400 non-null    float64\n",
      " 58  mood           400 non-null    object \n",
      "dtypes: float64(55), object(4)\n",
      "memory usage: 184.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9baff1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>roll_off_var</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean_16</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>4.000000e+02</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>4.000000e+02</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>121.153331</td>\n",
       "      <td>0.118770</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.331975</td>\n",
       "      <td>0.085352</td>\n",
       "      <td>1802.486037</td>\n",
       "      <td>3.180519e+05</td>\n",
       "      <td>3680.355592</td>\n",
       "      <td>1.672630e+06</td>\n",
       "      <td>0.080345</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.010624</td>\n",
       "      <td>59.615112</td>\n",
       "      <td>-4.744398</td>\n",
       "      <td>59.401602</td>\n",
       "      <td>-0.608768</td>\n",
       "      <td>62.063296</td>\n",
       "      <td>-4.442099</td>\n",
       "      <td>66.349466</td>\n",
       "      <td>-0.848953</td>\n",
       "      <td>73.378861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.744658</td>\n",
       "      <td>0.059437</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.087221</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>651.203680</td>\n",
       "      <td>2.810984e+05</td>\n",
       "      <td>1501.206045</td>\n",
       "      <td>1.395001e+06</td>\n",
       "      <td>0.041138</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559469</td>\n",
       "      <td>40.272152</td>\n",
       "      <td>4.768623</td>\n",
       "      <td>37.590001</td>\n",
       "      <td>4.756607</td>\n",
       "      <td>38.923017</td>\n",
       "      <td>4.446831</td>\n",
       "      <td>42.345726</td>\n",
       "      <td>4.790249</td>\n",
       "      <td>50.602605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>33.999794</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.160259</td>\n",
       "      <td>0.050952</td>\n",
       "      <td>375.472632</td>\n",
       "      <td>1.150694e+04</td>\n",
       "      <td>535.694759</td>\n",
       "      <td>3.266810e+04</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.610699</td>\n",
       "      <td>14.551353</td>\n",
       "      <td>-24.893364</td>\n",
       "      <td>14.379240</td>\n",
       "      <td>-16.672720</td>\n",
       "      <td>13.698275</td>\n",
       "      <td>-19.804493</td>\n",
       "      <td>14.141619</td>\n",
       "      <td>-18.626137</td>\n",
       "      <td>13.516327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>103.359375</td>\n",
       "      <td>0.074349</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.268281</td>\n",
       "      <td>0.081917</td>\n",
       "      <td>1300.376902</td>\n",
       "      <td>1.370374e+05</td>\n",
       "      <td>2575.757575</td>\n",
       "      <td>7.025397e+05</td>\n",
       "      <td>0.048085</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.842349</td>\n",
       "      <td>34.335782</td>\n",
       "      <td>-7.630008</td>\n",
       "      <td>34.245143</td>\n",
       "      <td>-3.382443</td>\n",
       "      <td>36.080644</td>\n",
       "      <td>-6.791193</td>\n",
       "      <td>38.651546</td>\n",
       "      <td>-3.680080</td>\n",
       "      <td>40.332462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>117.453835</td>\n",
       "      <td>0.108431</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.319929</td>\n",
       "      <td>0.086349</td>\n",
       "      <td>1772.615561</td>\n",
       "      <td>2.283629e+05</td>\n",
       "      <td>3595.035859</td>\n",
       "      <td>1.224653e+06</td>\n",
       "      <td>0.075321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508271</td>\n",
       "      <td>50.099451</td>\n",
       "      <td>-4.506119</td>\n",
       "      <td>51.089298</td>\n",
       "      <td>-0.276665</td>\n",
       "      <td>53.090158</td>\n",
       "      <td>-4.065011</td>\n",
       "      <td>56.254971</td>\n",
       "      <td>-0.693477</td>\n",
       "      <td>62.006828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>135.999178</td>\n",
       "      <td>0.156254</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.381731</td>\n",
       "      <td>0.090105</td>\n",
       "      <td>2248.942922</td>\n",
       "      <td>4.188546e+05</td>\n",
       "      <td>4785.132302</td>\n",
       "      <td>2.189253e+06</td>\n",
       "      <td>0.105276</td>\n",
       "      <td>...</td>\n",
       "      <td>1.939811</td>\n",
       "      <td>71.015478</td>\n",
       "      <td>-1.810183</td>\n",
       "      <td>70.942482</td>\n",
       "      <td>2.786151</td>\n",
       "      <td>75.734247</td>\n",
       "      <td>-1.440908</td>\n",
       "      <td>80.194420</td>\n",
       "      <td>1.858971</td>\n",
       "      <td>92.351814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>198.768029</td>\n",
       "      <td>0.381500</td>\n",
       "      <td>0.017487</td>\n",
       "      <td>0.635405</td>\n",
       "      <td>0.104724</td>\n",
       "      <td>3498.680882</td>\n",
       "      <td>2.039381e+06</td>\n",
       "      <td>6959.760493</td>\n",
       "      <td>8.731942e+06</td>\n",
       "      <td>0.246214</td>\n",
       "      <td>...</td>\n",
       "      <td>13.872192</td>\n",
       "      <td>358.093811</td>\n",
       "      <td>12.957845</td>\n",
       "      <td>302.761414</td>\n",
       "      <td>13.124251</td>\n",
       "      <td>303.582184</td>\n",
       "      <td>6.750900</td>\n",
       "      <td>280.381073</td>\n",
       "      <td>13.298891</td>\n",
       "      <td>442.129852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tempo    rms_mean     rms_var  chroma_mean  chroma_var  \\\n",
       "count  400.000000  400.000000  400.000000   400.000000  400.000000   \n",
       "mean   121.153331    0.118770    0.002119     0.331975    0.085352   \n",
       "std     21.744658    0.059437    0.002130     0.087221    0.007522   \n",
       "min     33.999794    0.006620    0.000022     0.160259    0.050952   \n",
       "25%    103.359375    0.074349    0.000723     0.268281    0.081917   \n",
       "50%    117.453835    0.108431    0.001499     0.319929    0.086349   \n",
       "75%    135.999178    0.156254    0.002770     0.381731    0.090105   \n",
       "max    198.768029    0.381500    0.017487     0.635405    0.104724   \n",
       "\n",
       "       centroid_mean  centroid_var  rolloff_mean  roll_off_var    zcr_mean  \\\n",
       "count     400.000000  4.000000e+02    400.000000  4.000000e+02  400.000000   \n",
       "mean     1802.486037  3.180519e+05   3680.355592  1.672630e+06    0.080345   \n",
       "std       651.203680  2.810984e+05   1501.206045  1.395001e+06    0.041138   \n",
       "min       375.472632  1.150694e+04    535.694759  3.266810e+04    0.012583   \n",
       "25%      1300.376902  1.370374e+05   2575.757575  7.025397e+05    0.048085   \n",
       "50%      1772.615561  2.283629e+05   3595.035859  1.224653e+06    0.075321   \n",
       "75%      2248.942922  4.188546e+05   4785.132302  2.189253e+06    0.105276   \n",
       "max      3498.680882  2.039381e+06   6959.760493  8.731942e+06    0.246214   \n",
       "\n",
       "       ...  mfcc_mean_16  mfcc_var_16  mfcc_mean_17  mfcc_var_17  \\\n",
       "count  ...    400.000000   400.000000    400.000000   400.000000   \n",
       "mean   ...     -1.010624    59.615112     -4.744398    59.401602   \n",
       "std    ...      4.559469    40.272152      4.768623    37.590001   \n",
       "min    ...    -15.610699    14.551353    -24.893364    14.379240   \n",
       "25%    ...     -3.842349    34.335782     -7.630008    34.245143   \n",
       "50%    ...     -0.508271    50.099451     -4.506119    51.089298   \n",
       "75%    ...      1.939811    71.015478     -1.810183    70.942482   \n",
       "max    ...     13.872192   358.093811     12.957845   302.761414   \n",
       "\n",
       "       mfcc_mean_18  mfcc_var_18  mfcc_mean_19  mfcc_var_19  mfcc_mean_20  \\\n",
       "count    400.000000   400.000000    400.000000   400.000000    400.000000   \n",
       "mean      -0.608768    62.063296     -4.442099    66.349466     -0.848953   \n",
       "std        4.756607    38.923017      4.446831    42.345726      4.790249   \n",
       "min      -16.672720    13.698275    -19.804493    14.141619    -18.626137   \n",
       "25%       -3.382443    36.080644     -6.791193    38.651546     -3.680080   \n",
       "50%       -0.276665    53.090158     -4.065011    56.254971     -0.693477   \n",
       "75%        2.786151    75.734247     -1.440908    80.194420      1.858971   \n",
       "max       13.124251   303.582184      6.750900   280.381073     13.298891   \n",
       "\n",
       "       mfcc_var_20  \n",
       "count   400.000000  \n",
       "mean     73.378861  \n",
       "std      50.602605  \n",
       "min      13.516327  \n",
       "25%      40.332462  \n",
       "50%      62.006828  \n",
       "75%      92.351814  \n",
       "max     442.129852  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "425f82d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>roll_off_var</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean_16</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mood</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>119.791301</td>\n",
       "      <td>0.143684</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.411701</td>\n",
       "      <td>0.078807</td>\n",
       "      <td>1682.188780</td>\n",
       "      <td>246726.109565</td>\n",
       "      <td>3599.542549</td>\n",
       "      <td>1.383809e+06</td>\n",
       "      <td>0.063626</td>\n",
       "      <td>...</td>\n",
       "      <td>1.716340</td>\n",
       "      <td>29.765322</td>\n",
       "      <td>-2.571759</td>\n",
       "      <td>30.967275</td>\n",
       "      <td>1.447512</td>\n",
       "      <td>31.125205</td>\n",
       "      <td>-2.521920</td>\n",
       "      <td>32.986997</td>\n",
       "      <td>0.481562</td>\n",
       "      <td>35.662359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>119.642832</td>\n",
       "      <td>0.133122</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.370830</td>\n",
       "      <td>0.084728</td>\n",
       "      <td>2493.997373</td>\n",
       "      <td>294069.478889</td>\n",
       "      <td>5204.505149</td>\n",
       "      <td>1.297738e+06</td>\n",
       "      <td>0.126250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320654</td>\n",
       "      <td>51.620961</td>\n",
       "      <td>-5.706858</td>\n",
       "      <td>53.342652</td>\n",
       "      <td>0.194193</td>\n",
       "      <td>54.841584</td>\n",
       "      <td>-4.663004</td>\n",
       "      <td>61.447341</td>\n",
       "      <td>0.325686</td>\n",
       "      <td>64.573383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relaxed</th>\n",
       "      <td>121.566391</td>\n",
       "      <td>0.098366</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.282407</td>\n",
       "      <td>0.089781</td>\n",
       "      <td>1330.463239</td>\n",
       "      <td>493941.118676</td>\n",
       "      <td>2562.743408</td>\n",
       "      <td>2.661889e+06</td>\n",
       "      <td>0.053082</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.757295</td>\n",
       "      <td>80.247555</td>\n",
       "      <td>-4.782255</td>\n",
       "      <td>79.223248</td>\n",
       "      <td>-2.434461</td>\n",
       "      <td>79.815612</td>\n",
       "      <td>-5.031546</td>\n",
       "      <td>82.772726</td>\n",
       "      <td>-2.542924</td>\n",
       "      <td>91.384488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>123.612802</td>\n",
       "      <td>0.099908</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.262961</td>\n",
       "      <td>0.088090</td>\n",
       "      <td>1703.294757</td>\n",
       "      <td>237471.037870</td>\n",
       "      <td>3354.631264</td>\n",
       "      <td>1.347084e+06</td>\n",
       "      <td>0.078424</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.680886</td>\n",
       "      <td>76.826611</td>\n",
       "      <td>-5.916719</td>\n",
       "      <td>74.073230</td>\n",
       "      <td>-1.642316</td>\n",
       "      <td>82.470784</td>\n",
       "      <td>-5.551928</td>\n",
       "      <td>88.190799</td>\n",
       "      <td>-1.660135</td>\n",
       "      <td>101.895213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tempo  rms_mean   rms_var  chroma_mean  chroma_var  \\\n",
       "mood                                                               \n",
       "angry    119.791301  0.143684  0.002207     0.411701    0.078807   \n",
       "happy    119.642832  0.133122  0.002388     0.370830    0.084728   \n",
       "relaxed  121.566391  0.098366  0.002285     0.282407    0.089781   \n",
       "sad      123.612802  0.099908  0.001595     0.262961    0.088090   \n",
       "\n",
       "         centroid_mean   centroid_var  rolloff_mean  roll_off_var  zcr_mean  \\\n",
       "mood                                                                          \n",
       "angry      1682.188780  246726.109565   3599.542549  1.383809e+06  0.063626   \n",
       "happy      2493.997373  294069.478889   5204.505149  1.297738e+06  0.126250   \n",
       "relaxed    1330.463239  493941.118676   2562.743408  2.661889e+06  0.053082   \n",
       "sad        1703.294757  237471.037870   3354.631264  1.347084e+06  0.078424   \n",
       "\n",
       "         ...  mfcc_mean_16  mfcc_var_16  mfcc_mean_17  mfcc_var_17  \\\n",
       "mood     ...                                                         \n",
       "angry    ...      1.716340    29.765322     -2.571759    30.967275   \n",
       "happy    ...     -0.320654    51.620961     -5.706858    53.342652   \n",
       "relaxed  ...     -2.757295    80.247555     -4.782255    79.223248   \n",
       "sad      ...     -2.680886    76.826611     -5.916719    74.073230   \n",
       "\n",
       "         mfcc_mean_18  mfcc_var_18  mfcc_mean_19  mfcc_var_19  mfcc_mean_20  \\\n",
       "mood                                                                          \n",
       "angry        1.447512    31.125205     -2.521920    32.986997      0.481562   \n",
       "happy        0.194193    54.841584     -4.663004    61.447341      0.325686   \n",
       "relaxed     -2.434461    79.815612     -5.031546    82.772726     -2.542924   \n",
       "sad         -1.642316    82.470784     -5.551928    88.190799     -1.660135   \n",
       "\n",
       "         mfcc_var_20  \n",
       "mood                  \n",
       "angry      35.662359  \n",
       "happy      64.573383  \n",
       "relaxed    91.384488  \n",
       "sad       101.895213  \n",
       "\n",
       "[4 rows x 55 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('mood').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eca9703",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing\n",
    "### 2.1 Define Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be28fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'happy', 'relaxed', 'sad'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = df1.drop(['mood'],axis=1)\n",
    "y1 = df1['mood']\n",
    "np.unique(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99328a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'happy', 'relaxed', 'sad'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = df2.drop(['mood'],axis=1)\n",
    "y2 = df2['mood']\n",
    "np.unique(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d5d1f",
   "metadata": {},
   "source": [
    "### 2.2 Encode the non-numerical features labels\n",
    "\n",
    "**Encode the labels in numerical way:**\n",
    "- Happy: 1 \n",
    "- Angry: 0 \n",
    "- Relaxed: 2 \n",
    "- Sad: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1d89f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y1)\n",
    "y1 = le.transform(y1)\n",
    "np.unique(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32e6a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(y2)\n",
    "y2 = le.transform(y2)\n",
    "np.unique(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a79f5",
   "metadata": {},
   "source": [
    "**Then encode the non-numeric variable scale:**\n",
    "- major: 0\n",
    "- minor: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e64ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['major', 'minor'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1['scale'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53bcb6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(X1['scale'])\n",
    "X1['scale'] = le.transform(X1['scale'])\n",
    "X1['scale'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e96d6209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['minor', 'major'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2['scale'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0532f958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(X2['scale'])\n",
    "X2['scale'] = le.transform(X2['scale'])\n",
    "X2['scale'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282266b",
   "metadata": {},
   "source": [
    "**Finally, encode the non-numeric variable key:**\n",
    "- A: 0\n",
    "- A#: 1\n",
    "- B: 2\n",
    "- C: 3\n",
    "- C#: 4\n",
    "- D: 5\n",
    "- D#: 6\n",
    "- E: 7\n",
    "- F: 8\n",
    "- F#: 9\n",
    "- G: 10\n",
    "- G#: 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbc4c682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'A', 'E', 'G', 'F', 'A#', 'G#', 'D', 'F#', 'B', 'C#', 'D#'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1['key'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7324da64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  0,  7, 10,  8,  1, 11,  5,  9,  2,  4,  6])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(X1['key'])\n",
    "X1['key'] = le.transform(X1['key'])\n",
    "X1['key'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42fbeede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C#', 'D', 'G', 'F', 'G#', 'B', 'C', 'E', 'A', 'D#', 'F#', 'A#'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2['key'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d88fb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5, 10,  8, 11,  2,  3,  7,  0,  6,  9,  1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(X2['key'])\n",
    "X2['key'] = le.transform(X2['key'])\n",
    "X2['key'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c55b16",
   "metadata": {},
   "source": [
    "### 2.3 Train Test Validation Split\n",
    "Finally, split the dataset into train and test set, 80% of data are used as train set, 10% of data are used as test set and the remaining ones are used for validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cfd54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, \n",
    "                                                        train_size = 0.8, \n",
    "                                                        random_state = 13,  \n",
    "                                                        stratify = y1)\n",
    "\n",
    "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, \n",
    "                                                      train_size = 0.8, \n",
    "                                                      random_state = 13,  \n",
    "                                                      stratify = y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4900c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, \n",
    "                                                    train_size = 0.9, \n",
    "                                                    random_state = 13, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify = y2)\n",
    "X2_train, X2_val, y2_train, y2_val = train_test_split(X2_train, y2_train, \n",
    "                                                train_size = 0.8, \n",
    "                                                random_state = 13, \n",
    "                                                shuffle = True, \n",
    "                                                stratify = y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1c809",
   "metadata": {},
   "source": [
    "### 2.4 Feature Scaling\n",
    "As the range of the variales varies distinctly, in order to make the learning process better, the features need to be scaled into similar ranges. Here the Min-Max Scaler is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38e763e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X1_train_scaled = scaler.fit_transform(X1_train.drop('file',axis=1))\n",
    "X1_val_scaled = scaler.fit_transform(X1_val.drop('file',axis=1))\n",
    "X1_test_scaled = scaler.fit_transform(X1_test.drop('file',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed445136",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train_scaled = scaler.fit_transform(X2_train.drop('file',axis=1))\n",
    "X2_val_scaled = scaler.fit_transform(X2_val.drop('file',axis=1))\n",
    "X2_test_scaled = scaler.fit_transform(X2_test.drop('file',axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f2ff7",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963df061",
   "metadata": {},
   "source": [
    "### 3.1 Overfitting problems and comparison study for improving the validation accuracy\n",
    "Using data in dataset 1 as training data, the model always suffers from the overfitting problems regardless of the\n",
    "adjustment of the parameters and number of input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5153ff50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define Model Builder of 3 conv1D layers and 2 fully connected layers\n",
    "# Input data and paras of layers are changable\n",
    "\n",
    "def modelBuilder3L(X_train,\n",
    "                  f1,k1,a1,\n",
    "                  f2,k2,a2,\n",
    "                  f3,k3,a3,\n",
    "                  d1,dr1,da1,r1,\n",
    "                  d2,dr2,da2,r2,\n",
    "                  num):\n",
    "    '''\n",
    "    args:\n",
    "    \n",
    "    X_train: training data\n",
    "    f1,k1,a1: num of filters, filter size and activation func of 1st conv1D layer\n",
    "    f2,k2,a2: num of filters, filter size and activation func of 2nd conv1D layer\n",
    "    f3,k3,a3: num of filters, filter size and activation func of 3rd conv1D layer\n",
    "    d1,dr1,da1, r1: num of units, dropout, activation func and regularizer para of 1st fully connected layer\n",
    "    d2,dr2,da2, r2: num of units, dropout, activation func and regularizer para of 2nd fully connected layer\n",
    "    num: integer for distinguishing different model\n",
    "    \n",
    "    return:\n",
    "    model\n",
    "    \n",
    "    '''\n",
    "    model = Sequential(name=\"Conv1D_\"+str(num))\n",
    "    m,n = X_train.shape\n",
    "    #layer 1\n",
    "    model.add(Conv1D(filters = f1, kernel_size = k1, input_shape = (n,1), padding = 'same', activation = a1, name ='Conv1D_1'))\n",
    "    model.add(BatchNormalization(name = \"BN1\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling1\"))\n",
    "    #layer 2\n",
    "    model.add(Conv1D(filters = f2, kernel_size = k2, activation = a2, padding='same', name = \"Conv1D_2\"))\n",
    "    model.add(BatchNormalization(name = \"BN2\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling2\"))\n",
    "    #layer 3\n",
    "    model.add(Conv1D(filters = f3, kernel_size = k3, activation = a3, padding='same', name = \"Conv1D_3\"))\n",
    "    model.add(BatchNormalization(name = \"BN3\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling3\"))\n",
    "    #Flatten output\n",
    "    model.add(Flatten(name = \"Flatten\"))\n",
    "    #Fully connected layer 4\n",
    "    model.add(Dense(d1, activation = da1, name = \"Dense_1\"))\n",
    "    #Prevent overfitting\n",
    "    model.add(Dropout(dr1, name = \"Dropout_1\"))\n",
    "    #Fully connected layer 6\n",
    "    model.add(Dense(d2, activation = da2, name = \"Dense_2\"))\n",
    "    #Prevent overfitting\n",
    "    model.add(Dropout(dr2, name = \"Dropout_2\"))\n",
    "    #Output layer\n",
    "    model.add(Dense(4, activation = 'softmax', name = \"Softmax\"))\n",
    "    #model compiling\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aca4bb89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 14, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 14, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 7, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               28800     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,548\n",
      "Trainable params: 48,388\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0\n",
    "num = 1\n",
    "\n",
    "model1 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "357e957b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 5s 24ms/step - loss: 1.6228 - accuracy: 0.3310 - val_loss: 1.3912 - val_accuracy: 0.2292\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 1.3780 - accuracy: 0.3798 - val_loss: 1.3932 - val_accuracy: 0.2639\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 1.1896 - accuracy: 0.4791 - val_loss: 1.3937 - val_accuracy: 0.2569\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 1.1375 - accuracy: 0.4652 - val_loss: 1.3906 - val_accuracy: 0.2569\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 1.0660 - accuracy: 0.5192 - val_loss: 1.3841 - val_accuracy: 0.2639\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 1.0504 - accuracy: 0.5331 - val_loss: 1.3788 - val_accuracy: 0.2708\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.9812 - accuracy: 0.5732 - val_loss: 1.3689 - val_accuracy: 0.2847\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.9120 - accuracy: 0.6115 - val_loss: 1.3468 - val_accuracy: 0.3264\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.8929 - accuracy: 0.6289 - val_loss: 1.3169 - val_accuracy: 0.3889\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.8717 - accuracy: 0.6237 - val_loss: 1.2827 - val_accuracy: 0.4306\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.8523 - accuracy: 0.6324 - val_loss: 1.2357 - val_accuracy: 0.4236\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.8018 - accuracy: 0.6672 - val_loss: 1.1768 - val_accuracy: 0.4583\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.7936 - accuracy: 0.6725 - val_loss: 1.1237 - val_accuracy: 0.4792\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7600 - accuracy: 0.6847 - val_loss: 1.0706 - val_accuracy: 0.5139\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7276 - accuracy: 0.6829 - val_loss: 1.0488 - val_accuracy: 0.5278\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7420 - accuracy: 0.6777 - val_loss: 1.0222 - val_accuracy: 0.5347\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.6718 - accuracy: 0.7160 - val_loss: 1.0230 - val_accuracy: 0.5486\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.7108 - val_loss: 1.0352 - val_accuracy: 0.5556\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6724 - accuracy: 0.7456 - val_loss: 1.0477 - val_accuracy: 0.5000\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.7491 - val_loss: 1.0677 - val_accuracy: 0.5069\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.6386 - accuracy: 0.7526 - val_loss: 1.0898 - val_accuracy: 0.5069\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6007 - accuracy: 0.7857 - val_loss: 1.1176 - val_accuracy: 0.5000\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5950 - accuracy: 0.7857 - val_loss: 1.1359 - val_accuracy: 0.4931\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5969 - accuracy: 0.7491 - val_loss: 1.1509 - val_accuracy: 0.4722\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5617 - accuracy: 0.7700 - val_loss: 1.1704 - val_accuracy: 0.4931\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.5287 - accuracy: 0.7753 - val_loss: 1.1802 - val_accuracy: 0.4583\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5121 - accuracy: 0.8223 - val_loss: 1.1467 - val_accuracy: 0.4861\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.8293 - val_loss: 1.1840 - val_accuracy: 0.4792\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.5041 - accuracy: 0.8066 - val_loss: 1.1953 - val_accuracy: 0.4931\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.4652 - accuracy: 0.8258 - val_loss: 1.1880 - val_accuracy: 0.4931\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.8345 - val_loss: 1.2256 - val_accuracy: 0.4931\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.8432 - val_loss: 1.2487 - val_accuracy: 0.4861\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.8449 - val_loss: 1.2531 - val_accuracy: 0.4861\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8502 - val_loss: 1.2909 - val_accuracy: 0.4861\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.3967 - accuracy: 0.8519 - val_loss: 1.2689 - val_accuracy: 0.4931\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.3893 - accuracy: 0.8624 - val_loss: 1.2685 - val_accuracy: 0.4931\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8449 - val_loss: 1.2656 - val_accuracy: 0.4931\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.3462 - accuracy: 0.8902 - val_loss: 1.2867 - val_accuracy: 0.5000\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3339 - accuracy: 0.8937 - val_loss: 1.3176 - val_accuracy: 0.5139\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.8902 - val_loss: 1.3447 - val_accuracy: 0.5069\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.3055 - accuracy: 0.9042 - val_loss: 1.3553 - val_accuracy: 0.4861\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3201 - accuracy: 0.8798 - val_loss: 1.3472 - val_accuracy: 0.5069\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3393 - accuracy: 0.8780 - val_loss: 1.4163 - val_accuracy: 0.5000\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2808 - accuracy: 0.9146 - val_loss: 1.4392 - val_accuracy: 0.4861\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2798 - accuracy: 0.9216 - val_loss: 1.4340 - val_accuracy: 0.5000\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2593 - accuracy: 0.9164 - val_loss: 1.4598 - val_accuracy: 0.5069\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2663 - accuracy: 0.9199 - val_loss: 1.4539 - val_accuracy: 0.5139\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2513 - accuracy: 0.9181 - val_loss: 1.4911 - val_accuracy: 0.5208\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2356 - accuracy: 0.9321 - val_loss: 1.4936 - val_accuracy: 0.5278\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2575 - accuracy: 0.9077 - val_loss: 1.5234 - val_accuracy: 0.5139\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2419 - accuracy: 0.9338 - val_loss: 1.5608 - val_accuracy: 0.5069\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2132 - accuracy: 0.9408 - val_loss: 1.5238 - val_accuracy: 0.5278\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2023 - accuracy: 0.9460 - val_loss: 1.5874 - val_accuracy: 0.5069\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2409 - accuracy: 0.9181 - val_loss: 1.5984 - val_accuracy: 0.5278\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1833 - accuracy: 0.9408 - val_loss: 1.6102 - val_accuracy: 0.5208\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1803 - accuracy: 0.9564 - val_loss: 1.6440 - val_accuracy: 0.5208\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1921 - accuracy: 0.9547 - val_loss: 1.6805 - val_accuracy: 0.5000\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1672 - accuracy: 0.9634 - val_loss: 1.6770 - val_accuracy: 0.5069\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1729 - accuracy: 0.9477 - val_loss: 1.6974 - val_accuracy: 0.5139\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1648 - accuracy: 0.9617 - val_loss: 1.7355 - val_accuracy: 0.5069\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1561 - accuracy: 0.9634 - val_loss: 1.7208 - val_accuracy: 0.5139\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1545 - accuracy: 0.9582 - val_loss: 1.7275 - val_accuracy: 0.5139\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1429 - accuracy: 0.9617 - val_loss: 1.7394 - val_accuracy: 0.5069\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1286 - accuracy: 0.9756 - val_loss: 1.7954 - val_accuracy: 0.5000\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1291 - accuracy: 0.9704 - val_loss: 1.8012 - val_accuracy: 0.4861\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1372 - accuracy: 0.9652 - val_loss: 1.8199 - val_accuracy: 0.4861\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1224 - accuracy: 0.9634 - val_loss: 1.8402 - val_accuracy: 0.4931\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1223 - accuracy: 0.9739 - val_loss: 1.8240 - val_accuracy: 0.4792\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1120 - accuracy: 0.9721 - val_loss: 1.8710 - val_accuracy: 0.4861\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.9739 - val_loss: 1.8588 - val_accuracy: 0.4861\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1315 - accuracy: 0.9634 - val_loss: 1.9256 - val_accuracy: 0.5139\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0909 - accuracy: 0.9808 - val_loss: 2.0095 - val_accuracy: 0.5000\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.9826 - val_loss: 1.9504 - val_accuracy: 0.4931\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0949 - accuracy: 0.9808 - val_loss: 1.9544 - val_accuracy: 0.5000\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9861 - val_loss: 1.9555 - val_accuracy: 0.4931\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0892 - accuracy: 0.9791 - val_loss: 1.9551 - val_accuracy: 0.5000\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0724 - accuracy: 0.9861 - val_loss: 1.9895 - val_accuracy: 0.4931\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0803 - accuracy: 0.9843 - val_loss: 2.0291 - val_accuracy: 0.4931\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9808 - val_loss: 2.0237 - val_accuracy: 0.4792\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0634 - accuracy: 0.9861 - val_loss: 2.0157 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40c7df",
   "metadata": {},
   "source": [
    "**Add regularization**</br>\n",
    "The training accuarcy is high but validation accuracy is low, which means the model is overfitting. Therefore, add the regularization parameters to the dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "256f299d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 14, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 14, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 7, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               28800     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,548\n",
      "Trainable params: 48,388\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 2\n",
    "\n",
    "model2 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a3822fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "36/36 [==============================] - 3s 17ms/step - loss: 1.6185 - accuracy: 0.2892 - val_loss: 1.3847 - val_accuracy: 0.2986\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.3358 - accuracy: 0.3955 - val_loss: 1.3881 - val_accuracy: 0.2708\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 1.1944 - accuracy: 0.4617 - val_loss: 1.4032 - val_accuracy: 0.2569\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.1242 - accuracy: 0.4913 - val_loss: 1.4242 - val_accuracy: 0.2639\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0921 - accuracy: 0.5174 - val_loss: 1.4463 - val_accuracy: 0.2708\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0274 - accuracy: 0.5279 - val_loss: 1.4676 - val_accuracy: 0.2639\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9886 - accuracy: 0.5453 - val_loss: 1.4767 - val_accuracy: 0.2569\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.9192 - accuracy: 0.5923 - val_loss: 1.4718 - val_accuracy: 0.2569\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8956 - accuracy: 0.5976 - val_loss: 1.4413 - val_accuracy: 0.2917\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8404 - accuracy: 0.6516 - val_loss: 1.3980 - val_accuracy: 0.3056\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8408 - accuracy: 0.6498 - val_loss: 1.3377 - val_accuracy: 0.3194\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8463 - accuracy: 0.6289 - val_loss: 1.2950 - val_accuracy: 0.3403\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7716 - accuracy: 0.6638 - val_loss: 1.2517 - val_accuracy: 0.3819\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.7696 - accuracy: 0.6829 - val_loss: 1.2102 - val_accuracy: 0.4236\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7479 - accuracy: 0.7056 - val_loss: 1.1720 - val_accuracy: 0.4792\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7134 - accuracy: 0.7038 - val_loss: 1.1539 - val_accuracy: 0.4653\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6806 - accuracy: 0.7300 - val_loss: 1.1304 - val_accuracy: 0.4792\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6851 - accuracy: 0.7160 - val_loss: 1.1200 - val_accuracy: 0.4931\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.6802 - accuracy: 0.7230 - val_loss: 1.0957 - val_accuracy: 0.5278\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6151 - accuracy: 0.7666 - val_loss: 1.0873 - val_accuracy: 0.5139\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6098 - accuracy: 0.7683 - val_loss: 1.1053 - val_accuracy: 0.5278\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5858 - accuracy: 0.7735 - val_loss: 1.1081 - val_accuracy: 0.5278\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5795 - accuracy: 0.7753 - val_loss: 1.1012 - val_accuracy: 0.5278\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.5411 - accuracy: 0.7944 - val_loss: 1.1024 - val_accuracy: 0.5347\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5164 - accuracy: 0.7909 - val_loss: 1.1093 - val_accuracy: 0.5417\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5284 - accuracy: 0.8188 - val_loss: 1.1339 - val_accuracy: 0.5417\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4990 - accuracy: 0.8240 - val_loss: 1.1153 - val_accuracy: 0.5417\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5099 - accuracy: 0.8118 - val_loss: 1.1079 - val_accuracy: 0.5486\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.8537 - val_loss: 1.1249 - val_accuracy: 0.5486\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.4574 - accuracy: 0.8467 - val_loss: 1.1432 - val_accuracy: 0.5486\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8693 - val_loss: 1.1478 - val_accuracy: 0.5417\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8589 - val_loss: 1.1445 - val_accuracy: 0.5764\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.8537 - val_loss: 1.1393 - val_accuracy: 0.5417\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.8589 - val_loss: 1.1485 - val_accuracy: 0.5625\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.3864 - accuracy: 0.8763 - val_loss: 1.1912 - val_accuracy: 0.5417\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8746 - val_loss: 1.1786 - val_accuracy: 0.5486\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3671 - accuracy: 0.8885 - val_loss: 1.1933 - val_accuracy: 0.5417\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3577 - accuracy: 0.8746 - val_loss: 1.2079 - val_accuracy: 0.5486\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3585 - accuracy: 0.8815 - val_loss: 1.2014 - val_accuracy: 0.5486\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3422 - accuracy: 0.8833 - val_loss: 1.2313 - val_accuracy: 0.5347\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.3330 - accuracy: 0.8815 - val_loss: 1.2133 - val_accuracy: 0.5556\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3278 - accuracy: 0.8815 - val_loss: 1.2437 - val_accuracy: 0.5556\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2860 - accuracy: 0.9111 - val_loss: 1.2371 - val_accuracy: 0.5556\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2983 - accuracy: 0.8902 - val_loss: 1.2438 - val_accuracy: 0.5556\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2777 - accuracy: 0.9199 - val_loss: 1.2799 - val_accuracy: 0.5556\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2717 - accuracy: 0.9181 - val_loss: 1.3138 - val_accuracy: 0.5486\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2553 - accuracy: 0.9111 - val_loss: 1.2927 - val_accuracy: 0.5486\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2586 - accuracy: 0.9164 - val_loss: 1.3370 - val_accuracy: 0.5486\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2336 - accuracy: 0.9181 - val_loss: 1.3088 - val_accuracy: 0.5417\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2087 - accuracy: 0.9460 - val_loss: 1.3747 - val_accuracy: 0.5625\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2312 - accuracy: 0.9268 - val_loss: 1.3474 - val_accuracy: 0.5486\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1911 - accuracy: 0.9512 - val_loss: 1.3359 - val_accuracy: 0.5556\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1930 - accuracy: 0.9443 - val_loss: 1.3827 - val_accuracy: 0.5347\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1799 - accuracy: 0.9582 - val_loss: 1.3857 - val_accuracy: 0.5417\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1940 - accuracy: 0.9408 - val_loss: 1.3644 - val_accuracy: 0.5556\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1912 - accuracy: 0.9338 - val_loss: 1.4134 - val_accuracy: 0.5625\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1898 - accuracy: 0.9390 - val_loss: 1.4384 - val_accuracy: 0.5625\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1731 - accuracy: 0.9512 - val_loss: 1.4263 - val_accuracy: 0.5556\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1730 - accuracy: 0.9547 - val_loss: 1.4333 - val_accuracy: 0.5417\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1541 - accuracy: 0.9634 - val_loss: 1.4832 - val_accuracy: 0.5417\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1405 - accuracy: 0.9634 - val_loss: 1.4504 - val_accuracy: 0.5556\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.9512 - val_loss: 1.4806 - val_accuracy: 0.5486\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1457 - accuracy: 0.9512 - val_loss: 1.4662 - val_accuracy: 0.5486\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1322 - accuracy: 0.9704 - val_loss: 1.5505 - val_accuracy: 0.5625\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1250 - accuracy: 0.9652 - val_loss: 1.5387 - val_accuracy: 0.5486\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1194 - accuracy: 0.9704 - val_loss: 1.5614 - val_accuracy: 0.5486\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1183 - accuracy: 0.9756 - val_loss: 1.6003 - val_accuracy: 0.5486\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1121 - accuracy: 0.9756 - val_loss: 1.6313 - val_accuracy: 0.5347\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1158 - accuracy: 0.9704 - val_loss: 1.5910 - val_accuracy: 0.5417\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1194 - accuracy: 0.9686 - val_loss: 1.6437 - val_accuracy: 0.5417\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0930 - accuracy: 0.9826 - val_loss: 1.6390 - val_accuracy: 0.5486\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0968 - accuracy: 0.9756 - val_loss: 1.6422 - val_accuracy: 0.5347\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0820 - accuracy: 0.9808 - val_loss: 1.6785 - val_accuracy: 0.5417\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0932 - accuracy: 0.9739 - val_loss: 1.6767 - val_accuracy: 0.5417\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1043 - accuracy: 0.9686 - val_loss: 1.6783 - val_accuracy: 0.5347\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0788 - accuracy: 0.9826 - val_loss: 1.7169 - val_accuracy: 0.5347\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0772 - accuracy: 0.9808 - val_loss: 1.7054 - val_accuracy: 0.5417\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0820 - accuracy: 0.9774 - val_loss: 1.7051 - val_accuracy: 0.5417\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0767 - accuracy: 0.9808 - val_loss: 1.7243 - val_accuracy: 0.5347\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0700 - accuracy: 0.9843 - val_loss: 1.7867 - val_accuracy: 0.5486\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d347faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 14, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 14, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 7, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               28800     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,548\n",
      "Trainable params: 48,388\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.2\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.2\n",
    "num = 3\n",
    "\n",
    "model3 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7d27032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "36/36 [==============================] - 4s 18ms/step - loss: 1.6816 - accuracy: 0.2892 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 1.4176 - accuracy: 0.3728 - val_loss: 1.3871 - val_accuracy: 0.3403\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.2944 - accuracy: 0.4024 - val_loss: 1.3889 - val_accuracy: 0.2569\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 1.1513 - accuracy: 0.4878 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.1019 - accuracy: 0.5348 - val_loss: 1.3895 - val_accuracy: 0.2500\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0310 - accuracy: 0.5732 - val_loss: 1.3869 - val_accuracy: 0.2569\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.0156 - accuracy: 0.5801 - val_loss: 1.3826 - val_accuracy: 0.2569\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9733 - accuracy: 0.5923 - val_loss: 1.3729 - val_accuracy: 0.2847\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.9809 - accuracy: 0.5627 - val_loss: 1.3640 - val_accuracy: 0.2708\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8811 - accuracy: 0.6481 - val_loss: 1.3467 - val_accuracy: 0.2847\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8714 - accuracy: 0.6498 - val_loss: 1.3129 - val_accuracy: 0.2778\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8680 - accuracy: 0.6446 - val_loss: 1.2650 - val_accuracy: 0.3472\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7774 - accuracy: 0.6934 - val_loss: 1.1987 - val_accuracy: 0.4306\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7702 - accuracy: 0.6934 - val_loss: 1.1424 - val_accuracy: 0.4861\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7434 - accuracy: 0.6969 - val_loss: 1.0943 - val_accuracy: 0.4931\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7155 - accuracy: 0.7125 - val_loss: 1.0596 - val_accuracy: 0.5000\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7224 - accuracy: 0.7021 - val_loss: 1.0414 - val_accuracy: 0.4861\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.7151 - accuracy: 0.7056 - val_loss: 1.0282 - val_accuracy: 0.5000\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6782 - accuracy: 0.7300 - val_loss: 1.0314 - val_accuracy: 0.4792\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6392 - accuracy: 0.7648 - val_loss: 1.0236 - val_accuracy: 0.5069\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6694 - accuracy: 0.7352 - val_loss: 1.0341 - val_accuracy: 0.4931\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6146 - accuracy: 0.7666 - val_loss: 1.0327 - val_accuracy: 0.5139\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.5856 - accuracy: 0.7840 - val_loss: 1.0521 - val_accuracy: 0.5208\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5298 - accuracy: 0.8066 - val_loss: 1.0638 - val_accuracy: 0.5139\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5643 - accuracy: 0.7718 - val_loss: 1.0816 - val_accuracy: 0.4861\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5160 - accuracy: 0.8206 - val_loss: 1.0846 - val_accuracy: 0.5139\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.8258 - val_loss: 1.1044 - val_accuracy: 0.5069\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.8415 - val_loss: 1.1109 - val_accuracy: 0.5000\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.4667 - accuracy: 0.8328 - val_loss: 1.1204 - val_accuracy: 0.5208\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.4371 - accuracy: 0.8432 - val_loss: 1.1465 - val_accuracy: 0.5069\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8676 - val_loss: 1.1571 - val_accuracy: 0.5069\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8415 - val_loss: 1.1845 - val_accuracy: 0.5069\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.8328 - val_loss: 1.1981 - val_accuracy: 0.5000\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.4007 - accuracy: 0.8519 - val_loss: 1.2101 - val_accuracy: 0.5069\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3750 - accuracy: 0.8659 - val_loss: 1.2185 - val_accuracy: 0.4861\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8624 - val_loss: 1.2170 - val_accuracy: 0.5139\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8902 - val_loss: 1.2213 - val_accuracy: 0.5278\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3295 - accuracy: 0.8902 - val_loss: 1.2409 - val_accuracy: 0.5069\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3047 - accuracy: 0.9129 - val_loss: 1.2550 - val_accuracy: 0.5139\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.3065 - accuracy: 0.8937 - val_loss: 1.2744 - val_accuracy: 0.5139\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2796 - accuracy: 0.9181 - val_loss: 1.3009 - val_accuracy: 0.4931\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2778 - accuracy: 0.9129 - val_loss: 1.3203 - val_accuracy: 0.5069\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2848 - accuracy: 0.9059 - val_loss: 1.3508 - val_accuracy: 0.4931\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2541 - accuracy: 0.9268 - val_loss: 1.3600 - val_accuracy: 0.5000\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2463 - accuracy: 0.9059 - val_loss: 1.3551 - val_accuracy: 0.4792\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2437 - accuracy: 0.9268 - val_loss: 1.4072 - val_accuracy: 0.5069\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2167 - accuracy: 0.9321 - val_loss: 1.4255 - val_accuracy: 0.4861\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2077 - accuracy: 0.9373 - val_loss: 1.4554 - val_accuracy: 0.4931\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1999 - accuracy: 0.9460 - val_loss: 1.4788 - val_accuracy: 0.5069\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2177 - accuracy: 0.9390 - val_loss: 1.4504 - val_accuracy: 0.4931\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2040 - accuracy: 0.9390 - val_loss: 1.4648 - val_accuracy: 0.5139\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1877 - accuracy: 0.9477 - val_loss: 1.5152 - val_accuracy: 0.5000\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1733 - accuracy: 0.9582 - val_loss: 1.5040 - val_accuracy: 0.5139\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1782 - accuracy: 0.9425 - val_loss: 1.5625 - val_accuracy: 0.5139\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1509 - accuracy: 0.9617 - val_loss: 1.5549 - val_accuracy: 0.5069\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1634 - accuracy: 0.9477 - val_loss: 1.5710 - val_accuracy: 0.5000\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1484 - accuracy: 0.9582 - val_loss: 1.6320 - val_accuracy: 0.4792\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1370 - accuracy: 0.9599 - val_loss: 1.6434 - val_accuracy: 0.4792\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.9652 - val_loss: 1.6770 - val_accuracy: 0.4931\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.9739 - val_loss: 1.6694 - val_accuracy: 0.4931\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1145 - accuracy: 0.9739 - val_loss: 1.7047 - val_accuracy: 0.5069\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1162 - accuracy: 0.9617 - val_loss: 1.7349 - val_accuracy: 0.5000\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1068 - accuracy: 0.9843 - val_loss: 1.7701 - val_accuracy: 0.4931\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1064 - accuracy: 0.9704 - val_loss: 1.7779 - val_accuracy: 0.5069\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1196 - accuracy: 0.9617 - val_loss: 1.8574 - val_accuracy: 0.4792\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0976 - accuracy: 0.9808 - val_loss: 1.7820 - val_accuracy: 0.5139\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0850 - accuracy: 0.9861 - val_loss: 1.8523 - val_accuracy: 0.4931\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1088 - accuracy: 0.9791 - val_loss: 1.8278 - val_accuracy: 0.5000\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0964 - accuracy: 0.9756 - val_loss: 1.9004 - val_accuracy: 0.4931\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0795 - accuracy: 0.9843 - val_loss: 1.9039 - val_accuracy: 0.5069\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0817 - accuracy: 0.9721 - val_loss: 1.9261 - val_accuracy: 0.5000\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0788 - accuracy: 0.9826 - val_loss: 1.9503 - val_accuracy: 0.5139\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9861 - val_loss: 1.9607 - val_accuracy: 0.5139\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9826 - val_loss: 1.9512 - val_accuracy: 0.5139\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0622 - accuracy: 0.9913 - val_loss: 1.9906 - val_accuracy: 0.5069\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0786 - accuracy: 0.9808 - val_loss: 2.0717 - val_accuracy: 0.5208\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0714 - accuracy: 0.9808 - val_loss: 2.1345 - val_accuracy: 0.4861\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.9895 - val_loss: 2.1049 - val_accuracy: 0.5069\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0551 - accuracy: 0.9913 - val_loss: 2.0976 - val_accuracy: 0.5208\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0637 - accuracy: 0.9808 - val_loss: 2.1112 - val_accuracy: 0.5139\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568ba75",
   "metadata": {},
   "source": [
    "Adding regularization parameters almost does not improve the validation accuracy very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f991714c",
   "metadata": {},
   "source": [
    "**Increase the dropout parameter value**<br>\n",
    "This only slightly improve the validation accuracy and damage the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7deb22f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 14, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 14, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 7, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               28800     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,548\n",
      "Trainable params: 48,388\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.3,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.3,'relu',0.15\n",
    "num = 4\n",
    "\n",
    "model4 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7435da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 4s 18ms/step - loss: 1.6607 - accuracy: 0.3432 - val_loss: 1.4217 - val_accuracy: 0.2500\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.4602 - accuracy: 0.3484 - val_loss: 1.4950 - val_accuracy: 0.2500\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.3275 - accuracy: 0.4477 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 1.2856 - accuracy: 0.4216 - val_loss: 1.5887 - val_accuracy: 0.3056\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.1754 - accuracy: 0.4756 - val_loss: 1.5983 - val_accuracy: 0.3958\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.1750 - accuracy: 0.4774 - val_loss: 1.5913 - val_accuracy: 0.3889\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0856 - accuracy: 0.5331 - val_loss: 1.5634 - val_accuracy: 0.3889\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0816 - accuracy: 0.5209 - val_loss: 1.5146 - val_accuracy: 0.4167\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.9918 - accuracy: 0.5767 - val_loss: 1.4588 - val_accuracy: 0.4375\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0354 - accuracy: 0.5523 - val_loss: 1.3992 - val_accuracy: 0.4792\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0060 - accuracy: 0.5418 - val_loss: 1.3364 - val_accuracy: 0.5000\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0066 - accuracy: 0.5453 - val_loss: 1.2723 - val_accuracy: 0.4444\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9721 - accuracy: 0.5540 - val_loss: 1.2140 - val_accuracy: 0.4514\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9363 - accuracy: 0.5993 - val_loss: 1.1672 - val_accuracy: 0.4375\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.8873 - accuracy: 0.6307 - val_loss: 1.1215 - val_accuracy: 0.4583\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8678 - accuracy: 0.6324 - val_loss: 1.0908 - val_accuracy: 0.4931\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8386 - accuracy: 0.6324 - val_loss: 1.0603 - val_accuracy: 0.5000\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8740 - accuracy: 0.6481 - val_loss: 1.0514 - val_accuracy: 0.5069\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8631 - accuracy: 0.6359 - val_loss: 1.0437 - val_accuracy: 0.5139\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.8340 - accuracy: 0.6516 - val_loss: 1.0427 - val_accuracy: 0.5000\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8318 - accuracy: 0.6463 - val_loss: 1.0498 - val_accuracy: 0.5000\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7568 - accuracy: 0.6916 - val_loss: 1.0468 - val_accuracy: 0.5139\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7824 - accuracy: 0.6794 - val_loss: 1.0476 - val_accuracy: 0.5208\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7492 - accuracy: 0.6986 - val_loss: 1.0479 - val_accuracy: 0.5069\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8028 - accuracy: 0.6585 - val_loss: 1.0514 - val_accuracy: 0.5139\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7055 - accuracy: 0.7056 - val_loss: 1.0602 - val_accuracy: 0.5139\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.7121 - accuracy: 0.6986 - val_loss: 1.0487 - val_accuracy: 0.5208\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6791 - accuracy: 0.7317 - val_loss: 1.0425 - val_accuracy: 0.5347\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7030 - accuracy: 0.6951 - val_loss: 1.0608 - val_accuracy: 0.5208\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6695 - accuracy: 0.7195 - val_loss: 1.0760 - val_accuracy: 0.5208\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6874 - accuracy: 0.7195 - val_loss: 1.0755 - val_accuracy: 0.5278\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6942 - accuracy: 0.7213 - val_loss: 1.0839 - val_accuracy: 0.5417\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.6327 - accuracy: 0.7491 - val_loss: 1.0835 - val_accuracy: 0.5417\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6144 - accuracy: 0.7700 - val_loss: 1.0974 - val_accuracy: 0.5347\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6096 - accuracy: 0.7700 - val_loss: 1.0969 - val_accuracy: 0.5278\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5887 - accuracy: 0.7840 - val_loss: 1.0988 - val_accuracy: 0.5347\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6153 - accuracy: 0.7700 - val_loss: 1.1113 - val_accuracy: 0.5347\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5153 - accuracy: 0.8118 - val_loss: 1.1207 - val_accuracy: 0.5486\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.5719 - accuracy: 0.7840 - val_loss: 1.1257 - val_accuracy: 0.5417\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5011 - accuracy: 0.7979 - val_loss: 1.1441 - val_accuracy: 0.5486\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5088 - accuracy: 0.7875 - val_loss: 1.1360 - val_accuracy: 0.5278\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4886 - accuracy: 0.8240 - val_loss: 1.1382 - val_accuracy: 0.5417\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.8171 - val_loss: 1.1695 - val_accuracy: 0.5278\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.4813 - accuracy: 0.8206 - val_loss: 1.1656 - val_accuracy: 0.5486\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.4770 - accuracy: 0.8310 - val_loss: 1.1610 - val_accuracy: 0.5556\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.8554 - val_loss: 1.1558 - val_accuracy: 0.5417\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4385 - accuracy: 0.8328 - val_loss: 1.2068 - val_accuracy: 0.5417\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.8258 - val_loss: 1.1934 - val_accuracy: 0.5486\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.8467 - val_loss: 1.2039 - val_accuracy: 0.5347\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.4224 - accuracy: 0.8397 - val_loss: 1.2386 - val_accuracy: 0.5278\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.8484 - val_loss: 1.2346 - val_accuracy: 0.5347\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.8432 - val_loss: 1.2407 - val_accuracy: 0.5417\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8693 - val_loss: 1.2380 - val_accuracy: 0.5278\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3715 - accuracy: 0.8589 - val_loss: 1.2507 - val_accuracy: 0.5208\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.3333 - accuracy: 0.8885 - val_loss: 1.2783 - val_accuracy: 0.5139\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.3219 - accuracy: 0.9042 - val_loss: 1.3230 - val_accuracy: 0.5139\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3538 - accuracy: 0.8763 - val_loss: 1.3184 - val_accuracy: 0.5347\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3140 - accuracy: 0.8972 - val_loss: 1.2996 - val_accuracy: 0.5139\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2815 - accuracy: 0.9077 - val_loss: 1.3105 - val_accuracy: 0.5208\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2945 - accuracy: 0.8972 - val_loss: 1.3598 - val_accuracy: 0.5208\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2935 - accuracy: 0.8798 - val_loss: 1.3605 - val_accuracy: 0.5139\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2735 - accuracy: 0.9094 - val_loss: 1.3635 - val_accuracy: 0.5278\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2507 - accuracy: 0.9199 - val_loss: 1.3735 - val_accuracy: 0.5139\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2788 - accuracy: 0.9059 - val_loss: 1.3807 - val_accuracy: 0.5208\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2530 - accuracy: 0.9233 - val_loss: 1.3997 - val_accuracy: 0.5208\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2289 - accuracy: 0.9268 - val_loss: 1.4263 - val_accuracy: 0.5208\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2258 - accuracy: 0.9303 - val_loss: 1.4137 - val_accuracy: 0.5347\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2659 - accuracy: 0.9042 - val_loss: 1.4361 - val_accuracy: 0.5278\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2505 - accuracy: 0.9251 - val_loss: 1.4324 - val_accuracy: 0.5139\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2219 - accuracy: 0.9286 - val_loss: 1.4714 - val_accuracy: 0.5069\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2343 - accuracy: 0.9181 - val_loss: 1.5083 - val_accuracy: 0.5000\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1965 - accuracy: 0.9425 - val_loss: 1.5284 - val_accuracy: 0.4931\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2053 - accuracy: 0.9338 - val_loss: 1.4675 - val_accuracy: 0.5139\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2012 - accuracy: 0.9355 - val_loss: 1.5111 - val_accuracy: 0.5000\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1852 - accuracy: 0.9443 - val_loss: 1.5515 - val_accuracy: 0.4931\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1707 - accuracy: 0.9564 - val_loss: 1.5638 - val_accuracy: 0.5069\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1587 - accuracy: 0.9477 - val_loss: 1.5736 - val_accuracy: 0.5208\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1861 - accuracy: 0.9408 - val_loss: 1.5709 - val_accuracy: 0.5208\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1575 - accuracy: 0.9495 - val_loss: 1.6086 - val_accuracy: 0.5139\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1700 - accuracy: 0.9425 - val_loss: 1.5992 - val_accuracy: 0.5069\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52d1fd",
   "metadata": {},
   "source": [
    "#### Use different parameters\n",
    "\n",
    "**1. Less unit num in Dense layer**<br>\n",
    "Unit number in Dense layer: 128 -> 64, 64 -> 32\n",
    "\n",
    "Lower complexity of the model improves the validation accuracy a bit and decreases the training validation a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b9cf91a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 14, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 14, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 7, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 64)                14400     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,844\n",
      "Trainable params: 27,684\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 64,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 32,0.2,'relu',0.15\n",
    "num = 5\n",
    "\n",
    "model5 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dabc0eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "36/36 [==============================] - 4s 16ms/step - loss: 1.7212 - accuracy: 0.2578 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.4474 - accuracy: 0.3554 - val_loss: 1.4038 - val_accuracy: 0.2500\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.3423 - accuracy: 0.3693 - val_loss: 1.4203 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.2522 - accuracy: 0.3868 - val_loss: 1.4344 - val_accuracy: 0.2500\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.1984 - accuracy: 0.4373 - val_loss: 1.4410 - val_accuracy: 0.2500\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 1.1457 - accuracy: 0.4774 - val_loss: 1.4414 - val_accuracy: 0.2500\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.1410 - accuracy: 0.4617 - val_loss: 1.4230 - val_accuracy: 0.2500\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.0807 - accuracy: 0.4913 - val_loss: 1.4004 - val_accuracy: 0.2500\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0507 - accuracy: 0.5209 - val_loss: 1.3544 - val_accuracy: 0.2431\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0154 - accuracy: 0.5017 - val_loss: 1.3009 - val_accuracy: 0.3472\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0135 - accuracy: 0.5401 - val_loss: 1.2470 - val_accuracy: 0.4375\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9769 - accuracy: 0.5610 - val_loss: 1.1991 - val_accuracy: 0.4792\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9239 - accuracy: 0.5871 - val_loss: 1.1702 - val_accuracy: 0.5139\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9480 - accuracy: 0.5767 - val_loss: 1.1439 - val_accuracy: 0.5208\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9305 - accuracy: 0.5732 - val_loss: 1.1199 - val_accuracy: 0.5417\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8595 - accuracy: 0.6185 - val_loss: 1.1044 - val_accuracy: 0.5417\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8607 - accuracy: 0.6080 - val_loss: 1.0838 - val_accuracy: 0.5417\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.8746 - accuracy: 0.6115 - val_loss: 1.0782 - val_accuracy: 0.5347\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8506 - accuracy: 0.6289 - val_loss: 1.0837 - val_accuracy: 0.5347\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.8108 - accuracy: 0.6707 - val_loss: 1.0771 - val_accuracy: 0.5347\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8108 - accuracy: 0.6498 - val_loss: 1.0672 - val_accuracy: 0.5486\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8115 - accuracy: 0.6463 - val_loss: 1.0655 - val_accuracy: 0.5556\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7734 - accuracy: 0.7021 - val_loss: 1.0636 - val_accuracy: 0.5417\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.7714 - accuracy: 0.6812 - val_loss: 1.0613 - val_accuracy: 0.5417\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.7446 - accuracy: 0.6794 - val_loss: 1.0748 - val_accuracy: 0.5347\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7293 - accuracy: 0.6934 - val_loss: 1.0604 - val_accuracy: 0.5486\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7206 - accuracy: 0.7056 - val_loss: 1.0714 - val_accuracy: 0.5556\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.7146 - accuracy: 0.7125 - val_loss: 1.0694 - val_accuracy: 0.5556\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6735 - accuracy: 0.7178 - val_loss: 1.0729 - val_accuracy: 0.5625\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6760 - accuracy: 0.7230 - val_loss: 1.0632 - val_accuracy: 0.5486\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.7108 - val_loss: 1.0805 - val_accuracy: 0.5694\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6246 - accuracy: 0.7683 - val_loss: 1.0926 - val_accuracy: 0.5764\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6589 - accuracy: 0.7282 - val_loss: 1.0892 - val_accuracy: 0.5625\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.6260 - accuracy: 0.7544 - val_loss: 1.0868 - val_accuracy: 0.5347\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6104 - accuracy: 0.7544 - val_loss: 1.0867 - val_accuracy: 0.5694\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6323 - accuracy: 0.7247 - val_loss: 1.1012 - val_accuracy: 0.5764\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6080 - accuracy: 0.7509 - val_loss: 1.0848 - val_accuracy: 0.5347\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.5964 - accuracy: 0.7561 - val_loss: 1.1151 - val_accuracy: 0.5694\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.5643 - accuracy: 0.7805 - val_loss: 1.1234 - val_accuracy: 0.5764\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5839 - accuracy: 0.7753 - val_loss: 1.1196 - val_accuracy: 0.5764\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5478 - accuracy: 0.7997 - val_loss: 1.1273 - val_accuracy: 0.5764\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5401 - accuracy: 0.7997 - val_loss: 1.1336 - val_accuracy: 0.5833\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.5322 - accuracy: 0.8066 - val_loss: 1.1246 - val_accuracy: 0.5486\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.5239 - accuracy: 0.8031 - val_loss: 1.1414 - val_accuracy: 0.5694\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5052 - accuracy: 0.8066 - val_loss: 1.1543 - val_accuracy: 0.5556\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5015 - accuracy: 0.8101 - val_loss: 1.1582 - val_accuracy: 0.5764\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.4696 - accuracy: 0.8258 - val_loss: 1.1545 - val_accuracy: 0.5694\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4795 - accuracy: 0.8258 - val_loss: 1.1868 - val_accuracy: 0.5694\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.4376 - accuracy: 0.8415 - val_loss: 1.1749 - val_accuracy: 0.5486\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8310 - val_loss: 1.1679 - val_accuracy: 0.5486\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8659 - val_loss: 1.1909 - val_accuracy: 0.5486\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8328 - val_loss: 1.1908 - val_accuracy: 0.5556\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.4547 - accuracy: 0.8293 - val_loss: 1.2065 - val_accuracy: 0.5694\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8519 - val_loss: 1.1926 - val_accuracy: 0.5625\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8380 - val_loss: 1.2118 - val_accuracy: 0.5417\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.8641 - val_loss: 1.2197 - val_accuracy: 0.5556\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3872 - accuracy: 0.8693 - val_loss: 1.2309 - val_accuracy: 0.5556\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.3660 - accuracy: 0.8676 - val_loss: 1.2754 - val_accuracy: 0.5556\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8676 - val_loss: 1.2814 - val_accuracy: 0.5556\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.9007 - val_loss: 1.3074 - val_accuracy: 0.5625\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3190 - accuracy: 0.9007 - val_loss: 1.2790 - val_accuracy: 0.5556\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.3378 - accuracy: 0.8902 - val_loss: 1.3085 - val_accuracy: 0.5556\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3038 - accuracy: 0.8920 - val_loss: 1.3007 - val_accuracy: 0.5625\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3102 - accuracy: 0.9007 - val_loss: 1.3159 - val_accuracy: 0.5347\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2798 - accuracy: 0.9129 - val_loss: 1.3408 - val_accuracy: 0.5347\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8972 - val_loss: 1.3209 - val_accuracy: 0.5208\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2662 - accuracy: 0.9321 - val_loss: 1.3501 - val_accuracy: 0.5347\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2963 - accuracy: 0.9042 - val_loss: 1.3889 - val_accuracy: 0.5625\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2845 - accuracy: 0.9042 - val_loss: 1.3485 - val_accuracy: 0.5347\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2799 - accuracy: 0.9059 - val_loss: 1.3769 - val_accuracy: 0.5347\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2746 - accuracy: 0.9129 - val_loss: 1.4057 - val_accuracy: 0.5486\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2561 - accuracy: 0.9216 - val_loss: 1.4036 - val_accuracy: 0.5069\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2450 - accuracy: 0.9251 - val_loss: 1.4521 - val_accuracy: 0.5486\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2507 - accuracy: 0.9216 - val_loss: 1.4356 - val_accuracy: 0.5347\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2326 - accuracy: 0.9321 - val_loss: 1.4215 - val_accuracy: 0.5347\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2273 - accuracy: 0.9268 - val_loss: 1.4409 - val_accuracy: 0.5278\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2200 - accuracy: 0.9321 - val_loss: 1.4507 - val_accuracy: 0.5278\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2304 - accuracy: 0.9286 - val_loss: 1.4964 - val_accuracy: 0.5417\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2306 - accuracy: 0.9338 - val_loss: 1.4999 - val_accuracy: 0.5486\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2295 - accuracy: 0.9233 - val_loss: 1.5437 - val_accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1efe6",
   "metadata": {},
   "source": [
    "Then, try: <br>\n",
    "Unit number of Dense layers: 128 -> 32, 64 -> 16\n",
    "\n",
    "\n",
    "But this way is unable to improve the model validation accuracy prominently but sacrifices the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d78cb1e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 14, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 14, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 7, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 32)                7200      \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,028\n",
      "Trainable params: 18,868\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 32,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 16,0.2,'relu',0.15\n",
    "num = 5\n",
    "\n",
    "model5 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,                            \n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,                               \n",
    "                        d1,dr1,da1,r1,                        \n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c642b5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 19ms/step - loss: 2.0124 - accuracy: 0.2648 - val_loss: 1.3921 - val_accuracy: 0.2500\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.5208 - accuracy: 0.3153 - val_loss: 1.4192 - val_accuracy: 0.2500\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 1.3808 - accuracy: 0.3693 - val_loss: 1.4607 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 1.3449 - accuracy: 0.3798 - val_loss: 1.5071 - val_accuracy: 0.2500\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.2482 - accuracy: 0.4181 - val_loss: 1.5381 - val_accuracy: 0.2500\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.2243 - accuracy: 0.4286 - val_loss: 1.5602 - val_accuracy: 0.2500\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.1422 - accuracy: 0.4826 - val_loss: 1.5528 - val_accuracy: 0.2500\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.1259 - accuracy: 0.4861 - val_loss: 1.5291 - val_accuracy: 0.2500\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0692 - accuracy: 0.5017 - val_loss: 1.4968 - val_accuracy: 0.2500\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0940 - accuracy: 0.5296 - val_loss: 1.4518 - val_accuracy: 0.2639\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 1.0682 - accuracy: 0.5348 - val_loss: 1.3932 - val_accuracy: 0.2847\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0396 - accuracy: 0.5314 - val_loss: 1.3338 - val_accuracy: 0.3125\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0249 - accuracy: 0.5401 - val_loss: 1.2591 - val_accuracy: 0.4167\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.9857 - accuracy: 0.6010 - val_loss: 1.2110 - val_accuracy: 0.4583\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.9720 - accuracy: 0.5662 - val_loss: 1.1834 - val_accuracy: 0.5069\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.9508 - accuracy: 0.5958 - val_loss: 1.1669 - val_accuracy: 0.5208\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.9056 - accuracy: 0.6115 - val_loss: 1.1591 - val_accuracy: 0.5069\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.9035 - accuracy: 0.6254 - val_loss: 1.1710 - val_accuracy: 0.4792\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.9132 - accuracy: 0.6132 - val_loss: 1.1726 - val_accuracy: 0.4792\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8818 - accuracy: 0.6220 - val_loss: 1.1715 - val_accuracy: 0.4792\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8866 - accuracy: 0.6080 - val_loss: 1.1626 - val_accuracy: 0.4792\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8750 - accuracy: 0.6202 - val_loss: 1.1651 - val_accuracy: 0.4792\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.8473 - accuracy: 0.6707 - val_loss: 1.1659 - val_accuracy: 0.4653\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.8501 - accuracy: 0.6254 - val_loss: 1.1751 - val_accuracy: 0.4722\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8056 - accuracy: 0.6847 - val_loss: 1.1841 - val_accuracy: 0.4653\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8395 - accuracy: 0.6498 - val_loss: 1.2002 - val_accuracy: 0.4653\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7560 - accuracy: 0.6969 - val_loss: 1.1903 - val_accuracy: 0.4583\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.7965 - accuracy: 0.6777 - val_loss: 1.1934 - val_accuracy: 0.4722\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8014 - accuracy: 0.6672 - val_loss: 1.1835 - val_accuracy: 0.4653\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7662 - accuracy: 0.6899 - val_loss: 1.1862 - val_accuracy: 0.4861\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7630 - accuracy: 0.6847 - val_loss: 1.1855 - val_accuracy: 0.4514\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8056 - accuracy: 0.6516 - val_loss: 1.2107 - val_accuracy: 0.4444\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7505 - accuracy: 0.6794 - val_loss: 1.1784 - val_accuracy: 0.4792\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.7201 - accuracy: 0.7108 - val_loss: 1.1980 - val_accuracy: 0.4861\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.7178 - val_loss: 1.2163 - val_accuracy: 0.4722\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7176 - accuracy: 0.7003 - val_loss: 1.2029 - val_accuracy: 0.4931\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6829 - accuracy: 0.7317 - val_loss: 1.1987 - val_accuracy: 0.5000\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.7244 - accuracy: 0.7195 - val_loss: 1.1878 - val_accuracy: 0.4722\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.7040 - accuracy: 0.7178 - val_loss: 1.1655 - val_accuracy: 0.4861\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6598 - accuracy: 0.7247 - val_loss: 1.1858 - val_accuracy: 0.4861\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6797 - accuracy: 0.7422 - val_loss: 1.1833 - val_accuracy: 0.5000\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6578 - accuracy: 0.7265 - val_loss: 1.1863 - val_accuracy: 0.4792\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6380 - accuracy: 0.7509 - val_loss: 1.1893 - val_accuracy: 0.4931\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6459 - accuracy: 0.7509 - val_loss: 1.2016 - val_accuracy: 0.4931\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.6165 - accuracy: 0.7526 - val_loss: 1.1931 - val_accuracy: 0.4861\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5915 - accuracy: 0.7822 - val_loss: 1.2085 - val_accuracy: 0.5069\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6183 - accuracy: 0.7456 - val_loss: 1.1798 - val_accuracy: 0.5000\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6023 - accuracy: 0.7596 - val_loss: 1.1705 - val_accuracy: 0.5208\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.7334 - val_loss: 1.1648 - val_accuracy: 0.5069\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5627 - accuracy: 0.7840 - val_loss: 1.1941 - val_accuracy: 0.5000\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.5595 - accuracy: 0.7857 - val_loss: 1.1940 - val_accuracy: 0.5139\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5947 - accuracy: 0.7753 - val_loss: 1.2052 - val_accuracy: 0.5069\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5575 - accuracy: 0.7997 - val_loss: 1.2007 - val_accuracy: 0.5069\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.5673 - accuracy: 0.7944 - val_loss: 1.2281 - val_accuracy: 0.5000\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.5317 - accuracy: 0.7805 - val_loss: 1.1772 - val_accuracy: 0.5139\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.5110 - accuracy: 0.8136 - val_loss: 1.1958 - val_accuracy: 0.5208\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5118 - accuracy: 0.7892 - val_loss: 1.2007 - val_accuracy: 0.5278\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5400 - accuracy: 0.7909 - val_loss: 1.2036 - val_accuracy: 0.5208\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5199 - accuracy: 0.8066 - val_loss: 1.2244 - val_accuracy: 0.5139\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5174 - accuracy: 0.7979 - val_loss: 1.2054 - val_accuracy: 0.5278\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.5200 - accuracy: 0.7822 - val_loss: 1.2357 - val_accuracy: 0.5139\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.8275 - val_loss: 1.2303 - val_accuracy: 0.5208\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4876 - accuracy: 0.8031 - val_loss: 1.2045 - val_accuracy: 0.5278\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.8240 - val_loss: 1.2108 - val_accuracy: 0.5278\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.8362 - val_loss: 1.2057 - val_accuracy: 0.5417\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.5012 - accuracy: 0.8206 - val_loss: 1.2076 - val_accuracy: 0.5278\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.4309 - accuracy: 0.8537 - val_loss: 1.2327 - val_accuracy: 0.5347\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.4473 - accuracy: 0.8415 - val_loss: 1.1897 - val_accuracy: 0.5556\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.8293 - val_loss: 1.2156 - val_accuracy: 0.5556\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.8345 - val_loss: 1.2082 - val_accuracy: 0.5556\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.4410 - accuracy: 0.8171 - val_loss: 1.2301 - val_accuracy: 0.5556\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.8484 - val_loss: 1.2606 - val_accuracy: 0.5347\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4258 - accuracy: 0.8362 - val_loss: 1.2712 - val_accuracy: 0.5417\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.8380 - val_loss: 1.2830 - val_accuracy: 0.5486\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8397 - val_loss: 1.2508 - val_accuracy: 0.5486\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3535 - accuracy: 0.8885 - val_loss: 1.3066 - val_accuracy: 0.5486\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.3898 - accuracy: 0.8641 - val_loss: 1.2893 - val_accuracy: 0.5486\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.3776 - accuracy: 0.8571 - val_loss: 1.3147 - val_accuracy: 0.5486\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3617 - accuracy: 0.8728 - val_loss: 1.3047 - val_accuracy: 0.5694\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.3623 - accuracy: 0.8571 - val_loss: 1.2784 - val_accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c949242",
   "metadata": {},
   "source": [
    "**Different num of filters and kernel size**<br>\n",
    "- f1,k1: 16,5 -> 8,3\n",
    "- f2,k2: 32,7 -> 16,5\n",
    "- f3,k3: 32,7 -> 16,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0357b4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 8)             32        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 8)             32        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 8)             0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 16)            656       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 14, 16)            1296      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 14, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 7, 16)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 112)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               14464     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,124\n",
      "Trainable params: 25,044\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 8,3,'relu'\n",
    "f2,k2,a2 = 16,5,'relu'\n",
    "f3,k3,a3 = 16,5,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 6\n",
    "\n",
    "model6 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00148418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "36/36 [==============================] - 4s 20ms/step - loss: 1.7415 - accuracy: 0.2561 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.5137 - accuracy: 0.3136 - val_loss: 1.3908 - val_accuracy: 0.2500\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.4408 - accuracy: 0.3310 - val_loss: 1.3954 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.3487 - accuracy: 0.3780 - val_loss: 1.3991 - val_accuracy: 0.2500\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.3374 - accuracy: 0.3902 - val_loss: 1.4046 - val_accuracy: 0.2500\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.2676 - accuracy: 0.4408 - val_loss: 1.4076 - val_accuracy: 0.2500\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.2440 - accuracy: 0.4338 - val_loss: 1.4014 - val_accuracy: 0.2569\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.2088 - accuracy: 0.4617 - val_loss: 1.3907 - val_accuracy: 0.2917\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.2066 - accuracy: 0.4477 - val_loss: 1.3752 - val_accuracy: 0.2778\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.1585 - accuracy: 0.4634 - val_loss: 1.3498 - val_accuracy: 0.2847\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.1530 - accuracy: 0.5070 - val_loss: 1.3268 - val_accuracy: 0.2778\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.1312 - accuracy: 0.4930 - val_loss: 1.2971 - val_accuracy: 0.3472\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0700 - accuracy: 0.5105 - val_loss: 1.2671 - val_accuracy: 0.4514\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 1.0614 - accuracy: 0.5348 - val_loss: 1.2363 - val_accuracy: 0.4444\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9965 - accuracy: 0.5505 - val_loss: 1.2093 - val_accuracy: 0.4375\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0307 - accuracy: 0.5505 - val_loss: 1.1851 - val_accuracy: 0.4306\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0384 - accuracy: 0.5348 - val_loss: 1.1612 - val_accuracy: 0.4514\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9938 - accuracy: 0.5436 - val_loss: 1.1402 - val_accuracy: 0.4583\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9918 - accuracy: 0.5767 - val_loss: 1.1265 - val_accuracy: 0.4792\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.9639 - accuracy: 0.5714 - val_loss: 1.1198 - val_accuracy: 0.4722\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9554 - accuracy: 0.5871 - val_loss: 1.1167 - val_accuracy: 0.4653\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9501 - accuracy: 0.5732 - val_loss: 1.1095 - val_accuracy: 0.4861\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9005 - accuracy: 0.6150 - val_loss: 1.1108 - val_accuracy: 0.4792\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9228 - accuracy: 0.5871 - val_loss: 1.1035 - val_accuracy: 0.5000\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.8927 - accuracy: 0.5993 - val_loss: 1.1007 - val_accuracy: 0.5000\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8806 - accuracy: 0.6237 - val_loss: 1.0991 - val_accuracy: 0.5069\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8623 - accuracy: 0.6115 - val_loss: 1.0969 - val_accuracy: 0.5000\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8474 - accuracy: 0.6394 - val_loss: 1.1032 - val_accuracy: 0.4931\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8448 - accuracy: 0.6481 - val_loss: 1.1052 - val_accuracy: 0.5000\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8339 - accuracy: 0.6307 - val_loss: 1.1033 - val_accuracy: 0.5000\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7806 - accuracy: 0.6498 - val_loss: 1.1015 - val_accuracy: 0.5069\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.6742 - val_loss: 1.1029 - val_accuracy: 0.4861\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7755 - accuracy: 0.6672 - val_loss: 1.1029 - val_accuracy: 0.4861\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7708 - accuracy: 0.6638 - val_loss: 1.1074 - val_accuracy: 0.4931\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7398 - accuracy: 0.6777 - val_loss: 1.1095 - val_accuracy: 0.4861\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7510 - accuracy: 0.6655 - val_loss: 1.1069 - val_accuracy: 0.5000\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.8050 - accuracy: 0.6446 - val_loss: 1.1030 - val_accuracy: 0.5069\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7263 - accuracy: 0.7003 - val_loss: 1.1035 - val_accuracy: 0.5069\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7439 - accuracy: 0.6829 - val_loss: 1.1103 - val_accuracy: 0.4931\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7288 - accuracy: 0.6812 - val_loss: 1.1158 - val_accuracy: 0.5000\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7067 - accuracy: 0.6847 - val_loss: 1.1213 - val_accuracy: 0.4653\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.6981 - accuracy: 0.7125 - val_loss: 1.1279 - val_accuracy: 0.5069\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6831 - accuracy: 0.7230 - val_loss: 1.1312 - val_accuracy: 0.5069\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6559 - accuracy: 0.7491 - val_loss: 1.1333 - val_accuracy: 0.4861\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6567 - accuracy: 0.7491 - val_loss: 1.1276 - val_accuracy: 0.5069\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6335 - accuracy: 0.7613 - val_loss: 1.1311 - val_accuracy: 0.5139\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6403 - accuracy: 0.7491 - val_loss: 1.1279 - val_accuracy: 0.5000\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.6154 - accuracy: 0.7439 - val_loss: 1.1269 - val_accuracy: 0.5069\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.6356 - accuracy: 0.7334 - val_loss: 1.1425 - val_accuracy: 0.4722\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6156 - accuracy: 0.7544 - val_loss: 1.1494 - val_accuracy: 0.4653\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5936 - accuracy: 0.7753 - val_loss: 1.1603 - val_accuracy: 0.4514\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5858 - accuracy: 0.7770 - val_loss: 1.1662 - val_accuracy: 0.4583\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.5838 - accuracy: 0.7787 - val_loss: 1.1574 - val_accuracy: 0.4792\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5856 - accuracy: 0.7700 - val_loss: 1.1581 - val_accuracy: 0.4792\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5846 - accuracy: 0.7787 - val_loss: 1.1636 - val_accuracy: 0.4653\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5662 - accuracy: 0.7753 - val_loss: 1.1683 - val_accuracy: 0.4653\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5566 - accuracy: 0.7718 - val_loss: 1.1690 - val_accuracy: 0.4722\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5513 - accuracy: 0.7875 - val_loss: 1.1827 - val_accuracy: 0.4722\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5432 - accuracy: 0.7787 - val_loss: 1.1761 - val_accuracy: 0.4792\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5360 - accuracy: 0.7875 - val_loss: 1.1831 - val_accuracy: 0.4653\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.8031 - val_loss: 1.1842 - val_accuracy: 0.4792\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5254 - accuracy: 0.7857 - val_loss: 1.1886 - val_accuracy: 0.4861\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.8031 - val_loss: 1.1835 - val_accuracy: 0.4861\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.8188 - val_loss: 1.1837 - val_accuracy: 0.4792\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.8031 - val_loss: 1.2056 - val_accuracy: 0.4792\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.8223 - val_loss: 1.2154 - val_accuracy: 0.4722\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.8467 - val_loss: 1.2246 - val_accuracy: 0.4792\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.8484 - val_loss: 1.2335 - val_accuracy: 0.4792\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.8328 - val_loss: 1.2296 - val_accuracy: 0.4792\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8432 - val_loss: 1.2487 - val_accuracy: 0.4861\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.8484 - val_loss: 1.2570 - val_accuracy: 0.4792\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.8502 - val_loss: 1.2563 - val_accuracy: 0.4792\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8415 - val_loss: 1.2634 - val_accuracy: 0.4792\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.4431 - accuracy: 0.8293 - val_loss: 1.2752 - val_accuracy: 0.4792\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.4127 - accuracy: 0.8397 - val_loss: 1.2829 - val_accuracy: 0.4583\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.8449 - val_loss: 1.2827 - val_accuracy: 0.4722\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8240 - val_loss: 1.2804 - val_accuracy: 0.4722\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.4055 - accuracy: 0.8571 - val_loss: 1.2893 - val_accuracy: 0.4722\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8589 - val_loss: 1.2983 - val_accuracy: 0.4722\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8606 - val_loss: 1.3079 - val_accuracy: 0.4653\n"
     ]
    }
   ],
   "source": [
    "history6 = model6.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd33b1e6",
   "metadata": {},
   "source": [
    "- f1,k1: 16,5 -> 8,3\n",
    "- f2,k2: 32,7 -> 16,5\n",
    "- f3,k3: 32,7 -> 32,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb3a20cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 8)             32        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 8)             32        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 8)             0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 16)            656       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 14, 32)            3616      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 14, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 7, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               28800     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,844\n",
      "Trainable params: 41,732\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 8,3,'relu'\n",
    "f2,k2,a2 = 16,5,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 7\n",
    "\n",
    "model7 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd93420f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 4s 16ms/step - loss: 1.9321 - accuracy: 0.2491 - val_loss: 1.3883 - val_accuracy: 0.2847\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.5014 - accuracy: 0.3223 - val_loss: 1.3969 - val_accuracy: 0.2778\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.3571 - accuracy: 0.3937 - val_loss: 1.4006 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.2451 - accuracy: 0.4669 - val_loss: 1.4028 - val_accuracy: 0.2569\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.1672 - accuracy: 0.4721 - val_loss: 1.4126 - val_accuracy: 0.2708\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.1196 - accuracy: 0.5192 - val_loss: 1.4170 - val_accuracy: 0.2639\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0369 - accuracy: 0.5436 - val_loss: 1.4052 - val_accuracy: 0.2569\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0698 - accuracy: 0.5279 - val_loss: 1.3877 - val_accuracy: 0.2778\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0000 - accuracy: 0.5505 - val_loss: 1.3641 - val_accuracy: 0.2847\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.9761 - accuracy: 0.5819 - val_loss: 1.3242 - val_accuracy: 0.3611\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9568 - accuracy: 0.5993 - val_loss: 1.2791 - val_accuracy: 0.3750\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9521 - accuracy: 0.5923 - val_loss: 1.2273 - val_accuracy: 0.4514\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8873 - accuracy: 0.6429 - val_loss: 1.1858 - val_accuracy: 0.4792\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.8745 - accuracy: 0.6359 - val_loss: 1.1523 - val_accuracy: 0.5208\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.8323 - accuracy: 0.6568 - val_loss: 1.1417 - val_accuracy: 0.5208\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.8116 - accuracy: 0.6899 - val_loss: 1.1320 - val_accuracy: 0.4792\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7903 - accuracy: 0.6603 - val_loss: 1.1372 - val_accuracy: 0.4931\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7671 - accuracy: 0.6794 - val_loss: 1.1281 - val_accuracy: 0.4583\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7966 - accuracy: 0.6829 - val_loss: 1.1412 - val_accuracy: 0.4583\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.7695 - accuracy: 0.6829 - val_loss: 1.1345 - val_accuracy: 0.4722\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7181 - accuracy: 0.7317 - val_loss: 1.1405 - val_accuracy: 0.4792\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7289 - accuracy: 0.7143 - val_loss: 1.1485 - val_accuracy: 0.4931\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7158 - accuracy: 0.7038 - val_loss: 1.1514 - val_accuracy: 0.4792\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6722 - accuracy: 0.7300 - val_loss: 1.1427 - val_accuracy: 0.4653\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.6968 - accuracy: 0.7160 - val_loss: 1.1401 - val_accuracy: 0.4792\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6643 - accuracy: 0.7265 - val_loss: 1.1530 - val_accuracy: 0.4722\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6299 - accuracy: 0.7404 - val_loss: 1.1589 - val_accuracy: 0.4792\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6136 - accuracy: 0.7683 - val_loss: 1.1502 - val_accuracy: 0.4792\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6059 - accuracy: 0.7648 - val_loss: 1.1619 - val_accuracy: 0.4583\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.6082 - accuracy: 0.7700 - val_loss: 1.1882 - val_accuracy: 0.4653\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6187 - accuracy: 0.7631 - val_loss: 1.1778 - val_accuracy: 0.4444\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5863 - accuracy: 0.7718 - val_loss: 1.1678 - val_accuracy: 0.4583\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5687 - accuracy: 0.7787 - val_loss: 1.1831 - val_accuracy: 0.4514\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.7805 - val_loss: 1.1872 - val_accuracy: 0.4792\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5528 - accuracy: 0.7927 - val_loss: 1.2223 - val_accuracy: 0.4792\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.5357 - accuracy: 0.8014 - val_loss: 1.2145 - val_accuracy: 0.4861\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5608 - accuracy: 0.7770 - val_loss: 1.2299 - val_accuracy: 0.4653\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5049 - accuracy: 0.8223 - val_loss: 1.2155 - val_accuracy: 0.4861\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 0.8258 - val_loss: 1.2217 - val_accuracy: 0.4722\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.8275 - val_loss: 1.2734 - val_accuracy: 0.4792\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.4988 - accuracy: 0.8206 - val_loss: 1.2755 - val_accuracy: 0.4722\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4832 - accuracy: 0.8084 - val_loss: 1.2596 - val_accuracy: 0.4722\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8240 - val_loss: 1.2690 - val_accuracy: 0.4792\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.8362 - val_loss: 1.2704 - val_accuracy: 0.4722\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4531 - accuracy: 0.8293 - val_loss: 1.2640 - val_accuracy: 0.4792\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.8798 - val_loss: 1.3113 - val_accuracy: 0.4861\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.8537 - val_loss: 1.2638 - val_accuracy: 0.4792\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8693 - val_loss: 1.2881 - val_accuracy: 0.4792\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8502 - val_loss: 1.2939 - val_accuracy: 0.4861\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8624 - val_loss: 1.2908 - val_accuracy: 0.4722\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3666 - accuracy: 0.8850 - val_loss: 1.3075 - val_accuracy: 0.4792\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8746 - val_loss: 1.3203 - val_accuracy: 0.4861\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.3350 - accuracy: 0.8833 - val_loss: 1.3278 - val_accuracy: 0.4861\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8589 - val_loss: 1.3074 - val_accuracy: 0.4861\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.9042 - val_loss: 1.3360 - val_accuracy: 0.5000\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3250 - accuracy: 0.8850 - val_loss: 1.3524 - val_accuracy: 0.4931\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.3263 - accuracy: 0.9024 - val_loss: 1.3591 - val_accuracy: 0.4931\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3389 - accuracy: 0.8833 - val_loss: 1.3480 - val_accuracy: 0.4931\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3061 - accuracy: 0.8868 - val_loss: 1.3804 - val_accuracy: 0.4931\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3008 - accuracy: 0.9059 - val_loss: 1.3983 - val_accuracy: 0.4931\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3152 - accuracy: 0.8833 - val_loss: 1.3891 - val_accuracy: 0.5000\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.3036 - accuracy: 0.9007 - val_loss: 1.4253 - val_accuracy: 0.4861\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2903 - accuracy: 0.9129 - val_loss: 1.4018 - val_accuracy: 0.4722\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2523 - accuracy: 0.9233 - val_loss: 1.3968 - val_accuracy: 0.4861\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2708 - accuracy: 0.9164 - val_loss: 1.4131 - val_accuracy: 0.4861\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2628 - accuracy: 0.9181 - val_loss: 1.4734 - val_accuracy: 0.4931\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2579 - accuracy: 0.9164 - val_loss: 1.4409 - val_accuracy: 0.4931\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2555 - accuracy: 0.9199 - val_loss: 1.4450 - val_accuracy: 0.4931\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2239 - accuracy: 0.9408 - val_loss: 1.4165 - val_accuracy: 0.4792\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9355 - val_loss: 1.4764 - val_accuracy: 0.4861\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2255 - accuracy: 0.9408 - val_loss: 1.4852 - val_accuracy: 0.4792\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2348 - accuracy: 0.9251 - val_loss: 1.4905 - val_accuracy: 0.4861\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2259 - accuracy: 0.9199 - val_loss: 1.5318 - val_accuracy: 0.4931\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2049 - accuracy: 0.9355 - val_loss: 1.5025 - val_accuracy: 0.4861\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2678 - accuracy: 0.8955 - val_loss: 1.5020 - val_accuracy: 0.4792\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1956 - accuracy: 0.9338 - val_loss: 1.5225 - val_accuracy: 0.4722\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2089 - accuracy: 0.9390 - val_loss: 1.5152 - val_accuracy: 0.4931\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1756 - accuracy: 0.9460 - val_loss: 1.5643 - val_accuracy: 0.4861\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1871 - accuracy: 0.9495 - val_loss: 1.5318 - val_accuracy: 0.4792\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1581 - accuracy: 0.9547 - val_loss: 1.5546 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history7 = model7.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d1c7f",
   "metadata": {},
   "source": [
    "- f1,k1: 16,5 -> 16,5\n",
    "- f2,k2: 32,7 -> 16,5\n",
    "- f3,k3: 32,7 -> 32,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2bf3529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 16)            1296      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 14, 32)            3616      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 14, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 7, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               28800     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,580\n",
      "Trainable params: 42,452\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 16,5,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 8\n",
    "\n",
    "model8 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5549275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "36/36 [==============================] - 4s 17ms/step - loss: 1.8454 - accuracy: 0.3101 - val_loss: 1.3850 - val_accuracy: 0.3056\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.5018 - accuracy: 0.3328 - val_loss: 1.3802 - val_accuracy: 0.2500\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.3094 - accuracy: 0.4530 - val_loss: 1.3748 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.2331 - accuracy: 0.4425 - val_loss: 1.3702 - val_accuracy: 0.2569\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.1518 - accuracy: 0.4721 - val_loss: 1.3699 - val_accuracy: 0.2222\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.1214 - accuracy: 0.5052 - val_loss: 1.3691 - val_accuracy: 0.2222\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0534 - accuracy: 0.5279 - val_loss: 1.3634 - val_accuracy: 0.2569\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9947 - accuracy: 0.5697 - val_loss: 1.3447 - val_accuracy: 0.2708\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9815 - accuracy: 0.5714 - val_loss: 1.3120 - val_accuracy: 0.2708\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9322 - accuracy: 0.6115 - val_loss: 1.2606 - val_accuracy: 0.3403\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9045 - accuracy: 0.6272 - val_loss: 1.2150 - val_accuracy: 0.3681\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.9034 - accuracy: 0.6028 - val_loss: 1.1813 - val_accuracy: 0.4028\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8728 - accuracy: 0.6167 - val_loss: 1.1433 - val_accuracy: 0.4583\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8447 - accuracy: 0.6672 - val_loss: 1.1187 - val_accuracy: 0.4306\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7777 - accuracy: 0.6986 - val_loss: 1.0858 - val_accuracy: 0.4375\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7932 - accuracy: 0.6812 - val_loss: 1.0614 - val_accuracy: 0.4514\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.7968 - accuracy: 0.6742 - val_loss: 1.0541 - val_accuracy: 0.4722\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7631 - accuracy: 0.7003 - val_loss: 1.0516 - val_accuracy: 0.4792\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7361 - accuracy: 0.6847 - val_loss: 1.0576 - val_accuracy: 0.4931\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.7382 - accuracy: 0.6777 - val_loss: 1.0620 - val_accuracy: 0.5000\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7242 - accuracy: 0.7003 - val_loss: 1.0601 - val_accuracy: 0.5208\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6951 - accuracy: 0.7178 - val_loss: 1.0619 - val_accuracy: 0.4861\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6608 - accuracy: 0.7178 - val_loss: 1.0595 - val_accuracy: 0.4931\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6223 - accuracy: 0.7474 - val_loss: 1.0582 - val_accuracy: 0.4861\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6259 - accuracy: 0.7439 - val_loss: 1.0665 - val_accuracy: 0.5000\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6177 - accuracy: 0.7666 - val_loss: 1.0822 - val_accuracy: 0.5069\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.7700 - val_loss: 1.0794 - val_accuracy: 0.5208\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.6066 - accuracy: 0.7666 - val_loss: 1.0795 - val_accuracy: 0.5069\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.5929 - accuracy: 0.7805 - val_loss: 1.0813 - val_accuracy: 0.4931\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7666 - val_loss: 1.0968 - val_accuracy: 0.4861\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5532 - accuracy: 0.7997 - val_loss: 1.0783 - val_accuracy: 0.4861\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.5407 - accuracy: 0.8066 - val_loss: 1.0980 - val_accuracy: 0.4931\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5311 - accuracy: 0.7962 - val_loss: 1.1139 - val_accuracy: 0.4931\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.8310 - val_loss: 1.1177 - val_accuracy: 0.4931\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4825 - accuracy: 0.8310 - val_loss: 1.1094 - val_accuracy: 0.4792\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4814 - accuracy: 0.8293 - val_loss: 1.1411 - val_accuracy: 0.5069\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4604 - accuracy: 0.8432 - val_loss: 1.1408 - val_accuracy: 0.5139\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.4561 - accuracy: 0.8328 - val_loss: 1.1483 - val_accuracy: 0.5139\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.4634 - accuracy: 0.8206 - val_loss: 1.1509 - val_accuracy: 0.5139\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.8449 - val_loss: 1.1698 - val_accuracy: 0.5139\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.8397 - val_loss: 1.1554 - val_accuracy: 0.5069\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.4311 - accuracy: 0.8310 - val_loss: 1.1697 - val_accuracy: 0.5069\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8432 - val_loss: 1.1729 - val_accuracy: 0.5069\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.8746 - val_loss: 1.1701 - val_accuracy: 0.4861\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8537 - val_loss: 1.1929 - val_accuracy: 0.5069\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8711 - val_loss: 1.2167 - val_accuracy: 0.5139\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3695 - accuracy: 0.8868 - val_loss: 1.2313 - val_accuracy: 0.5139\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3416 - accuracy: 0.8746 - val_loss: 1.2371 - val_accuracy: 0.5069\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3530 - accuracy: 0.8589 - val_loss: 1.2295 - val_accuracy: 0.5278\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8833 - val_loss: 1.2264 - val_accuracy: 0.5000\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3017 - accuracy: 0.8937 - val_loss: 1.2364 - val_accuracy: 0.5208\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8920 - val_loss: 1.2758 - val_accuracy: 0.5069\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2923 - accuracy: 0.8955 - val_loss: 1.2889 - val_accuracy: 0.5000\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2883 - accuracy: 0.8972 - val_loss: 1.2940 - val_accuracy: 0.5000\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2844 - accuracy: 0.9181 - val_loss: 1.3402 - val_accuracy: 0.4861\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2908 - accuracy: 0.8990 - val_loss: 1.3522 - val_accuracy: 0.5069\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2882 - accuracy: 0.9007 - val_loss: 1.3226 - val_accuracy: 0.5208\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3004 - accuracy: 0.9059 - val_loss: 1.3589 - val_accuracy: 0.5069\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2473 - accuracy: 0.9251 - val_loss: 1.3732 - val_accuracy: 0.5069\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2694 - accuracy: 0.9181 - val_loss: 1.3654 - val_accuracy: 0.5069\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2519 - accuracy: 0.9303 - val_loss: 1.4033 - val_accuracy: 0.5069\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.2361 - accuracy: 0.9233 - val_loss: 1.4449 - val_accuracy: 0.4861\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2379 - accuracy: 0.9164 - val_loss: 1.4728 - val_accuracy: 0.4792\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2326 - accuracy: 0.9251 - val_loss: 1.4099 - val_accuracy: 0.4931\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2093 - accuracy: 0.9390 - val_loss: 1.5033 - val_accuracy: 0.4792\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2312 - accuracy: 0.9146 - val_loss: 1.4734 - val_accuracy: 0.5000\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2044 - accuracy: 0.9408 - val_loss: 1.4674 - val_accuracy: 0.4931\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1934 - accuracy: 0.9390 - val_loss: 1.4957 - val_accuracy: 0.5069\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1966 - accuracy: 0.9286 - val_loss: 1.4562 - val_accuracy: 0.4931\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1932 - accuracy: 0.9303 - val_loss: 1.4812 - val_accuracy: 0.4931\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1706 - accuracy: 0.9443 - val_loss: 1.5312 - val_accuracy: 0.4861\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1730 - accuracy: 0.9495 - val_loss: 1.5325 - val_accuracy: 0.4931\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1622 - accuracy: 0.9547 - val_loss: 1.6094 - val_accuracy: 0.4931\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1635 - accuracy: 0.9599 - val_loss: 1.6091 - val_accuracy: 0.4861\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1515 - accuracy: 0.9512 - val_loss: 1.6332 - val_accuracy: 0.5000\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1444 - accuracy: 0.9704 - val_loss: 1.6184 - val_accuracy: 0.4583\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1326 - accuracy: 0.9652 - val_loss: 1.6351 - val_accuracy: 0.4861\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1370 - accuracy: 0.9652 - val_loss: 1.6258 - val_accuracy: 0.4861\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1373 - accuracy: 0.9617 - val_loss: 1.6751 - val_accuracy: 0.4722\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1320 - accuracy: 0.9686 - val_loss: 1.7234 - val_accuracy: 0.4931\n"
     ]
    }
   ],
   "source": [
    "history8 = model8.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133387af",
   "metadata": {},
   "source": [
    "**Simplify the networks**</br>\n",
    "Overfitting problems might be due to the complexity of the neural networks. Here only 2 conv2D layers are used, decreasing 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "352aeb23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def modelBuilder2L(X_train,\n",
    "                   f1,k1,a1,\n",
    "                   f2,k2,a2,                \n",
    "                   d1,dr1,da1,r1,\n",
    "                   d2,dr2,da2,r2,\n",
    "                   num):\n",
    "    '''\n",
    "    args:\n",
    "    \n",
    "    X_train: training data\n",
    "    f1,k1,a1: num of filters, filter size and activation func of 1st conv1D layer\n",
    "    f2,k2,a2: num of filters, filter size and activation func of 2nd conv1D layer\n",
    "    d1,dr1,da1, r1: num of units, dropout, activation func and regularizer para of 1st fully connected layer\n",
    "    d2,dr2,da2, r2: num of units, dropout, activation func and regularizer para  of 2nd fully connected layer\n",
    "    num: integer for distinguishing different model\n",
    "    \n",
    "    return:\n",
    "    model\n",
    "    '''\n",
    "    model = Sequential(name=\"Conv1D_\"+str(num))\n",
    "\n",
    "    m,n = X_train.shape\n",
    "    \n",
    "    #L1\n",
    "    model.add(Conv1D(filters = f1, kernel_size = k1, input_shape = (n,1), padding = 'same', activation = a1, name ='Conv1D_1'))\n",
    "    model.add(BatchNormalization(name = \"BN1\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling1\"))\n",
    "    #L2\n",
    "    model.add(Conv1D(filters = f2, kernel_size = k2, activation = a2, padding='same', name = \"Conv1D_2\"))\n",
    "    model.add(BatchNormalization(name = \"BN2\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling2\"))\n",
    "\n",
    "    #Flatten output\n",
    "    model.add(Flatten(name = \"Flatten\"))\n",
    "\n",
    "    #Fully connected layer 3\n",
    "    model.add(Dense(d1, activation = da1, name = \"Dense_1\"))\n",
    "    #Prevent overfitting\n",
    "    model.add(Dropout(dr1, name = \"Dropout_1\"))\n",
    "\n",
    "    #Fully connected layer 4 \n",
    "    model.add(Dense(d2, activation = da2, name = \"Dense_2\"))\n",
    "    #Prevent overfitting\n",
    "    model.add(Dropout(dr2, name = \"Dropout_2\"))\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(4, activation = 'softmax', name = \"Softmax\"))\n",
    "\n",
    "    #model compiling\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ea98757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 32)            0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 448)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               57472     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,892\n",
      "Trainable params: 69,796\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 9\n",
    "\n",
    "model9 = modelBuilder2L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a79257c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "36/36 [==============================] - 3s 15ms/step - loss: 1.7195 - accuracy: 0.2927 - val_loss: 1.3840 - val_accuracy: 0.2986\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 1.3195 - accuracy: 0.3885 - val_loss: 1.3910 - val_accuracy: 0.2986\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.2407 - accuracy: 0.4251 - val_loss: 1.3993 - val_accuracy: 0.2778\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.1006 - accuracy: 0.5174 - val_loss: 1.4071 - val_accuracy: 0.2639\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.0668 - accuracy: 0.5314 - val_loss: 1.4084 - val_accuracy: 0.2639\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0305 - accuracy: 0.5453 - val_loss: 1.4080 - val_accuracy: 0.2708\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9752 - accuracy: 0.5819 - val_loss: 1.3971 - val_accuracy: 0.2847\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.9807 - accuracy: 0.5784 - val_loss: 1.3840 - val_accuracy: 0.3194\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.9220 - accuracy: 0.6185 - val_loss: 1.3572 - val_accuracy: 0.3472\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8936 - accuracy: 0.6533 - val_loss: 1.3250 - val_accuracy: 0.3611\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8533 - accuracy: 0.6359 - val_loss: 1.2819 - val_accuracy: 0.3611\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8324 - accuracy: 0.6516 - val_loss: 1.2246 - val_accuracy: 0.4167\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8138 - accuracy: 0.6341 - val_loss: 1.1770 - val_accuracy: 0.4653\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7939 - accuracy: 0.6777 - val_loss: 1.1381 - val_accuracy: 0.4861\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7774 - accuracy: 0.6934 - val_loss: 1.1045 - val_accuracy: 0.5278\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7915 - accuracy: 0.6638 - val_loss: 1.0976 - val_accuracy: 0.5208\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.7577 - accuracy: 0.7073 - val_loss: 1.0774 - val_accuracy: 0.5278\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.7334 - val_loss: 1.0818 - val_accuracy: 0.5486\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.7213 - val_loss: 1.0745 - val_accuracy: 0.5556\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6753 - accuracy: 0.7282 - val_loss: 1.0700 - val_accuracy: 0.5556\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6651 - accuracy: 0.7456 - val_loss: 1.0751 - val_accuracy: 0.5139\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6605 - accuracy: 0.7265 - val_loss: 1.0706 - val_accuracy: 0.5417\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6584 - accuracy: 0.7282 - val_loss: 1.0780 - val_accuracy: 0.5417\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6027 - accuracy: 0.7909 - val_loss: 1.0941 - val_accuracy: 0.5556\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6033 - accuracy: 0.7596 - val_loss: 1.1023 - val_accuracy: 0.5556\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.5737 - accuracy: 0.7822 - val_loss: 1.1101 - val_accuracy: 0.5556\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.5559 - accuracy: 0.7944 - val_loss: 1.1322 - val_accuracy: 0.5694\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.8171 - val_loss: 1.1403 - val_accuracy: 0.5694\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5441 - accuracy: 0.7962 - val_loss: 1.1613 - val_accuracy: 0.5278\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5067 - accuracy: 0.8206 - val_loss: 1.1633 - val_accuracy: 0.5556\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.8206 - val_loss: 1.1899 - val_accuracy: 0.5417\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.5062 - accuracy: 0.8014 - val_loss: 1.1946 - val_accuracy: 0.5833\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.8397 - val_loss: 1.1912 - val_accuracy: 0.5694\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8362 - val_loss: 1.2179 - val_accuracy: 0.5417\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8676 - val_loss: 1.2298 - val_accuracy: 0.5486\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8484 - val_loss: 1.2588 - val_accuracy: 0.5417\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.8589 - val_loss: 1.2527 - val_accuracy: 0.5347\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.4046 - accuracy: 0.8693 - val_loss: 1.2336 - val_accuracy: 0.5694\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8554 - val_loss: 1.2825 - val_accuracy: 0.5347\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.4185 - accuracy: 0.8397 - val_loss: 1.2771 - val_accuracy: 0.5486\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8624 - val_loss: 1.2822 - val_accuracy: 0.5417\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8519 - val_loss: 1.2820 - val_accuracy: 0.5625\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.3835 - accuracy: 0.8798 - val_loss: 1.2927 - val_accuracy: 0.5556\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3471 - accuracy: 0.8937 - val_loss: 1.2858 - val_accuracy: 0.5556\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3613 - accuracy: 0.9007 - val_loss: 1.3010 - val_accuracy: 0.5556\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3418 - accuracy: 0.8815 - val_loss: 1.3000 - val_accuracy: 0.5278\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8937 - val_loss: 1.3486 - val_accuracy: 0.5208\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.9042 - val_loss: 1.3473 - val_accuracy: 0.5278\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.3095 - accuracy: 0.9077 - val_loss: 1.3766 - val_accuracy: 0.5347\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.3055 - accuracy: 0.9059 - val_loss: 1.3641 - val_accuracy: 0.5278\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2860 - accuracy: 0.9129 - val_loss: 1.4157 - val_accuracy: 0.5417\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.3083 - accuracy: 0.8937 - val_loss: 1.3973 - val_accuracy: 0.5417\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2637 - accuracy: 0.9286 - val_loss: 1.3999 - val_accuracy: 0.5208\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2653 - accuracy: 0.9199 - val_loss: 1.4246 - val_accuracy: 0.5208\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.2569 - accuracy: 0.9408 - val_loss: 1.4152 - val_accuracy: 0.5278\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2306 - accuracy: 0.9373 - val_loss: 1.4834 - val_accuracy: 0.4861\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2694 - accuracy: 0.9129 - val_loss: 1.4700 - val_accuracy: 0.5208\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2289 - accuracy: 0.9373 - val_loss: 1.4891 - val_accuracy: 0.5417\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2296 - accuracy: 0.9425 - val_loss: 1.5201 - val_accuracy: 0.5000\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2260 - accuracy: 0.9338 - val_loss: 1.5207 - val_accuracy: 0.4861\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.2207 - accuracy: 0.9355 - val_loss: 1.5980 - val_accuracy: 0.4722\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2045 - accuracy: 0.9355 - val_loss: 1.5462 - val_accuracy: 0.4931\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2071 - accuracy: 0.9460 - val_loss: 1.6301 - val_accuracy: 0.5000\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2146 - accuracy: 0.9408 - val_loss: 1.5791 - val_accuracy: 0.4931\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2051 - accuracy: 0.9338 - val_loss: 1.6651 - val_accuracy: 0.4861\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1907 - accuracy: 0.9530 - val_loss: 1.6411 - val_accuracy: 0.4931\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1831 - accuracy: 0.9390 - val_loss: 1.6743 - val_accuracy: 0.5069\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9425 - val_loss: 1.7153 - val_accuracy: 0.5208\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 0.9425 - val_loss: 1.6811 - val_accuracy: 0.4861\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1878 - accuracy: 0.9443 - val_loss: 1.7221 - val_accuracy: 0.5000\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1531 - accuracy: 0.9721 - val_loss: 1.7421 - val_accuracy: 0.4792\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1545 - accuracy: 0.9530 - val_loss: 1.6607 - val_accuracy: 0.5069\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1580 - accuracy: 0.9634 - val_loss: 1.7423 - val_accuracy: 0.4792\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.9634 - val_loss: 1.7357 - val_accuracy: 0.4931\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9443 - val_loss: 1.7768 - val_accuracy: 0.4861\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1353 - accuracy: 0.9652 - val_loss: 1.8621 - val_accuracy: 0.4931\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1333 - accuracy: 0.9808 - val_loss: 1.8298 - val_accuracy: 0.5000\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1402 - accuracy: 0.9547 - val_loss: 1.8644 - val_accuracy: 0.5000\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1439 - accuracy: 0.9686 - val_loss: 1.7924 - val_accuracy: 0.4931\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1277 - accuracy: 0.9686 - val_loss: 1.8687 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history9 = model9.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74296e6",
   "metadata": {},
   "source": [
    "Simplifying the layer leads to the underfitting of the model, which lowers the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2ffb932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 8)             32        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 8)             32        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 8)             0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 16)            656       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 16)            0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 64)                14400     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,396\n",
      "Trainable params: 17,348\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 8,3,'relu'\n",
    "f2,k2,a2 = 16,5,'relu'\n",
    "d1,dr1,da1,r1 = 64,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 32,0.2,'relu',0.15\n",
    "num = 10\n",
    "\n",
    "model10 = modelBuilder2L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11db717a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "36/36 [==============================] - 3s 17ms/step - loss: 1.7546 - accuracy: 0.2317 - val_loss: 1.3912 - val_accuracy: 0.2639\n",
      "Epoch 2/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.5931 - accuracy: 0.2596 - val_loss: 1.3851 - val_accuracy: 0.2500\n",
      "Epoch 3/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.4481 - accuracy: 0.3153 - val_loss: 1.3806 - val_accuracy: 0.2569\n",
      "Epoch 4/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.3798 - accuracy: 0.3467 - val_loss: 1.3763 - val_accuracy: 0.2361\n",
      "Epoch 5/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.2941 - accuracy: 0.3920 - val_loss: 1.3706 - val_accuracy: 0.2569\n",
      "Epoch 6/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.3131 - accuracy: 0.3763 - val_loss: 1.3565 - val_accuracy: 0.2569\n",
      "Epoch 7/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.2259 - accuracy: 0.4111 - val_loss: 1.3378 - val_accuracy: 0.2639\n",
      "Epoch 8/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.2114 - accuracy: 0.4443 - val_loss: 1.3152 - val_accuracy: 0.3264\n",
      "Epoch 9/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.1918 - accuracy: 0.4268 - val_loss: 1.2906 - val_accuracy: 0.3611\n",
      "Epoch 10/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.1580 - accuracy: 0.4669 - val_loss: 1.2622 - val_accuracy: 0.3750\n",
      "Epoch 11/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.1347 - accuracy: 0.4826 - val_loss: 1.2353 - val_accuracy: 0.4306\n",
      "Epoch 12/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.0802 - accuracy: 0.4878 - val_loss: 1.2115 - val_accuracy: 0.4375\n",
      "Epoch 13/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 1.0935 - accuracy: 0.5244 - val_loss: 1.1924 - val_accuracy: 0.4722\n",
      "Epoch 14/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.1009 - accuracy: 0.5087 - val_loss: 1.1734 - val_accuracy: 0.4792\n",
      "Epoch 15/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.0578 - accuracy: 0.5296 - val_loss: 1.1568 - val_accuracy: 0.4792\n",
      "Epoch 16/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 1.0384 - accuracy: 0.5523 - val_loss: 1.1437 - val_accuracy: 0.4861\n",
      "Epoch 17/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.0241 - accuracy: 0.5035 - val_loss: 1.1299 - val_accuracy: 0.4653\n",
      "Epoch 18/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.0108 - accuracy: 0.5697 - val_loss: 1.1210 - val_accuracy: 0.4792\n",
      "Epoch 19/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.0408 - accuracy: 0.5192 - val_loss: 1.1119 - val_accuracy: 0.4931\n",
      "Epoch 20/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.0067 - accuracy: 0.5331 - val_loss: 1.1009 - val_accuracy: 0.4931\n",
      "Epoch 21/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 1.0134 - accuracy: 0.5174 - val_loss: 1.0990 - val_accuracy: 0.4722\n",
      "Epoch 22/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.9802 - accuracy: 0.5697 - val_loss: 1.0966 - val_accuracy: 0.4653\n",
      "Epoch 23/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.9777 - accuracy: 0.5557 - val_loss: 1.0933 - val_accuracy: 0.4861\n",
      "Epoch 24/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.9513 - accuracy: 0.5941 - val_loss: 1.0883 - val_accuracy: 0.4722\n",
      "Epoch 25/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.9530 - accuracy: 0.5819 - val_loss: 1.0800 - val_accuracy: 0.4861\n",
      "Epoch 26/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.9776 - accuracy: 0.5784 - val_loss: 1.0785 - val_accuracy: 0.4653\n",
      "Epoch 27/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.9163 - accuracy: 0.6028 - val_loss: 1.0707 - val_accuracy: 0.4722\n",
      "Epoch 28/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.9024 - accuracy: 0.5993 - val_loss: 1.0692 - val_accuracy: 0.4653\n",
      "Epoch 29/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8941 - accuracy: 0.6359 - val_loss: 1.0644 - val_accuracy: 0.4792\n",
      "Epoch 30/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.8871 - accuracy: 0.5958 - val_loss: 1.0608 - val_accuracy: 0.4792\n",
      "Epoch 31/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.9091 - accuracy: 0.5976 - val_loss: 1.0619 - val_accuracy: 0.4861\n",
      "Epoch 32/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8761 - accuracy: 0.6010 - val_loss: 1.0647 - val_accuracy: 0.4792\n",
      "Epoch 33/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8910 - accuracy: 0.5958 - val_loss: 1.0668 - val_accuracy: 0.4653\n",
      "Epoch 34/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8491 - accuracy: 0.6655 - val_loss: 1.0678 - val_accuracy: 0.4792\n",
      "Epoch 35/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8884 - accuracy: 0.6359 - val_loss: 1.0685 - val_accuracy: 0.4583\n",
      "Epoch 36/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.8926 - accuracy: 0.5889 - val_loss: 1.0690 - val_accuracy: 0.4583\n",
      "Epoch 37/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8248 - accuracy: 0.6568 - val_loss: 1.0690 - val_accuracy: 0.4653\n",
      "Epoch 38/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8301 - accuracy: 0.6533 - val_loss: 1.0666 - val_accuracy: 0.4583\n",
      "Epoch 39/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8361 - accuracy: 0.6098 - val_loss: 1.0694 - val_accuracy: 0.4514\n",
      "Epoch 40/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.8079 - accuracy: 0.6551 - val_loss: 1.0729 - val_accuracy: 0.4931\n",
      "Epoch 41/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8123 - accuracy: 0.6672 - val_loss: 1.0712 - val_accuracy: 0.4792\n",
      "Epoch 42/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8192 - accuracy: 0.6429 - val_loss: 1.0745 - val_accuracy: 0.4722\n",
      "Epoch 43/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8003 - accuracy: 0.6568 - val_loss: 1.0702 - val_accuracy: 0.4722\n",
      "Epoch 44/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7983 - accuracy: 0.6707 - val_loss: 1.0747 - val_accuracy: 0.4792\n",
      "Epoch 45/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7723 - accuracy: 0.6777 - val_loss: 1.0737 - val_accuracy: 0.4583\n",
      "Epoch 46/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7950 - accuracy: 0.6760 - val_loss: 1.0725 - val_accuracy: 0.4583\n",
      "Epoch 47/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7687 - accuracy: 0.6969 - val_loss: 1.0776 - val_accuracy: 0.4931\n",
      "Epoch 48/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7649 - accuracy: 0.6812 - val_loss: 1.0826 - val_accuracy: 0.4722\n",
      "Epoch 49/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7897 - accuracy: 0.6603 - val_loss: 1.0915 - val_accuracy: 0.5000\n",
      "Epoch 50/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7441 - accuracy: 0.7143 - val_loss: 1.0899 - val_accuracy: 0.4722\n",
      "Epoch 51/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7423 - accuracy: 0.6829 - val_loss: 1.0966 - val_accuracy: 0.4792\n",
      "Epoch 52/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7495 - accuracy: 0.6916 - val_loss: 1.0993 - val_accuracy: 0.4722\n",
      "Epoch 53/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7430 - accuracy: 0.7003 - val_loss: 1.1035 - val_accuracy: 0.4653\n",
      "Epoch 54/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7632 - accuracy: 0.6551 - val_loss: 1.1017 - val_accuracy: 0.4722\n",
      "Epoch 55/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.7345 - accuracy: 0.6899 - val_loss: 1.1112 - val_accuracy: 0.4792\n",
      "Epoch 56/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7178 - accuracy: 0.7143 - val_loss: 1.1202 - val_accuracy: 0.4792\n",
      "Epoch 57/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7190 - accuracy: 0.7056 - val_loss: 1.1184 - val_accuracy: 0.4861\n",
      "Epoch 58/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.7160 - val_loss: 1.1168 - val_accuracy: 0.4861\n",
      "Epoch 59/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7042 - accuracy: 0.7021 - val_loss: 1.1050 - val_accuracy: 0.5139\n",
      "Epoch 60/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7124 - accuracy: 0.7300 - val_loss: 1.1058 - val_accuracy: 0.4861\n",
      "Epoch 61/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.7073 - val_loss: 1.1128 - val_accuracy: 0.4931\n",
      "Epoch 62/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6901 - accuracy: 0.7143 - val_loss: 1.1081 - val_accuracy: 0.4861\n",
      "Epoch 63/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.7048 - accuracy: 0.7003 - val_loss: 1.1132 - val_accuracy: 0.4931\n",
      "Epoch 64/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6525 - accuracy: 0.7317 - val_loss: 1.1213 - val_accuracy: 0.4861\n",
      "Epoch 65/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.7091 - val_loss: 1.1346 - val_accuracy: 0.4861\n",
      "Epoch 66/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6573 - accuracy: 0.7578 - val_loss: 1.1392 - val_accuracy: 0.4861\n",
      "Epoch 67/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.7422 - val_loss: 1.1340 - val_accuracy: 0.4931\n",
      "Epoch 68/80\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.6623 - accuracy: 0.7544 - val_loss: 1.1265 - val_accuracy: 0.4931\n",
      "Epoch 69/80\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6652 - accuracy: 0.7317 - val_loss: 1.1409 - val_accuracy: 0.5000\n",
      "Epoch 70/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.7613 - val_loss: 1.1485 - val_accuracy: 0.4792\n",
      "Epoch 71/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6565 - accuracy: 0.7247 - val_loss: 1.1522 - val_accuracy: 0.5069\n",
      "Epoch 72/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6270 - accuracy: 0.7526 - val_loss: 1.1637 - val_accuracy: 0.4931\n",
      "Epoch 73/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6035 - accuracy: 0.7404 - val_loss: 1.1807 - val_accuracy: 0.5000\n",
      "Epoch 74/80\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.6186 - accuracy: 0.7578 - val_loss: 1.1725 - val_accuracy: 0.5208\n",
      "Epoch 75/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6046 - accuracy: 0.7648 - val_loss: 1.1728 - val_accuracy: 0.5069\n",
      "Epoch 76/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.5999 - accuracy: 0.7753 - val_loss: 1.1815 - val_accuracy: 0.5000\n",
      "Epoch 77/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.7631 - val_loss: 1.1849 - val_accuracy: 0.4792\n",
      "Epoch 78/80\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.6060 - accuracy: 0.7648 - val_loss: 1.1837 - val_accuracy: 0.4931\n",
      "Epoch 79/80\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.5937 - accuracy: 0.7526 - val_loss: 1.1784 - val_accuracy: 0.4861\n",
      "Epoch 80/80\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.6188 - accuracy: 0.7561 - val_loss: 1.1778 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history10 = model10.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca19c2",
   "metadata": {},
   "source": [
    "### 3.2 Change dataset\n",
    "After trying out multiple ways to address the overfitting problems, the model accuracy still remain almost same and did not improve significantly. Because the number of data in this dataset is sufficient, therefore, changing of the dataset is considered. Here the dataset2 is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c538707f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 57, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 57, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 28, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 28, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 28, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 14, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 14, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 14, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 7, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               28800     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,548\n",
      "Trainable params: 48,388\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 11\n",
    "\n",
    "model11 = modelBuilder3L(X2_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7948184b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "18/18 [==============================] - 5s 43ms/step - loss: 1.6793 - accuracy: 0.3160 - val_loss: 1.3872 - val_accuracy: 0.2917\n",
      "Epoch 2/80\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1.3820 - accuracy: 0.4236 - val_loss: 1.3766 - val_accuracy: 0.2500\n",
      "Epoch 3/80\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1.1314 - accuracy: 0.4826 - val_loss: 1.3777 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9658 - accuracy: 0.5799 - val_loss: 1.3886 - val_accuracy: 0.2500\n",
      "Epoch 5/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.9045 - accuracy: 0.6285 - val_loss: 1.4002 - val_accuracy: 0.2500\n",
      "Epoch 6/80\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.8257 - accuracy: 0.6910 - val_loss: 1.4127 - val_accuracy: 0.2500\n",
      "Epoch 7/80\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.7775 - accuracy: 0.6528 - val_loss: 1.4251 - val_accuracy: 0.2500\n",
      "Epoch 8/80\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.7759 - accuracy: 0.6944 - val_loss: 1.4337 - val_accuracy: 0.2500\n",
      "Epoch 9/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7489 - accuracy: 0.6979 - val_loss: 1.4341 - val_accuracy: 0.2500\n",
      "Epoch 10/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.7063 - accuracy: 0.7222 - val_loss: 1.4321 - val_accuracy: 0.2500\n",
      "Epoch 11/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6370 - accuracy: 0.7708 - val_loss: 1.4233 - val_accuracy: 0.2500\n",
      "Epoch 12/80\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.5630 - accuracy: 0.7708 - val_loss: 1.4138 - val_accuracy: 0.2500\n",
      "Epoch 13/80\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6143 - accuracy: 0.7500 - val_loss: 1.3964 - val_accuracy: 0.2500\n",
      "Epoch 14/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5699 - accuracy: 0.7674 - val_loss: 1.3763 - val_accuracy: 0.2500\n",
      "Epoch 15/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5239 - accuracy: 0.7812 - val_loss: 1.3540 - val_accuracy: 0.2500\n",
      "Epoch 16/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5085 - accuracy: 0.8194 - val_loss: 1.3228 - val_accuracy: 0.2778\n",
      "Epoch 17/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4957 - accuracy: 0.8021 - val_loss: 1.3007 - val_accuracy: 0.3056\n",
      "Epoch 18/80\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4687 - accuracy: 0.8368 - val_loss: 1.2691 - val_accuracy: 0.3056\n",
      "Epoch 19/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.8403 - val_loss: 1.2306 - val_accuracy: 0.3333\n",
      "Epoch 20/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8611 - val_loss: 1.1683 - val_accuracy: 0.4167\n",
      "Epoch 21/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4409 - accuracy: 0.8403 - val_loss: 1.1017 - val_accuracy: 0.5278\n",
      "Epoch 22/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3969 - accuracy: 0.8576 - val_loss: 1.0435 - val_accuracy: 0.5833\n",
      "Epoch 23/80\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3323 - accuracy: 0.9062 - val_loss: 0.9832 - val_accuracy: 0.6111\n",
      "Epoch 24/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3487 - accuracy: 0.8889 - val_loss: 0.9171 - val_accuracy: 0.7083\n",
      "Epoch 25/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3339 - accuracy: 0.8785 - val_loss: 0.8489 - val_accuracy: 0.7083\n",
      "Epoch 26/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3312 - accuracy: 0.8993 - val_loss: 0.7926 - val_accuracy: 0.7083\n",
      "Epoch 27/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3129 - accuracy: 0.8993 - val_loss: 0.7557 - val_accuracy: 0.7083\n",
      "Epoch 28/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3195 - accuracy: 0.9097 - val_loss: 0.7111 - val_accuracy: 0.7222\n",
      "Epoch 29/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2907 - accuracy: 0.9201 - val_loss: 0.6711 - val_accuracy: 0.7639\n",
      "Epoch 30/80\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.3199 - accuracy: 0.8854 - val_loss: 0.6361 - val_accuracy: 0.7500\n",
      "Epoch 31/80\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.2557 - accuracy: 0.9062 - val_loss: 0.6115 - val_accuracy: 0.7500\n",
      "Epoch 32/80\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.2505 - accuracy: 0.9132 - val_loss: 0.5957 - val_accuracy: 0.7500\n",
      "Epoch 33/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2259 - accuracy: 0.9306 - val_loss: 0.5797 - val_accuracy: 0.7500\n",
      "Epoch 34/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2200 - accuracy: 0.9271 - val_loss: 0.5701 - val_accuracy: 0.7500\n",
      "Epoch 35/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2398 - accuracy: 0.9132 - val_loss: 0.5646 - val_accuracy: 0.7500\n",
      "Epoch 36/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2068 - accuracy: 0.9201 - val_loss: 0.5456 - val_accuracy: 0.7639\n",
      "Epoch 37/80\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.1911 - accuracy: 0.9514 - val_loss: 0.5462 - val_accuracy: 0.7639\n",
      "Epoch 38/80\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.2064 - accuracy: 0.9444 - val_loss: 0.5547 - val_accuracy: 0.7778\n",
      "Epoch 39/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1666 - accuracy: 0.9653 - val_loss: 0.5500 - val_accuracy: 0.7639\n",
      "Epoch 40/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2002 - accuracy: 0.9340 - val_loss: 0.5562 - val_accuracy: 0.7639\n",
      "Epoch 41/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1799 - accuracy: 0.9375 - val_loss: 0.5586 - val_accuracy: 0.7917\n",
      "Epoch 42/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1861 - accuracy: 0.9375 - val_loss: 0.5671 - val_accuracy: 0.8056\n",
      "Epoch 43/80\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.1555 - accuracy: 0.9549 - val_loss: 0.5809 - val_accuracy: 0.8056\n",
      "Epoch 44/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1596 - accuracy: 0.9479 - val_loss: 0.5905 - val_accuracy: 0.7917\n",
      "Epoch 45/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1681 - accuracy: 0.9444 - val_loss: 0.5911 - val_accuracy: 0.7778\n",
      "Epoch 46/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1706 - accuracy: 0.9479 - val_loss: 0.5854 - val_accuracy: 0.7778\n",
      "Epoch 47/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1631 - accuracy: 0.9514 - val_loss: 0.5963 - val_accuracy: 0.7778\n",
      "Epoch 48/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1708 - accuracy: 0.9549 - val_loss: 0.6093 - val_accuracy: 0.7639\n",
      "Epoch 49/80\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.1271 - accuracy: 0.9722 - val_loss: 0.6044 - val_accuracy: 0.7917\n",
      "Epoch 50/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1208 - accuracy: 0.9549 - val_loss: 0.6074 - val_accuracy: 0.8056\n",
      "Epoch 51/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1056 - accuracy: 0.9688 - val_loss: 0.6116 - val_accuracy: 0.7917\n",
      "Epoch 52/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1070 - accuracy: 0.9826 - val_loss: 0.6180 - val_accuracy: 0.7917\n",
      "Epoch 53/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1119 - accuracy: 0.9792 - val_loss: 0.6432 - val_accuracy: 0.7778\n",
      "Epoch 54/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1060 - accuracy: 0.9826 - val_loss: 0.6509 - val_accuracy: 0.7778\n",
      "Epoch 55/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1368 - accuracy: 0.9514 - val_loss: 0.6757 - val_accuracy: 0.7639\n",
      "Epoch 56/80\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.1162 - accuracy: 0.9583 - val_loss: 0.6412 - val_accuracy: 0.7917\n",
      "Epoch 57/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1230 - accuracy: 0.9722 - val_loss: 0.6372 - val_accuracy: 0.7778\n",
      "Epoch 58/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1002 - accuracy: 0.9688 - val_loss: 0.6415 - val_accuracy: 0.7778\n",
      "Epoch 59/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0941 - accuracy: 0.9757 - val_loss: 0.6428 - val_accuracy: 0.7778\n",
      "Epoch 60/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0938 - accuracy: 0.9792 - val_loss: 0.6430 - val_accuracy: 0.7917\n",
      "Epoch 61/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0799 - accuracy: 0.9826 - val_loss: 0.6488 - val_accuracy: 0.7917\n",
      "Epoch 62/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0858 - accuracy: 0.9722 - val_loss: 0.6622 - val_accuracy: 0.7778\n",
      "Epoch 63/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0939 - accuracy: 0.9688 - val_loss: 0.6822 - val_accuracy: 0.7778\n",
      "Epoch 64/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9792 - val_loss: 0.6838 - val_accuracy: 0.7778\n",
      "Epoch 65/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0680 - accuracy: 0.9861 - val_loss: 0.6917 - val_accuracy: 0.7778\n",
      "Epoch 66/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0845 - accuracy: 0.9826 - val_loss: 0.6947 - val_accuracy: 0.7778\n",
      "Epoch 67/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0617 - accuracy: 0.9931 - val_loss: 0.7014 - val_accuracy: 0.7778\n",
      "Epoch 68/80\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0654 - accuracy: 0.9931 - val_loss: 0.6830 - val_accuracy: 0.7917\n",
      "Epoch 69/80\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0577 - accuracy: 0.9861 - val_loss: 0.6844 - val_accuracy: 0.7917\n",
      "Epoch 70/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0787 - accuracy: 0.9826 - val_loss: 0.7126 - val_accuracy: 0.8056\n",
      "Epoch 71/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0579 - accuracy: 0.9896 - val_loss: 0.7296 - val_accuracy: 0.8056\n",
      "Epoch 72/80\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0542 - accuracy: 0.9792 - val_loss: 0.6862 - val_accuracy: 0.8194\n",
      "Epoch 73/80\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0660 - accuracy: 0.9861 - val_loss: 0.6691 - val_accuracy: 0.8194\n",
      "Epoch 74/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0472 - accuracy: 0.9931 - val_loss: 0.6847 - val_accuracy: 0.8194\n",
      "Epoch 75/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0534 - accuracy: 0.9965 - val_loss: 0.7367 - val_accuracy: 0.8056\n",
      "Epoch 76/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0491 - accuracy: 0.9896 - val_loss: 0.7412 - val_accuracy: 0.7917\n",
      "Epoch 77/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0561 - accuracy: 0.9896 - val_loss: 0.7200 - val_accuracy: 0.7917\n",
      "Epoch 78/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0458 - accuracy: 0.9931 - val_loss: 0.7143 - val_accuracy: 0.7917\n",
      "Epoch 79/80\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0514 - accuracy: 0.9861 - val_loss: 0.7175 - val_accuracy: 0.7917\n",
      "Epoch 80/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0534 - accuracy: 0.9896 - val_loss: 0.7421 - val_accuracy: 0.7917\n"
     ]
    }
   ],
   "source": [
    "history11 = model11.fit(X2_train_scaled, y2_train, \n",
    "                        validation_data=(X2_val_scaled, y2_val), \n",
    "                        batch_size=16, \n",
    "                        epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149e7d3",
   "metadata": {},
   "source": [
    "**Different number of features**</br>\n",
    "**MFCCs Only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d2789432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 40, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 20, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 20, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 10, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 10, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 10, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 5, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 160)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               20608     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,356\n",
      "Trainable params: 40,196\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 12\n",
    "\n",
    "model12 = modelBuilder3L(X2_train_scaled[:,17:],\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c8ca28d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 4s 31ms/step - loss: 1.6436 - accuracy: 0.2465 - val_loss: 1.3848 - val_accuracy: 0.2639\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.4416 - accuracy: 0.3576 - val_loss: 1.3932 - val_accuracy: 0.3194\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1901 - accuracy: 0.5174 - val_loss: 1.4045 - val_accuracy: 0.2917\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1.1305 - accuracy: 0.5208 - val_loss: 1.4166 - val_accuracy: 0.2639\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0459 - accuracy: 0.5382 - val_loss: 1.4320 - val_accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0323 - accuracy: 0.6042 - val_loss: 1.4482 - val_accuracy: 0.2500\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9344 - accuracy: 0.6562 - val_loss: 1.4665 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8585 - accuracy: 0.6701 - val_loss: 1.4890 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8220 - accuracy: 0.7014 - val_loss: 1.5026 - val_accuracy: 0.2500\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8250 - accuracy: 0.6667 - val_loss: 1.5241 - val_accuracy: 0.2500\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.7732 - accuracy: 0.6910 - val_loss: 1.5343 - val_accuracy: 0.2500\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.7146 - accuracy: 0.7292 - val_loss: 1.5564 - val_accuracy: 0.2500\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6561 - accuracy: 0.7674 - val_loss: 1.5612 - val_accuracy: 0.2500\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7043 - accuracy: 0.7465 - val_loss: 1.5639 - val_accuracy: 0.2639\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6132 - accuracy: 0.7847 - val_loss: 1.5655 - val_accuracy: 0.2639\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6072 - accuracy: 0.7743 - val_loss: 1.5553 - val_accuracy: 0.3194\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5483 - accuracy: 0.8090 - val_loss: 1.5384 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5237 - accuracy: 0.8229 - val_loss: 1.5133 - val_accuracy: 0.3611\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5709 - accuracy: 0.7917 - val_loss: 1.4717 - val_accuracy: 0.3750\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5799 - accuracy: 0.7674 - val_loss: 1.4228 - val_accuracy: 0.4306\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4743 - accuracy: 0.8299 - val_loss: 1.3730 - val_accuracy: 0.4167\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4952 - accuracy: 0.8368 - val_loss: 1.3171 - val_accuracy: 0.4167\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.8160 - val_loss: 1.2751 - val_accuracy: 0.4167\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8854 - val_loss: 1.2296 - val_accuracy: 0.4167\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4483 - accuracy: 0.8576 - val_loss: 1.1933 - val_accuracy: 0.4444\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8576 - val_loss: 1.1446 - val_accuracy: 0.4167\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8681 - val_loss: 1.0873 - val_accuracy: 0.4306\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4799 - accuracy: 0.8229 - val_loss: 1.0384 - val_accuracy: 0.4861\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3606 - accuracy: 0.8854 - val_loss: 1.0048 - val_accuracy: 0.5417\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3560 - accuracy: 0.8819 - val_loss: 0.9782 - val_accuracy: 0.5556\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3356 - accuracy: 0.8854 - val_loss: 0.9476 - val_accuracy: 0.6111\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3666 - accuracy: 0.8889 - val_loss: 0.9118 - val_accuracy: 0.6389\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2787 - accuracy: 0.9236 - val_loss: 0.8992 - val_accuracy: 0.6250\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3075 - accuracy: 0.8958 - val_loss: 0.8936 - val_accuracy: 0.6389\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2790 - accuracy: 0.9201 - val_loss: 0.8744 - val_accuracy: 0.6528\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.2875 - accuracy: 0.9132 - val_loss: 0.8806 - val_accuracy: 0.6250\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.3040 - accuracy: 0.8958 - val_loss: 0.8810 - val_accuracy: 0.6389\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2869 - accuracy: 0.9132 - val_loss: 0.8836 - val_accuracy: 0.6111\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2597 - accuracy: 0.9306 - val_loss: 0.8957 - val_accuracy: 0.6250\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2451 - accuracy: 0.9444 - val_loss: 0.9018 - val_accuracy: 0.6111\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2772 - accuracy: 0.9167 - val_loss: 0.9159 - val_accuracy: 0.6111\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2578 - accuracy: 0.9167 - val_loss: 0.9400 - val_accuracy: 0.6111\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2379 - accuracy: 0.9444 - val_loss: 0.9396 - val_accuracy: 0.6111\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2067 - accuracy: 0.9340 - val_loss: 0.9535 - val_accuracy: 0.6111\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1979 - accuracy: 0.9583 - val_loss: 0.9488 - val_accuracy: 0.6389\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2113 - accuracy: 0.9444 - val_loss: 0.9573 - val_accuracy: 0.6250\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1885 - accuracy: 0.9653 - val_loss: 0.9658 - val_accuracy: 0.6250\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1987 - accuracy: 0.9410 - val_loss: 0.9614 - val_accuracy: 0.6250\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.2053 - accuracy: 0.9271 - val_loss: 0.9732 - val_accuracy: 0.6250\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1949 - accuracy: 0.9375 - val_loss: 0.9806 - val_accuracy: 0.6528\n"
     ]
    }
   ],
   "source": [
    "history12 = model12.fit(X2_train_scaled[:,17:], y2_train, \n",
    "                    validation_data=(X2_val_scaled[:,17:], y2_val), \n",
    "                    batch_size=16, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313777ce",
   "metadata": {},
   "source": [
    "**Mel Spectrogram + MFCCs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8e08c557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 42, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 42, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 21, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 21, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 21, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 10, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 10, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 10, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 5, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 160)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               20608     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,356\n",
      "Trainable params: 40,196\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 13\n",
    "\n",
    "model13 = modelBuilder3L(X2_train_scaled[:,15:],\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "90ab1fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 4s 29ms/step - loss: 1.8982 - accuracy: 0.2812 - val_loss: 1.3898 - val_accuracy: 0.2361\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5669 - accuracy: 0.3681 - val_loss: 1.3923 - val_accuracy: 0.2361\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4348 - accuracy: 0.4167 - val_loss: 1.3961 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3500 - accuracy: 0.4618 - val_loss: 1.4013 - val_accuracy: 0.2500\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2824 - accuracy: 0.4688 - val_loss: 1.4082 - val_accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1579 - accuracy: 0.5069 - val_loss: 1.4138 - val_accuracy: 0.2500\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1051 - accuracy: 0.5451 - val_loss: 1.4167 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9878 - accuracy: 0.5729 - val_loss: 1.4155 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0445 - accuracy: 0.5694 - val_loss: 1.4105 - val_accuracy: 0.2639\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9631 - accuracy: 0.5938 - val_loss: 1.4038 - val_accuracy: 0.3056\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.8838 - accuracy: 0.6458 - val_loss: 1.3948 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8544 - accuracy: 0.6458 - val_loss: 1.3858 - val_accuracy: 0.3750\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8576 - accuracy: 0.6458 - val_loss: 1.3768 - val_accuracy: 0.3889\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8172 - accuracy: 0.7049 - val_loss: 1.3637 - val_accuracy: 0.3750\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7870 - accuracy: 0.6875 - val_loss: 1.3492 - val_accuracy: 0.3889\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7147 - accuracy: 0.7188 - val_loss: 1.3357 - val_accuracy: 0.3750\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.7465 - val_loss: 1.3181 - val_accuracy: 0.3611\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6999 - accuracy: 0.7257 - val_loss: 1.2943 - val_accuracy: 0.4167\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6639 - accuracy: 0.7431 - val_loss: 1.2660 - val_accuracy: 0.4583\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6335 - accuracy: 0.7847 - val_loss: 1.2315 - val_accuracy: 0.4861\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6077 - accuracy: 0.7535 - val_loss: 1.1945 - val_accuracy: 0.5556\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5398 - accuracy: 0.8160 - val_loss: 1.1597 - val_accuracy: 0.5694\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5411 - accuracy: 0.7882 - val_loss: 1.1242 - val_accuracy: 0.5833\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5259 - accuracy: 0.8264 - val_loss: 1.0891 - val_accuracy: 0.6111\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4449 - accuracy: 0.8472 - val_loss: 1.0557 - val_accuracy: 0.6111\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.8125 - val_loss: 1.0201 - val_accuracy: 0.6250\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4839 - accuracy: 0.8368 - val_loss: 0.9839 - val_accuracy: 0.6389\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4880 - accuracy: 0.8333 - val_loss: 0.9565 - val_accuracy: 0.6389\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4545 - accuracy: 0.8438 - val_loss: 0.9306 - val_accuracy: 0.6528\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.8403 - val_loss: 0.9079 - val_accuracy: 0.6528\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3987 - accuracy: 0.8472 - val_loss: 0.8985 - val_accuracy: 0.6528\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.3886 - accuracy: 0.8646 - val_loss: 0.8979 - val_accuracy: 0.6528\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3474 - accuracy: 0.9236 - val_loss: 0.8874 - val_accuracy: 0.6389\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.8889 - val_loss: 0.8888 - val_accuracy: 0.6528\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3711 - accuracy: 0.8993 - val_loss: 0.8821 - val_accuracy: 0.6389\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3114 - accuracy: 0.9062 - val_loss: 0.8729 - val_accuracy: 0.6667\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2980 - accuracy: 0.9201 - val_loss: 0.8662 - val_accuracy: 0.6806\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3050 - accuracy: 0.8958 - val_loss: 0.8852 - val_accuracy: 0.6667\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3114 - accuracy: 0.8993 - val_loss: 0.8881 - val_accuracy: 0.6667\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3077 - accuracy: 0.8958 - val_loss: 0.8990 - val_accuracy: 0.6944\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3225 - accuracy: 0.8924 - val_loss: 0.9061 - val_accuracy: 0.6944\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.2852 - accuracy: 0.9062 - val_loss: 0.8951 - val_accuracy: 0.6806\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2302 - accuracy: 0.9340 - val_loss: 0.8893 - val_accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2441 - accuracy: 0.9236 - val_loss: 0.8995 - val_accuracy: 0.6667\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2640 - accuracy: 0.9201 - val_loss: 0.8993 - val_accuracy: 0.6944\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2397 - accuracy: 0.9306 - val_loss: 0.9123 - val_accuracy: 0.6944\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2524 - accuracy: 0.9201 - val_loss: 0.9378 - val_accuracy: 0.6806\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.2200 - accuracy: 0.9479 - val_loss: 0.9582 - val_accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2044 - accuracy: 0.9306 - val_loss: 0.9482 - val_accuracy: 0.6667\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2149 - accuracy: 0.9271 - val_loss: 0.9793 - val_accuracy: 0.6806\n"
     ]
    }
   ],
   "source": [
    "history13 = model13.fit(X2_train_scaled[:,15:], y2_train, \n",
    "                    validation_data=(X2_val_scaled[:,15:], y2_val), \n",
    "                    batch_size=16, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab1b1bd",
   "metadata": {},
   "source": [
    "**Mel Spectrogram + MFCCs + Tonnetz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "25cc8197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 44, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 44, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 22, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 22, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 22, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 11, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 11, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 11, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 5, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 160)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               20608     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,356\n",
      "Trainable params: 40,196\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 14\n",
    "\n",
    "model14 = modelBuilder3L(X2_train_scaled[:,13:],\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a12d654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 27ms/step - loss: 1.6827 - accuracy: 0.3368 - val_loss: 1.3808 - val_accuracy: 0.3333\n",
      "Epoch 2/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3893 - accuracy: 0.3403 - val_loss: 1.3852 - val_accuracy: 0.2500\n",
      "Epoch 3/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.2095 - accuracy: 0.5174 - val_loss: 1.3874 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1152 - accuracy: 0.5347 - val_loss: 1.3889 - val_accuracy: 0.2500\n",
      "Epoch 5/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9991 - accuracy: 0.5903 - val_loss: 1.3898 - val_accuracy: 0.2500\n",
      "Epoch 6/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9212 - accuracy: 0.6424 - val_loss: 1.3914 - val_accuracy: 0.2639\n",
      "Epoch 7/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8590 - accuracy: 0.6840 - val_loss: 1.3921 - val_accuracy: 0.2500\n",
      "Epoch 8/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8615 - accuracy: 0.6910 - val_loss: 1.3931 - val_accuracy: 0.3194\n",
      "Epoch 9/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8181 - accuracy: 0.6701 - val_loss: 1.3971 - val_accuracy: 0.3333\n",
      "Epoch 10/80\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.7326 - accuracy: 0.7361 - val_loss: 1.4017 - val_accuracy: 0.3333\n",
      "Epoch 11/80\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.7235 - accuracy: 0.7361 - val_loss: 1.4027 - val_accuracy: 0.3472\n",
      "Epoch 12/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7252 - accuracy: 0.7361 - val_loss: 1.4002 - val_accuracy: 0.3472\n",
      "Epoch 13/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6622 - accuracy: 0.7500 - val_loss: 1.3960 - val_accuracy: 0.3611\n",
      "Epoch 14/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6180 - accuracy: 0.7951 - val_loss: 1.3921 - val_accuracy: 0.3611\n",
      "Epoch 15/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6191 - accuracy: 0.7743 - val_loss: 1.3856 - val_accuracy: 0.3611\n",
      "Epoch 16/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5653 - accuracy: 0.8090 - val_loss: 1.3794 - val_accuracy: 0.3750\n",
      "Epoch 17/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5464 - accuracy: 0.8194 - val_loss: 1.3725 - val_accuracy: 0.4028\n",
      "Epoch 18/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4842 - accuracy: 0.8472 - val_loss: 1.3616 - val_accuracy: 0.4306\n",
      "Epoch 19/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5154 - accuracy: 0.8125 - val_loss: 1.3508 - val_accuracy: 0.4167\n",
      "Epoch 20/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4475 - accuracy: 0.8611 - val_loss: 1.3245 - val_accuracy: 0.4444\n",
      "Epoch 21/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.8403 - val_loss: 1.3013 - val_accuracy: 0.4583\n",
      "Epoch 22/80\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4378 - accuracy: 0.8611 - val_loss: 1.2875 - val_accuracy: 0.4722\n",
      "Epoch 23/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.8611 - val_loss: 1.2667 - val_accuracy: 0.5000\n",
      "Epoch 24/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8750 - val_loss: 1.2286 - val_accuracy: 0.5139\n",
      "Epoch 25/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4303 - accuracy: 0.8542 - val_loss: 1.1842 - val_accuracy: 0.5417\n",
      "Epoch 26/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8854 - val_loss: 1.1386 - val_accuracy: 0.5556\n",
      "Epoch 27/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3154 - accuracy: 0.8889 - val_loss: 1.0772 - val_accuracy: 0.5694\n",
      "Epoch 28/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.8924 - val_loss: 1.0243 - val_accuracy: 0.6250\n",
      "Epoch 29/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3234 - accuracy: 0.8924 - val_loss: 0.9892 - val_accuracy: 0.6389\n",
      "Epoch 30/80\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3334 - accuracy: 0.8993 - val_loss: 0.9537 - val_accuracy: 0.6389\n",
      "Epoch 31/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3318 - accuracy: 0.8993 - val_loss: 0.9344 - val_accuracy: 0.6250\n",
      "Epoch 32/80\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3129 - accuracy: 0.9028 - val_loss: 0.9221 - val_accuracy: 0.6250\n",
      "Epoch 33/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2834 - accuracy: 0.9201 - val_loss: 0.8943 - val_accuracy: 0.6250\n",
      "Epoch 34/80\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2732 - accuracy: 0.9097 - val_loss: 0.8836 - val_accuracy: 0.6389\n",
      "Epoch 35/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2634 - accuracy: 0.9201 - val_loss: 0.8645 - val_accuracy: 0.6528\n",
      "Epoch 36/80\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2494 - accuracy: 0.9201 - val_loss: 0.8362 - val_accuracy: 0.6667\n",
      "Epoch 37/80\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2429 - accuracy: 0.9201 - val_loss: 0.8365 - val_accuracy: 0.6667\n",
      "Epoch 38/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2049 - accuracy: 0.9340 - val_loss: 0.8366 - val_accuracy: 0.6944\n",
      "Epoch 39/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2360 - accuracy: 0.9306 - val_loss: 0.8227 - val_accuracy: 0.6944\n",
      "Epoch 40/80\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2373 - accuracy: 0.9201 - val_loss: 0.8260 - val_accuracy: 0.6944\n",
      "Epoch 41/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2377 - accuracy: 0.9410 - val_loss: 0.8272 - val_accuracy: 0.6944\n",
      "Epoch 42/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2312 - accuracy: 0.9340 - val_loss: 0.8249 - val_accuracy: 0.6944\n",
      "Epoch 43/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2237 - accuracy: 0.9236 - val_loss: 0.8210 - val_accuracy: 0.7083\n",
      "Epoch 44/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1853 - accuracy: 0.9444 - val_loss: 0.8192 - val_accuracy: 0.7500\n",
      "Epoch 45/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2088 - accuracy: 0.9306 - val_loss: 0.8217 - val_accuracy: 0.7639\n",
      "Epoch 46/80\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1651 - accuracy: 0.9618 - val_loss: 0.8335 - val_accuracy: 0.7361\n",
      "Epoch 47/80\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.1947 - accuracy: 0.9306 - val_loss: 0.8438 - val_accuracy: 0.7500\n",
      "Epoch 48/80\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1328 - accuracy: 0.9757 - val_loss: 0.8453 - val_accuracy: 0.7639\n",
      "Epoch 49/80\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1240 - accuracy: 0.9792 - val_loss: 0.8459 - val_accuracy: 0.7222\n",
      "Epoch 50/80\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1863 - accuracy: 0.9340 - val_loss: 0.8506 - val_accuracy: 0.7361\n",
      "Epoch 51/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1435 - accuracy: 0.9618 - val_loss: 0.8471 - val_accuracy: 0.7500\n",
      "Epoch 52/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1406 - accuracy: 0.9722 - val_loss: 0.8291 - val_accuracy: 0.7500\n",
      "Epoch 53/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1478 - accuracy: 0.9583 - val_loss: 0.8469 - val_accuracy: 0.7500\n",
      "Epoch 54/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1480 - accuracy: 0.9549 - val_loss: 0.8340 - val_accuracy: 0.7639\n",
      "Epoch 55/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1292 - accuracy: 0.9618 - val_loss: 0.8439 - val_accuracy: 0.7361\n",
      "Epoch 56/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1329 - accuracy: 0.9688 - val_loss: 0.8569 - val_accuracy: 0.7222\n",
      "Epoch 57/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1131 - accuracy: 0.9722 - val_loss: 0.8685 - val_accuracy: 0.7222\n",
      "Epoch 58/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1039 - accuracy: 0.9792 - val_loss: 0.8863 - val_accuracy: 0.7083\n",
      "Epoch 59/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1340 - accuracy: 0.9757 - val_loss: 0.8937 - val_accuracy: 0.7361\n",
      "Epoch 60/80\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1192 - accuracy: 0.9722 - val_loss: 0.9109 - val_accuracy: 0.7222\n",
      "Epoch 61/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1046 - accuracy: 0.9757 - val_loss: 0.9222 - val_accuracy: 0.7083\n",
      "Epoch 62/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1084 - accuracy: 0.9757 - val_loss: 0.9041 - val_accuracy: 0.7222\n",
      "Epoch 63/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1018 - accuracy: 0.9722 - val_loss: 0.9058 - val_accuracy: 0.7083\n",
      "Epoch 64/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0906 - accuracy: 0.9826 - val_loss: 0.9136 - val_accuracy: 0.7222\n",
      "Epoch 65/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1001 - accuracy: 0.9722 - val_loss: 0.9279 - val_accuracy: 0.7361\n",
      "Epoch 66/80\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0758 - accuracy: 0.9931 - val_loss: 0.9259 - val_accuracy: 0.7222\n",
      "Epoch 67/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0912 - accuracy: 0.9826 - val_loss: 0.9311 - val_accuracy: 0.7222\n",
      "Epoch 68/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0739 - accuracy: 0.9861 - val_loss: 0.9414 - val_accuracy: 0.7222\n",
      "Epoch 69/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0768 - accuracy: 0.9826 - val_loss: 0.9388 - val_accuracy: 0.7083\n",
      "Epoch 70/80\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0901 - accuracy: 0.9826 - val_loss: 0.9479 - val_accuracy: 0.7222\n",
      "Epoch 71/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0812 - accuracy: 0.9792 - val_loss: 0.9562 - val_accuracy: 0.7222\n",
      "Epoch 72/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0658 - accuracy: 0.9792 - val_loss: 0.9695 - val_accuracy: 0.7361\n",
      "Epoch 73/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0728 - accuracy: 0.9792 - val_loss: 0.9933 - val_accuracy: 0.7083\n",
      "Epoch 74/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0568 - accuracy: 0.9896 - val_loss: 1.0105 - val_accuracy: 0.7222\n",
      "Epoch 75/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0679 - accuracy: 0.9826 - val_loss: 1.0022 - val_accuracy: 0.7222\n",
      "Epoch 76/80\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0537 - accuracy: 0.9931 - val_loss: 1.0152 - val_accuracy: 0.7222\n",
      "Epoch 77/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0528 - accuracy: 0.9931 - val_loss: 1.0451 - val_accuracy: 0.7222\n",
      "Epoch 78/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0559 - accuracy: 0.9931 - val_loss: 1.0509 - val_accuracy: 0.7222\n",
      "Epoch 79/80\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0517 - accuracy: 0.9931 - val_loss: 1.0647 - val_accuracy: 0.7222\n",
      "Epoch 80/80\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0646 - accuracy: 0.9826 - val_loss: 1.0680 - val_accuracy: 0.7083\n"
     ]
    }
   ],
   "source": [
    "history14 = model14.fit(X2_train_scaled[:,13:], y2_train, \n",
    "                    validation_data=(X2_val_scaled[:,13:], y2_val), \n",
    "                    batch_size=16, epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d483091",
   "metadata": {},
   "source": [
    "**Mel Spectrogram + MFCCs + Tonnetz + Centroid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c8b84a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X2_train_scaled_4 = np.concatenate([X2_train_scaled[:,7:9],X2_train_scaled[:,13:]],axis=1)\n",
    "X2_val_scaled_4 = np.concatenate([X2_val_scaled[:,7:9],X2_val_scaled[:,13:]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5c71a81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1D_1 (Conv1D)           (None, 46, 16)            96        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 46, 16)            64        \n",
      "                                                                 \n",
      " MaxPooling1 (MaxPooling1D)  (None, 23, 16)            0         \n",
      "                                                                 \n",
      " Conv1D_2 (Conv1D)           (None, 23, 32)            3616      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 23, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling2 (MaxPooling1D)  (None, 11, 32)            0         \n",
      "                                                                 \n",
      " Conv1D_3 (Conv1D)           (None, 11, 32)            7200      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 11, 32)            128       \n",
      "                                                                 \n",
      " MaxPooling3 (MaxPooling1D)  (None, 5, 32)             0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 160)               0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               20608     \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Softmax (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,356\n",
      "Trainable params: 40,196\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 15\n",
    "\n",
    "model15 = modelBuilder3L(X2_train_scaled_4,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93993958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 32ms/step - loss: 2.0445 - accuracy: 0.2639 - val_loss: 1.3870 - val_accuracy: 0.3889\n",
      "Epoch 2/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5378 - accuracy: 0.3507 - val_loss: 1.3924 - val_accuracy: 0.2361\n",
      "Epoch 3/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2433 - accuracy: 0.4583 - val_loss: 1.3999 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.2135 - accuracy: 0.4722 - val_loss: 1.4099 - val_accuracy: 0.2500\n",
      "Epoch 5/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0698 - accuracy: 0.5694 - val_loss: 1.4206 - val_accuracy: 0.2500\n",
      "Epoch 6/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9613 - accuracy: 0.5938 - val_loss: 1.4304 - val_accuracy: 0.2500\n",
      "Epoch 7/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9002 - accuracy: 0.6458 - val_loss: 1.4432 - val_accuracy: 0.2500\n",
      "Epoch 8/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8897 - accuracy: 0.6181 - val_loss: 1.4593 - val_accuracy: 0.2500\n",
      "Epoch 9/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8259 - accuracy: 0.6597 - val_loss: 1.4723 - val_accuracy: 0.2500\n",
      "Epoch 10/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7711 - accuracy: 0.7118 - val_loss: 1.4886 - val_accuracy: 0.2500\n",
      "Epoch 11/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.7601 - accuracy: 0.7257 - val_loss: 1.4999 - val_accuracy: 0.2500\n",
      "Epoch 12/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7063 - accuracy: 0.7153 - val_loss: 1.5125 - val_accuracy: 0.2500\n",
      "Epoch 13/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6480 - accuracy: 0.7847 - val_loss: 1.5170 - val_accuracy: 0.2500\n",
      "Epoch 14/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5839 - accuracy: 0.7847 - val_loss: 1.5205 - val_accuracy: 0.2500\n",
      "Epoch 15/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6147 - accuracy: 0.7465 - val_loss: 1.5250 - val_accuracy: 0.2500\n",
      "Epoch 16/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5711 - accuracy: 0.7882 - val_loss: 1.5263 - val_accuracy: 0.2500\n",
      "Epoch 17/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5676 - accuracy: 0.8021 - val_loss: 1.5119 - val_accuracy: 0.2361\n",
      "Epoch 18/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5593 - accuracy: 0.7951 - val_loss: 1.4910 - val_accuracy: 0.2361\n",
      "Epoch 19/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5212 - accuracy: 0.8299 - val_loss: 1.4721 - val_accuracy: 0.2500\n",
      "Epoch 20/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8750 - val_loss: 1.4496 - val_accuracy: 0.2778\n",
      "Epoch 21/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4692 - accuracy: 0.8229 - val_loss: 1.4302 - val_accuracy: 0.2778\n",
      "Epoch 22/80\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4503 - accuracy: 0.8368 - val_loss: 1.3952 - val_accuracy: 0.3056\n",
      "Epoch 23/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4617 - accuracy: 0.8576 - val_loss: 1.3592 - val_accuracy: 0.3056\n",
      "Epoch 24/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8819 - val_loss: 1.3198 - val_accuracy: 0.3472\n",
      "Epoch 25/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8646 - val_loss: 1.2662 - val_accuracy: 0.3889\n",
      "Epoch 26/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.8750 - val_loss: 1.2050 - val_accuracy: 0.4444\n",
      "Epoch 27/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3711 - accuracy: 0.8576 - val_loss: 1.1245 - val_accuracy: 0.5000\n",
      "Epoch 28/80\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3439 - accuracy: 0.9062 - val_loss: 1.0707 - val_accuracy: 0.5278\n",
      "Epoch 29/80\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3464 - accuracy: 0.9062 - val_loss: 1.0168 - val_accuracy: 0.5417\n",
      "Epoch 30/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2997 - accuracy: 0.9062 - val_loss: 0.9603 - val_accuracy: 0.5694\n",
      "Epoch 31/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3077 - accuracy: 0.9028 - val_loss: 0.9021 - val_accuracy: 0.5972\n",
      "Epoch 32/80\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3176 - accuracy: 0.8854 - val_loss: 0.8626 - val_accuracy: 0.6250\n",
      "Epoch 33/80\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.2824 - accuracy: 0.9167 - val_loss: 0.8427 - val_accuracy: 0.6389\n",
      "Epoch 34/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2854 - accuracy: 0.9097 - val_loss: 0.8219 - val_accuracy: 0.6389\n",
      "Epoch 35/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2969 - accuracy: 0.9028 - val_loss: 0.7951 - val_accuracy: 0.6667\n",
      "Epoch 36/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3029 - accuracy: 0.9028 - val_loss: 0.7665 - val_accuracy: 0.7222\n",
      "Epoch 37/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2932 - accuracy: 0.9271 - val_loss: 0.7587 - val_accuracy: 0.7222\n",
      "Epoch 38/80\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.2414 - accuracy: 0.9167 - val_loss: 0.7559 - val_accuracy: 0.7083\n",
      "Epoch 39/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2055 - accuracy: 0.9479 - val_loss: 0.7571 - val_accuracy: 0.7361\n",
      "Epoch 40/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2287 - accuracy: 0.9167 - val_loss: 0.7553 - val_accuracy: 0.7361\n",
      "Epoch 41/80\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2428 - accuracy: 0.9236 - val_loss: 0.7714 - val_accuracy: 0.6944\n",
      "Epoch 42/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2008 - accuracy: 0.9306 - val_loss: 0.7567 - val_accuracy: 0.7083\n",
      "Epoch 43/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1671 - accuracy: 0.9549 - val_loss: 0.7568 - val_accuracy: 0.6944\n",
      "Epoch 44/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1889 - accuracy: 0.9375 - val_loss: 0.7582 - val_accuracy: 0.7083\n",
      "Epoch 45/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1709 - accuracy: 0.9653 - val_loss: 0.7791 - val_accuracy: 0.7083\n",
      "Epoch 46/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1821 - accuracy: 0.9410 - val_loss: 0.7855 - val_accuracy: 0.7083\n",
      "Epoch 47/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1819 - accuracy: 0.9410 - val_loss: 0.7908 - val_accuracy: 0.6944\n",
      "Epoch 48/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1392 - accuracy: 0.9653 - val_loss: 0.7918 - val_accuracy: 0.6944\n",
      "Epoch 49/80\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1608 - accuracy: 0.9618 - val_loss: 0.7929 - val_accuracy: 0.6944\n",
      "Epoch 50/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1651 - accuracy: 0.9479 - val_loss: 0.7722 - val_accuracy: 0.7222\n",
      "Epoch 51/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1565 - accuracy: 0.9514 - val_loss: 0.7668 - val_accuracy: 0.7500\n",
      "Epoch 52/80\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.9514 - val_loss: 0.7928 - val_accuracy: 0.7222\n",
      "Epoch 53/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1242 - accuracy: 0.9792 - val_loss: 0.7968 - val_accuracy: 0.7222\n",
      "Epoch 54/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1368 - accuracy: 0.9618 - val_loss: 0.8031 - val_accuracy: 0.6944\n",
      "Epoch 55/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1180 - accuracy: 0.9861 - val_loss: 0.7965 - val_accuracy: 0.6944\n",
      "Epoch 56/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1098 - accuracy: 0.9653 - val_loss: 0.8221 - val_accuracy: 0.6944\n",
      "Epoch 57/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1401 - accuracy: 0.9722 - val_loss: 0.8570 - val_accuracy: 0.6806\n",
      "Epoch 58/80\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9861 - val_loss: 0.8501 - val_accuracy: 0.6944\n",
      "Epoch 59/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1101 - accuracy: 0.9653 - val_loss: 0.8366 - val_accuracy: 0.7083\n",
      "Epoch 60/80\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.1012 - accuracy: 0.9792 - val_loss: 0.8423 - val_accuracy: 0.7222\n",
      "Epoch 61/80\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1134 - accuracy: 0.9722 - val_loss: 0.8250 - val_accuracy: 0.7361\n",
      "Epoch 62/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0752 - accuracy: 0.9861 - val_loss: 0.8217 - val_accuracy: 0.7361\n",
      "Epoch 63/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0773 - accuracy: 0.9826 - val_loss: 0.8251 - val_accuracy: 0.7361\n",
      "Epoch 64/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0954 - accuracy: 0.9757 - val_loss: 0.8344 - val_accuracy: 0.7361\n",
      "Epoch 65/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0994 - accuracy: 0.9792 - val_loss: 0.8579 - val_accuracy: 0.7222\n",
      "Epoch 66/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0853 - accuracy: 0.9861 - val_loss: 0.8594 - val_accuracy: 0.7222\n",
      "Epoch 67/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0958 - accuracy: 0.9688 - val_loss: 0.8657 - val_accuracy: 0.7222\n",
      "Epoch 68/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0976 - accuracy: 0.9722 - val_loss: 0.8577 - val_accuracy: 0.7083\n",
      "Epoch 69/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0741 - accuracy: 0.9861 - val_loss: 0.8642 - val_accuracy: 0.7083\n",
      "Epoch 70/80\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0775 - accuracy: 0.9757 - val_loss: 0.8703 - val_accuracy: 0.7083\n",
      "Epoch 71/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0697 - accuracy: 0.9896 - val_loss: 0.9033 - val_accuracy: 0.6944\n",
      "Epoch 72/80\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0927 - accuracy: 0.9757 - val_loss: 0.9023 - val_accuracy: 0.7222\n",
      "Epoch 73/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0735 - accuracy: 0.9861 - val_loss: 0.9288 - val_accuracy: 0.6806\n",
      "Epoch 74/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0600 - accuracy: 0.9896 - val_loss: 0.9139 - val_accuracy: 0.7083\n",
      "Epoch 75/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0726 - accuracy: 0.9722 - val_loss: 0.9293 - val_accuracy: 0.7361\n",
      "Epoch 76/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0604 - accuracy: 0.9896 - val_loss: 0.9540 - val_accuracy: 0.6667\n",
      "Epoch 77/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0627 - accuracy: 0.9861 - val_loss: 0.9537 - val_accuracy: 0.6667\n",
      "Epoch 78/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.9792 - val_loss: 0.9546 - val_accuracy: 0.6667\n",
      "Epoch 79/80\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0661 - accuracy: 0.9826 - val_loss: 0.9898 - val_accuracy: 0.6528\n",
      "Epoch 80/80\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0745 - accuracy: 0.9688 - val_loss: 0.9982 - val_accuracy: 0.6528\n"
     ]
    }
   ],
   "source": [
    "history15 = model15.fit(X2_train_scaled_4, y2_train, \n",
    "                    validation_data=(X2_val_scaled_4, y2_val), \n",
    "                    batch_size=16, epochs=80)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7010ec1e",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "### 4.1 Model Evaluation For Dataset1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "17665928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train and Validation accuracy and loss\n",
    "f = plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('train validation accuracy')\n",
    "plt.plot(history11.history['accuracy'])\n",
    "plt.plot(history11.history['val_accuracy'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('train validation loss')\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4aeb3bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_prob = model1.predict(X1_test_scaled)\n",
    "y_pred = np.argmax(y_prob, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "61f7d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc_1d = round(accuracy_score(y_pred,y1_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "66767ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_1d = confusion_matrix(y1_test,y_pred)\n",
    "cm_display_1d = ConfusionMatrixDisplay(confusion_matrix = cm_1d, display_labels = ['Angry', 'Happy', 'Relaxed', 'Sad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9dac2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.66      0.64      0.65        45\n",
      "       Happy       0.44      0.44      0.44        45\n",
      "     Relaxed       0.44      0.62      0.52        45\n",
      "         Sad       0.54      0.33      0.41        45\n",
      "\n",
      "    accuracy                           0.51       180\n",
      "   macro avg       0.52      0.51      0.51       180\n",
      "weighted avg       0.52      0.51      0.51       180\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(y1_test, y_pred, target_names = ['Angry', 'Happy', 'Relaxed', 'Sad']))\n",
    "cm_display_1d.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9e1b5cae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train and Validation accuracy and loss\n",
    "f = plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('train validation accuracy')\n",
    "plt.plot(history11.history['accuracy'])\n",
    "plt.plot(history11.history['val_accuracy'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('train validation loss')\n",
    "plt.plot(history11.history['loss'])\n",
    "plt.plot(history11.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8a6d039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_prob = model11.predict(X2_test_scaled)\n",
    "y_pred = np.argmax(y_prob, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "05c0ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc_1d = round(accuracy_score(y_pred,y2_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "470773d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_1d = confusion_matrix(y2_test,y_pred)\n",
    "cm_display_1d = ConfusionMatrixDisplay(confusion_matrix = cm_1d, display_labels = ['Angry', 'Happy', 'Relaxed', 'Sad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f25642c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model11.save('Features1D/Model/Conv1D.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7f32ad08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.90      0.90      0.90        10\n",
      "       Happy       0.77      1.00      0.87        10\n",
      "     Relaxed       0.78      0.70      0.74        10\n",
      "         Sad       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.82        40\n",
      "   macro avg       0.83      0.82      0.82        40\n",
      "weighted avg       0.83      0.82      0.82        40\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAG2CAYAAABGXj3fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIxUlEQVR4nO3deVxU9f4/8NewDfuiiAiiYiiC4n41t5RvGNzUoMzMXHDB7nVfIrfCXckdta5aImjXNUt/hqYphQu4JGpqGe5JrrgAArHNfH5/cJ0aQWWY7TDzej4e5/Hw7O9zGJk378/nfI5MCCFAREREZEAWxg6AiIiIzA8TECIiIjI4JiBERERkcExAiIiIyOCYgBAREZHBMQEhIiIig2MCQkRERAbHBISIiIgMjgkIERERGRwTECIiIjI4JiBERESk5tChQ+jVqxe8vLwgk8mwc+dOtfVCCEyfPh116tSBnZ0dQkJCcOnSJY3OwQSEiIiI1OTn56NFixb47LPPKly/cOFCrFixAqtXr8bx48fh4OCA0NBQFBYWVvocMr6MjoiIiJ5FJpNhx44diIiIAFBW/fDy8sIHH3yA6OhoAEBOTg5q166NxMREvPvuu5U6rpW+AqbnUyqVuHXrFpycnCCTyYwdDhERaUAIgcePH8PLywsWFvprTCgsLERxcbHWxxFClPuukcvlkMvlGh/r2rVruHPnDkJCQlTLXFxc0L59exw9epQJiNTdunULPj4+xg6DiIi0kJmZibp16+rl2IWFhfCt74g79xRaH8vR0RF5eXlqy2bMmIGZM2dqfKw7d+4AAGrXrq22vHbt2qp1lcEExEicnJwAAFtSfWHvyK44hrAi4nVjh2B2Sq/dMHYIRHpRihIcwR7V73J9KC4uxp17Cvye3gDOTlX/nsh9rET9NteRmZkJZ2dn1fKqVD90iQmIkTwphdk7WsDBydLI0ZgHKwvj/mczSzJrY0dApB//6z1piCZ0RycZHJ2qfh4lyvZ1dnZWS0CqytPTEwBw9+5d1KlTR7X87t27aNmyZaWPwz+9iYiIJEwhlFpPuuTr6wtPT08kJyerluXm5uL48ePo0KFDpY/DCggREZGEKSGgRNUfWK3Kvnl5ebh8+bJq/tq1azhz5gxq1KiBevXqYfz48Zg7dy4aNWoEX19fxMTEwMvLS/WkTGUwASEiIiI1J0+eRHBwsGp+4sSJAIDIyEgkJiZi0qRJyM/Px/vvv4/s7Gx07twZe/fuha2tbaXPwQSEiIhIwpRQQptGlKrs3a1bNzxvmDCZTIbZs2dj9uzZVY6LCQgREZGEKYSAQosxQ7XZV5/YCZWIiIgMjhUQIiIiCTNGJ1RDYAJCREQkYUoIKEwwAWETDBERERkcKyBEREQSxiYYIiIiMjg+BUNERESkI6yAEBERSZjyf5M2+0sRExAiIiIJU2j5FIw2++oTExAiIiIJU4iySZv9pYh9QIiIiMjgWAEhIiKSMPYBISIiIoNTQgYFZFrtL0VsgiEiIiKDYwWEiIhIwpSibNJmfyliAkJERCRhCi2bYLTZV5/YBENEREQGxwoIERGRhJlqBYQJCBERkYQphQxKocVTMFrsq09sgiEiIiKDYwWEiIhIwtgEQ0RERAangAUUWjRYKHQYiy4xASEiIpIwoWUfEME+IERERERlWAEhIiKSMPYBISIiIoNTCAsohBZ9QCQ6FDubYIiIiMjgWAEhIiKSMCVkUGpRL1BCmiUQJiBEREQSZqp9QNgEQ0RERAbHCggREZGEad8JlU0wREREpKGyPiBavIyOTTBEREREZVgBoUopyrPAoWW1cfF7FxQ8sELtwD8RMv0WvJr/aezQTFLTFvfR+73L8PPPRk33IsyZ2g7HDtcxdlgmr9fg+3h7xD3UqFWKq7/a4T8feyPjjL2xwzJZvN+Vo9TyXTBSfQqmWldAjh49CktLS/To0cPYoZi876bWxfVUJ/Rakolhey7Ct0setgxsiMd3mMPqg62dAtcuu2DV0ubGDsVsdH3jEd6fcQsbl3piVGhjXP3VFvM2XYVLzRJjh2aSeL8r70kfEG0mKZJmVJUUHx+PMWPG4NChQ7h165bez1dcXKz3c0hRSaEMv+1zQfDk26jXLh81GhSjy7i7cKtfhFMbaxo7PJOUfqw2vvwiAEcPeRk7FLPx1vv3sXdTDXy/tQZuXLLFisl1UfSnDKH9Hho7NJPE+115SlhoPUmRNKOqhLy8PGzduhUjRoxAjx49kJiYqFqXkpICmUyG5ORktG3bFvb29ujYsSMyMjLUjjF37lx4eHjAyckJUVFRmDJlClq2bKlaP3jwYERERGDevHnw8vKCv78/Zs+ejWbNmpWLp2XLloiJidHX5RqVslQGoZDByka9jGdlK/BHuoORoiLSHStrJRo1L8Cpw06qZULIcPqwEwLbFBgxMtPE+01ANU5Atm3bhiZNmsDf3x8DBgzAunXrIJ561Oijjz7CkiVLcPLkSVhZWWHo0KGqdRs3bsS8efOwYMECpKeno169eli1alW58yQnJyMjIwP79+9HUlIShg4digsXLuCnn35SbXP69GmcPXsWQ4YMeWa8RUVFyM3NVZuqC7mjEt6t8pH6mQce37WCUgGc3+mKm6ftkXfP2tjhEWnNuYYCllZAdpZ6k+Kj+1Zwq1VqpKhMF++3ZhRCpvUkRdU2AYmPj8eAAQMAAGFhYcjJycHBgwfVtpk3bx66du2KwMBATJkyBWlpaSgsLAQArFy5EsOGDcOQIUPQuHFjTJ8+HUFBQeXO4+DggLVr16Jp06Zo2rQp6tati9DQUCQkJKi2SUhIQNeuXdGwYcNnxhsbGwsXFxfV5OPjo4vbYDC9lmRCCODTjoFYGBCEk+vdEdgrGzILaXZuIiIyFYr/dULVZpIiaUb1AhkZGThx4gT69esHALCyskLfvn0RHx+vtl3z5n914KtTp+wJgnv37qmO0a5dO7Xtn54HgKCgINjY2KgtGz58ODZv3ozCwkIUFxdj06ZNatWVikydOhU5OTmqKTMzs5JXKw1u9YsxYPNVfHDuHEYfuYDBOy5DWSKDq4959osh05L70BKKUsD1qb++3dxL8SiLHa11jfebgGr6GG58fDxKS0vh5fVXBz0hBORyOT799FPVMmvrv5oHZLKyEpRSqdToXA4O5fs49OrVC3K5HDt27ICNjQ1KSkrw9ttvP/c4crkccrlco3NLkY29gI19Kf7MscTVw04Innzb2CERaa20xAKXztqjVefHOLrXBQAgkwm07JyHXYnsaK1rvN+aUQoLKLV4kkXJkVB1o7S0FBs2bMCSJUvw2muvqa2LiIjA5s2b0aRJkxcex9/fHz/99BMGDRqkWvb3fh3PY2VlhcjISCQkJMDGxgbvvvsu7OzsNLuQaubqIUcIAdRsWIRHv8vxwyd1UPOlQjR/mz3W9cHWrhRe3vmqec86BWjol4PHj62RdZfjJOjDN5+7IzouExd/tkfGaXu8OTwLtvZKfL+lhrFDM0m835WnbTOKQqLjgFS7BCQpKQmPHj3CsGHD4OLioraud+/eiI+Px6JFi154nDFjxmD48OFo27YtOnbsiK1bt+Ls2bPP7cfxd1FRUQgICAAApKaman4h1UzRY0ukLPbE4zvWsHVRwD8sB10/uANL9kHVi0ZNsvHJyr8+V8PHngcAHNjjg2XzWxsrLJN2cJcbXGoqMOjDO3CrVYqrv9jho/6+yL7PD7k+8H5TtUtA4uPjERISUi75AMoSkIULF+Ls2bMvPE7//v1x9epVREdHo7CwEO+88w4GDx6MEydOVCqORo0aoWPHjnj48CHat2+v8XVUNwE9chDQI8fYYZiNc6fd0aNzuLHDMDu7EtyxK8Hd2GGYDd7vylECWj3JolnHA8OpdgnIt99++8x17dq1Uz2KO3bsWLV1LVu2LPeYbkxMjNrYHd27d4efn59q/u9jizxNCIFbt25h5MiRmoRPRESkEW0HE5PqQGTVLgHRlYKCAqxevRqhoaGwtLTE5s2bceDAAezfv/+F+2ZlZWHLli24c+fOc8f+ICIiooqZbQIik8mwZ88ezJs3D4WFhfD398fXX3+NkJCQF+7r4eEBd3d3fP7553BzczNAtEREZK60fZ+LVN8FY7YJiJ2dHQ4cOFClfZ9uyiEiItIXJWRQQps+INIcCdVsExAiIqLqwFQrINKMioiIiEwaKyBEREQSpv1AZNKsNTABISIikjClkEGpzTggfBsuERERURlWQIiIiCRMqWUTDAciIyIiIo1p/zZcaSYg0oyKiIiITBorIERERBKmgAwKLQYT02ZffWICQkREJGFsgiEiIiLSEVZAiIiIJEwB7ZpRFLoLRaeYgBAREUmYqTbBMAEhIiKSML6MjoiIiEyeQqFATEwMfH19YWdnh5deeglz5syBEEKn52EFhIiISMIEZFBq0QdEaLjvggULsGrVKqxfvx5NmzbFyZMnMWTIELi4uGDs2LFVjuNpTECIiIgkzNBNMGlpaQgPD0ePHj0AAA0aNMDmzZtx4sSJKsdQETbBEBERmYHc3Fy1qaioqMLtOnbsiOTkZFy8eBEA8PPPP+PIkSP45z//qdN4WAEhIiKSMKWQQSmq3gTzZF8fHx+15TNmzMDMmTPLbT9lyhTk5uaiSZMmsLS0hEKhwLx589C/f/8qx1ARJiBEREQSptDybbhP9s3MzISzs7NquVwur3D7bdu2YePGjdi0aROaNm2KM2fOYPz48fDy8kJkZGSV43gaExAiIiIz4OzsrJaAPMuHH36IKVOm4N133wUABAUF4ffff0dsbCwTECIiInOhqyaYyiooKICFhXrFxdLSEkqlssoxVIQJCBERkYQpYQGlFk0wmu7bq1cvzJs3D/Xq1UPTpk1x+vRpLF26FEOHDq1yDBVhAkJEREQqK1euRExMDEaOHIl79+7By8sL//rXvzB9+nSdnocJCBERkYQphAwKLZpgNN3XyckJcXFxiIuLq/I5K4MJCBERkYQZug+IoTABISIikjCh5dtwBV9GR0RERFSGFRAiIiIJU0AGhRYvo9NmX31iAkJERCRhSqFdPw6l0GEwOsQmGCIiIjI4VkCIiIgkTKllJ1Rt9tUnJiBEREQSpoQMSi36cWizrz5JMy0iIiIik8YKCBERkYQZeiRUQ2ECQkREJGHsA0J6sbRFM1jJrI0dhlnYd2unsUMwO6FeLY0dAhFJFBMQIiIiCVNCy3fBSLQTKhMQIiIiCRNaPgUjmIAQERGRpkz1bbjS7JlCREREJo0VECIiIgnjUzBERERkcGyCISIiItIRVkCIiIgkzFTfBcMEhIiISMLYBENERESkI6yAEBERSZipVkCYgBAREUmYqSYgbIIhIiIig2MFhIiISMJMtQLCBISIiEjCBLR7lFboLhSdYgJCREQkYaZaAWEfECIiIjI4VkCIiIgkzFQrIExAiIiIJMxUExA2wRAREZHBsQJCREQkYaZaAWECQkREJGFCyCC0SCK02Vef2ARDREREBscKCBERkYQpIdNqIDJt9tUnJiBEREQSZqp9QNgEQ0RERAbHCggREZGEmWonVCYgREREEmaqTTBMQIiIiCTMVCsg7ANCREREBscKCBERkYQJLZtgpFoBYQJCREQkYQKAENrtL0VsgiEiIiKDYwWEiIhIwpSQQcaRUImIiMiQ+BQMERERkY6wAkJERCRhSiGDjAORERERkSEJoeVTMBJ9DIZNMERERGRwrIAQERFJGDuhktnrNfg+1h//Fd9ePYvlSZfg37LA2CGZjHPHHDB9kC/6tWqKUK+WSPvORW29EMD6hZ7o17IpejVsjsnvvISbV22MFK3p4mfcsHi/K+dJAqLNJEVMQKhSur7xCO/PuIWNSz0xKrQxrv5qi3mbrsKlZomxQzMJhQUWaNj0T4ye/0eF67d95oH/t64WxnySieVJF2Frr8S0915CcaE0f7FUR/yMGxbvd+U9eRuuNpMUVYsEZPDgwYiIiCi3PCUlBTKZDNnZ2QaPydy89f597N1UA99vrYEbl2yxYnJdFP0pQ2i/h8YOzST84/8eY/DkO+j0z5xy64QAdq6thX7j7qBjWC4aBhZi0orf8eCuNdL2ulRwNKoKfsYNi/ebqkUCQsZlZa1Eo+YFOHXYSbVMCBlOH3ZCYBuWTPXtzg0bPLxnjdZd8lTLHJyVaNKqABfSHYwYmengZ9yweL818+QpGG0mKTKZBOTBgwfo168fvL29YW9vj6CgIGzevFltm27dumH06NEYPXo0XFxc4O7ujpiYGIi//XQaNGiAOXPmoF+/fnBwcIC3tzc+++wz1fqhQ4eiZ8+easctKSmBh4cH4uPj9XuRRuJcQwFLKyA7S73P8qP7VnCrVWqkqMzHw3tl9921lnpp2rVWiWodaYefccPi/dZMWRKhTR8QY19BxUwmASksLESbNm2we/dunD9/Hu+//z4GDhyIEydOqG23fv16WFlZ4cSJE1i+fDmWLl2KtWvXqm2zaNEitGjRAqdPn8aUKVMwbtw47N+/HwAQFRWFvXv34vbt26rtk5KSUFBQgL59+z4zvqKiIuTm5qpNRERE5qra/PmUlJQER0dHtWUKhUL1b29vb0RHR6vmx4wZg3379mHbtm1o166darmPjw+WLVsGmUwGf39/nDt3DsuWLcPw4cNV23Tq1AlTpkwBADRu3BipqalYtmwZunfvjo4dO8Lf3x9ffvklJk2aBABISEhAnz59ysX3d7GxsZg1a5Z2N8FIch9aQlEKuD71l4mbeykeZVWbj1C1VcOj7L5nZ1mjZu2/fgbZWdZ4qemfxgrLpPAzbli835rhY7hGFhwcjDNnzqhNf69cKBQKzJkzB0FBQahRowYcHR2xb98+3LhxQ+04L7/8MmSyv34YHTp0wKVLl9SSmQ4dOqjt06FDB1y4cEE1HxUVhYSEBADA3bt38d1332Ho0KHPjX/q1KnIyclRTZmZmZrfBCMpLbHApbP2aNX5sWqZTCbQsnMefk23N2Jk5sGzXjFqeJTg9JG/Etz8xxb47bQ9AtrkGzEy08HPuGHxfmtG6GCSomqTajo4OMDPz09t2R9//PXI4qJFi7B8+XLExcUhKCgIDg4OGD9+PIqLi3Uey6BBgzBlyhQcPXoUaWlp8PX1RZcuXZ67j1wuh1wu13kshvLN5+6IjsvExZ/tkXHaHm8Oz4KtvRLfb6lh7NBMwp/5Frh17a/Px51MG1w5bwcn11J41C1BRFQWNi+vDW/fInjWK8b6hXVQs3YJOoaVf2qGqoafccPi/aZqk4C8SGpqKsLDwzFgwAAAgFKpxMWLFxEYGKi23fHjx9Xmjx07hkaNGsHS0lJt2dPbBAQEqOZr1qyJiIgIJCQk4OjRoxgyZIiuL0dyDu5yg0tNBQZ9eAdutUpx9Rc7fNTfF9n3rY0dmkm4+LM9Jr39V4K9ZqY3AKD7Ow8RHXcD74y6h8ICCyyf5IO8XEs0/Uc+5m28Chtbqf5tU/3wM25YvN+VZ6pNMCaTgDRq1Ajbt29HWloa3NzcsHTpUty9e7dcAnLjxg1MnDgR//rXv3Dq1CmsXLkSS5YsUdsmNTUVCxcuREREBPbv34+vvvoKu3fvVtsmKioKPXv2hEKhQGRkpN6vTwp2JbhjV4K7scMwSS065mHfrTPPXC+TAZGT7iBy0h3DBWWG+Bk3LN7vStK2HUWif6dUmz4gL/Lxxx+jdevWCA0NRbdu3eDp6Vnh4GWDBg3Cn3/+iXbt2mHUqFEYN24c3n//fbVtPvjgA5w8eRKtWrXC3LlzsXTpUoSGhqptExISgjp16iA0NBReXl76vDQiIjJn2g7DXoUKyM2bNzFgwADUrFkTdnZ2CAoKwsmTJ3V6WdWiApKYmFjh8m7duqmN4bFz584XHsva2hpxcXFYtWrVM7dxdnbGtm3bnnuc/Px8PHr0CMOGDXvhOYmIiKqLR48eoVOnTggODsZ3332HWrVq4dKlS3Bzc9PpeapFAiIlSqUS9+/fx5IlS+Dq6oo33njD2CEREZEJ03Y0U033XbBgAXx8fFRPewKAr69v1QN4BpNpgjGUGzduoHbt2ti0aRPWrVsHKyvmcEREpD+6ehvu04NhFhUVVXi+Xbt2oW3btujTpw88PDzQqlUrfPHFFzq/LrP69kxJSXnhNtevX3/u+gYNGqg1+xAREVUHPj4+avMzZszAzJkzy2139epVrFq1ChMnTsS0adPw008/YezYsbCxsdHpQxdmlYAQERFVO1XsSKq2P4DMzEw4OzurFj9rbCqlUom2bdti/vz5AIBWrVrh/PnzWL16tU4TEDbBEBERSZiu3obr7OysNj0rAalTp065ISwCAgLKjSyuLSYgREREpNKpUydkZGSoLbt48SLq16+v0/MwASEiIpIyA78MZsKECTh27Bjmz5+Py5cvY9OmTfj8888xatQo3VzP/1SqD8iuXbsqfUA+lkpERKQ7hh6K/R//+Ad27NiBqVOnYvbs2fD19UVcXBz69+9f5RgqUqkEpKIRRSsik8nU3ipLRERE1U/Pnj3Rs2dPvZ6jUgmIUqnUaxBERET0HCY4+oNWj+EWFhbC1tZWV7EQERHRU0z1bbgad0JVKBSYM2cOvL294ejoiKtXrwIAYmJiEB8fr/MAiYiIzJqBO6EaisYJyLx585CYmIiFCxfCxsZGtbxZs2ZYu3atToMjIiIi06RxArJhwwZ8/vnn6N+/PywtLVXLW7Rogd9++02nwREREZFMB5P0aNwH5ObNm/Dz8yu3XKlUoqSkRCdBERER0f9o24xiKk0wgYGBOHz4cLnl27dvR6tWrXQSFBEREZk2jSsg06dPR2RkJG7evAmlUolvvvkGGRkZ2LBhA5KSkvQRIxERkfliBaRMeHg4vv32Wxw4cAAODg6YPn06Lly4gG+//Rbdu3fXR4xERETm68nbcLWZJKhK44B06dIF+/fv13UsREREZCaqPBDZyZMnceHCBQBl/ULatGmjs6CIiIiojBBlkzb7S5HGCcgff/yBfv36ITU1Fa6urgCA7OxsdOzYEVu2bEHdunV1HSMREZH5Yh+QMlFRUSgpKcGFCxfw8OFDPHz4EBcuXIBSqURUVJQ+YiQiIiITo3EF5ODBg0hLS4O/v79qmb+/P1auXIkuXbroNDgiIiKzp21HUlPphOrj41PhgGMKhQJeXl46CYqIiIjKyETZpM3+UqRxE8yiRYswZswYnDx5UrXs5MmTGDduHBYvXqzT4IiIiMyeib6MrlIVEDc3N8hkf5Vw8vPz0b59e1hZle1eWloKKysrDB06FBEREXoJlIiIiExHpRKQuLg4PYdBREREFTLnPiCRkZH6joOIiIgqYqKP4VZ5IDIAKCwsRHFxsdoyZ2dnrQIiIiIi06dxJ9T8/HyMHj0aHh4ecHBwgJubm9pEREREOmSinVA1TkAmTZqEH374AatWrYJcLsfatWsxa9YseHl5YcOGDfqIkYiIyHyZaAKicRPMt99+iw0bNqBbt24YMmQIunTpAj8/P9SvXx8bN25E//799REnERERmRCNKyAPHz5Ew4YNAZT193j48CEAoHPnzjh06JBuoyMiIjJ3T56C0WaSII0TkIYNG+LatWsAgCZNmmDbtm0AyiojT15OR0RERLrxZCRUbSYp0jgBGTJkCH7++WcAwJQpU/DZZ5/B1tYWEyZMwIcffqjzAImIiMj0aNwHZMKECap/h4SE4LfffkN6ejr8/PzQvHlznQZHRERk9jgOSMXq16+P+vXr6yIWIiIiMhOVSkBWrFhR6QOOHTu2ysEQERGROhm0fBuuziLRrUolIMuWLavUwWQyGRMQIiIieqFKJSBPnnoh3bPyrQcrC7mxwzALPTo3MHYI5ie51NgRmBWr4Vq3qlNlKYsAQ301mvPL6IiIiMhITLQTqsaP4RIRERFpixUQIiIiKTPRCggTECIiIgnTdjRTkxkJlYiIiEhbVUpADh8+jAEDBqBDhw64efMmAODLL7/EkSNHdBocERGR2RM6mCRI4wTk66+/RmhoKOzs7HD69GkUFRUBAHJycjB//nydB0hERGTWmICUmTt3LlavXo0vvvgC1tbWquWdOnXCqVOndBocERERmSaNO6FmZGTglVdeKbfcxcUF2dnZuoiJiIiI/oedUP/H09MTly9fLrf8yJEjaNiwoU6CIiIiov95MhKqNpMEaZyADB8+HOPGjcPx48chk8lw69YtbNy4EdHR0RgxYoQ+YiQiIjJfJtoHROMmmClTpkCpVOLVV19FQUEBXnnlFcjlckRHR2PMmDH6iJGIiIhMjMYJiEwmw0cffYQPP/wQly9fRl5eHgIDA+Ho6KiP+IiIiMyaqfYBqfJIqDY2NggMDNRlLERERPQ0DsVeJjg4GDLZszu0/PDDD1oFRERERKZP4wSkZcuWavMlJSU4c+YMzp8/j8jISF3FRURERACgZROMyVRAli1bVuHymTNnIi8vT+uAiIiI6G9MtAlGZy+jGzBgANatW6erwxEREZEJq3In1KcdPXoUtra2ujocERERASZbAdE4AXnrrbfU5oUQuH37Nk6ePImYmBidBUZERER8DFfFxcVFbd7CwgL+/v6YPXs2XnvtNZ0FRkRERKZLowREoVBgyJAhCAoKgpubm75iIiIiIhOnUSdUS0tLvPbaa3zrLRERkaGY6LtgNH4KplmzZrh69ao+YiEiIqKnPOkDos0kRRonIHPnzkV0dDSSkpJw+/Zt5Obmqk1EREREL1LpPiCzZ8/GBx98gNdffx0A8MYbb6gNyS6EgEwmg0Kh0H2URERE5kyiVQxtVDoBmTVrFv7973/jxx9/1Gc8RERE9HfmPg6IEGVX0LVrV70FQ0REROZBo8dwn/cWXCIiItI9DkQGoHHjxi9MQh4+fKhVQERERPQ35t4EA5T1A3l6JFQiIiIiTWmUgLz77rvw8PDQVyxERET0FFNtgqn0OCDs/0FERGQERh4J9ZNPPoFMJsP48eO1O9BTKp2APHkKhoiIiMzDTz/9hDVr1qB58+Y6P3alExClUsnmFyIiIkMzUgUkLy8P/fv3xxdffKGXF9BqPBQ7ERERGY6u3gXz9KtTioqKnnveUaNGoUePHggJCdHLdTEBISIikjIdVUB8fHzg4uKimmJjY595yi1btuDUqVPP3UZbGj0FQ0RERNVTZmYmnJ2dVfNyufyZ240bNw779++Hra2t3uJhAkJERCRlOhqIzNnZWS0BeZb09HTcu3cPrVu3Vi1TKBQ4dOgQPv30UxQVFcHS0lKLgMowASEiIpIwQ48D8uqrr+LcuXNqy4YMGYImTZpg8uTJOkk+gGqegKSkpCA4OBiPHj2Cq6ur0eJITEzE+PHjkZ2dbbQY9K1pi/vo/d5l+Plno6Z7EeZMbYdjh+sYOyyTxfttYO/dBu4qyi9/wwEYp/ve/8TPuJQ5OTmhWbNmasscHBxQs2bNcsu1YdROqIMHD4ZMJoNMJoO1tTV8fX0xadIkFBYWGjMsqoCtnQLXLrtg1VLdPwtO5fF+G9h/PICv6vw1LXQvW97VzrhxmTB+xjVg5IHI9MXoFZCwsDAkJCSgpKQE6enpiIyMhEwmw4IFC4wdGv1N+rHaSD9W29hhmA3ebwNzfaqkvPkx4GUJtKi4kx5pj5/xypPCUOwpKSnaH+QpRn8MVy6Xw9PTEz4+PoiIiEBISAj2798PoGzws9jYWPj6+sLOzg4tWrTA9u3bn3msBw8eoF+/fvD29oa9vT2CgoKwefNm1fqsrCx4enpi/vz5qmVpaWmwsbFBcnIyAKCoqAjR0dHw9vaGg4MD2rdvX+7GJyYmol69erC3t8ebb76JBw8e6PCOEJFRlQjgQAEQ5gDwFRREemP0BOTvzp8/r0oIACA2NhYbNmzA6tWr8csvv2DChAkYMGAADh48WOH+hYWFaNOmDXbv3o3z58/j/fffx8CBA3HixAkAQK1atbBu3TrMnDkTJ0+exOPHjzFw4ECMHj0ar776KgBg9OjROHr0KLZs2YKzZ8+iT58+CAsLw6VLlwAAx48fx7BhwzB69GicOXMGwcHBmDt37guvraioqNwgMEQkQal/AnlKINTB2JEQlWETjH4kJSXB0dERpaWlKCoqgoWFheoxn/nz5+PAgQPo0KEDAKBhw4Y4cuQI1qxZg65du5Y7lre3N6Kjo1XzY8aMwb59+7Bt2za0a9cOAPD6669j+PDh6N+/P9q2bQsHBwfVQCs3btxAQkICbty4AS8vLwBAdHQ09u7di4SEBMyfPx/Lly9HWFgYJk2aBABo3Lgx0tLSsHfv3udeZ2xsLGbNmqX9DSMi/fouH2hnC7jrpqc/kdZ09Biu1Bg9AQkODsaqVauQn5+PZcuWwcrKCr1798Yvv/yCgoICdO/eXW374uJitGrVqsJjKRQKzJ8/H9u2bcPNmzdRXFyMoqIi2Nvbq223ePFiNGvWDF999RXS09NVg7GcO3cOCoUCjRs3Vtu+qKgINWvWBABcuHABb775ptr6Dh06vDABmTp1KiZOnKiaz83NhY+Pz3P3ISIDu1sKnCoCZtY0diREJs/oCYiDgwP8/PwAAOvWrUOLFi0QHx+vetRn9+7d8Pb2VtvnWaO3LVq0CMuXL0dcXByCgoLg4OCA8ePHo7i4WG27K1eu4NatW1Aqlbh+/TqCgoIAlL14x9LSEunp6eWec3Z0dNTqOuVy+TPjJiKJ2JsPuFoAL+tv9EciTcn+N2mzvxQZPQH5OwsLC0ybNg0TJ07ExYsXIZfLcePGjQqbWyqSmpqK8PBwDBgwAEBZJ9aLFy8iMDBQtU1xcTEGDBiAvn37wt/fH1FRUTh37hw8PDzQqlUrKBQK3Lt3D126dKnwHAEBATh+/LjasmPHjlXxiqsPW7tSeHnnq+Y96xSgoV8OHj+2RtZd++fsSVXB+20ESgHsLQBecwAspfor23TwM64BNsEYRp8+ffDhhx9izZo1iI6OxoQJE6BUKtG5c2fk5OQgNTUVzs7OiIyMLLdvo0aNsH37dqSlpcHNzQ1Lly7F3bt31RKQjz76CDk5OVixYgUcHR2xZ88eDB06FElJSWjcuDH69++PQYMGYcmSJWjVqhWysrKQnJyM5s2bo0ePHhg7diw6deqExYsXIzw8HPv27Xth84spaNQkG5+sTFXNDx97HgBwYI8Pls1v/azdqIp4v43gVBFwTwGE8cvPEPgZrzwpPIarD5JLQKysrDB69GgsXLgQ165dQ61atRAbG4urV6/C1dUVrVu3xrRp0yrc9+OPP8bVq1cRGhoKe3t7vP/++4iIiEBOTg6AsueY4+Li8OOPP6rGw//yyy/RokULrFq1CiNGjEBCQgLmzp2LDz74ADdv3oS7uztefvll9OzZEwDw8ssv44svvsCMGTMwffp0hISE4OOPP8acOXMMc4OM5Nxpd/ToHG7sMMwG77cRtLUFkusaOwqzwc84yYQQEs2NTFtubi5cXFwQ4jsGVhbsG0KmqfSLUmOHYFashkvub0qTVaoswoFrK5GTk1OpF7xVxZPviab/mg9LedX7JSmKCvHLmml6jbUq+GklIiKSOhMsFUhqIDIiIiIyD6yAEBERSRg7oRIREZHhmehjuGyCISIiIoNjBYSIiEjC2ARDREREhscmGCIiIiLdYAWEiIhIwtgEQ0RERIZnok0wTECIiIikzEQTEPYBISIiIoNjBYSIiEjC2AeEiIiIDI9NMERERES6wQoIERGRhMmEgExUvYyhzb76xASEiIhIytgEQ0RERKQbrIAQERFJGJ+CISIiIsNjEwwRERGRbrACQkREJGFsgiEiIiLDM9EmGCYgREREEmaqFRD2ASEiIiKDYwWEiIhIytgEQ0RERMYg1WYUbbAJhoiIiAyOFRAiIiIpE6Js0mZ/CWICQkREJGF8CoaIiIhIR1gBISIikjI+BUNERESGJlOWTdrsL0VsgiEiIiKDYwWEiIhIytgEQ0RERIZmqk/BMAEhIiKSMhMdB4R9QIiIiMjgWAEhIiKSMDbBkF6UXrsByKyNHYZZsGrYwNghmJ3SebWNHYJ5+eKusSMwG6X5pUAvA53MRDuhsgmGiIiIDI4VECIiIgljEwwREREZHp+CISIiItINVkCIiIgkjE0wREREZHh8CoaIiIhIN1gBISIikjA2wRAREZHhKUXZpM3+EsQEhIiISMrYB4SIiIhIN1gBISIikjAZtOwDorNIdIsJCBERkZRxJFQiIiIi3WACQkREJGFPHsPVZtJEbGws/vGPf8DJyQkeHh6IiIhARkaGzq+LCQgREZGUCR1MGjh48CBGjRqFY8eOYf/+/SgpKcFrr72G/Px83VzP/7APCBEREans3btXbT4xMREeHh5IT0/HK6+8orPzMAEhIiKSMJkQkGnRkfTJvrm5uWrL5XI55HL5C/fPyckBANSoUaPKMVSETTBERERSptTBBMDHxwcuLi6qKTY29sWnVioxfvx4dOrUCc2aNdPpZbECQkREZAYyMzPh7Oysmq9M9WPUqFE4f/48jhw5ovN4mIAQERFJmK6aYJydndUSkBcZPXo0kpKScOjQIdStW7fK538WJiBERERSZuB3wQghMGbMGOzYsQMpKSnw9fXV4uTPxgSEiIhIygw8EuqoUaOwadMm/L//9//g5OSEO3fuAABcXFxgZ2dX9Tiewk6oREREpLJq1Srk5OSgW7duqFOnjmraunWrTs/DCggREZGEVWU006f314Qw0LtjmIAQERFJGV9GR0RERKQbrIAQERFJmExZNmmzvxQxASEiIpIyNsEQERER6QYrIERERFJm4IHIDIUJCBERkYTpaih2qWETDBERERkcKyBERERSZqKdUJmAEBERSZkAoM2jtNLMP5iAEBERSRn7gBARERHpCCsgREREUiagZR8QnUWiU0xAiIiIpMxEO6GyCYaIiIgMjhUQHUhMTMT48eORnZ1t7FD0qtfg+3h7xD3UqFWKq7/a4T8feyPjjL2xwzJJTVvcR+/3LsPPPxs13YswZ2o7HDtcx9hhmax+vX5G53/8jnp1slFUbIVfL3ng863/wB+3XYwdmul67zZwV1F++RsOwDg3w8cjZUoAMi33lyCzq4BkZWVhxIgRqFevHuRyOTw9PREaGorU1FRjhyZpXd94hPdn3MLGpZ4YFdoYV3+1xbxNV+FSs8TYoZkkWzsFrl12waqlzY0dilloHnAHu/YHYPTMXpi0IBSWVkosnLwXtnJ+vvXmPx7AV3X+mha6ly3vamfcuCToyVMw2kxSZHYVkN69e6O4uBjr169Hw4YNcffuXSQnJ+PBgwfGDk3S3nr/PvZuqoHvt9YAAKyYXBftXs1FaL+H2PZpbSNHZ3rSj9VG+jHeV0OZujBUbX7hmi74ZtVmNGrwAOcyPI0UlYlztVSf3/wY8LIEWsiNEw8ZnFlVQLKzs3H48GEsWLAAwcHBqF+/Ptq1a4epU6fijTfeAAAsXboUQUFBcHBwgI+PD0aOHIm8vDy14yQmJqJevXqwt7fHm2++afLJi5W1Eo2aF+DUYSfVMiFkOH3YCYFtCowYGZF+ONiXVT4e5/PL0CBKBHCgAAhzAGTatDWYqCedULWZJMisEhBHR0c4Ojpi586dKCoqqnAbCwsLrFixAr/88gvWr1+PH374AZMmTVKtP378OIYNG4bRo0fjzJkzCA4Oxty5cw11CUbhXEMBSysgO0u9YPbovhXcapUaKSoi/ZDJBEYNOI5zGR64/gf7IhhE6p9AnhIIdTB2JNLEBKT6s7KyQmJiItavXw9XV1d06tQJ06ZNw9mzZ1XbjB8/HsHBwWjQoAH+7//+D3PnzsW2bdtU65cvX46wsDBMmjQJjRs3xtixYxEaGlrR6dQUFRUhNzdXbSIi6RkbeRQN6j7C3M+CjR2K+fguH2hnC7hbvnhbMhlmlYAAZX1Abt26hV27diEsLAwpKSlo3bo1EhMTAQAHDhzAq6++Cm9vbzg5OWHgwIF48OABCgrKmhouXLiA9u3bqx2zQ4cOLzxvbGwsXFxcVJOPj4/Or01fch9aQlEKuD5V7XBzL8WjLLPrRkQmbMygo3i5VSY+mP9P3H/Iv8YN4m4pcKoIeJ33+5lYATEdtra26N69O2JiYpCWlobBgwdjxowZuH79Onr27InmzZvj66+/Rnp6Oj777DMAQHFxsVbnnDp1KnJyclRTZmamLi7FIEpLLHDprD1adX6sWiaTCbTsnIdf0/kYLpkCgTGDjqJz298RPT8Md7KcXrwL6cbefMDVAnjZ1tiRSJdSB5ME8c9XAIGBgdi5cyfS09OhVCqxZMkSWFiU5WZ/b34BgICAABw/flxt2bFjx154DrlcDrm8+nZo++Zzd0THZeLiz/bIOG2PN4dnwdZeie+31DB2aCbJ1q4UXt75qnnPOgVo6JeDx4+tkXWXSZ+ujR18FK92uIqYZa+ioNAabi5lFc/8AhsUl/DXpN4oBbC3AHjNAbBk59NnMdWX0ZnV/6wHDx6gT58+GDp0KJo3bw4nJyecPHkSCxcuRHh4OPz8/FBSUoKVK1eiV69eSE1NxerVq9WOMXbsWHTq1AmLFy9GeHg49u3bh7179xrpigzn4C43uNRUYNCHd+BWqxRXf7HDR/19kX3f2tihmaRGTbLxycq/xqYZPvY8AODAHh8sm9/aWGGZrPCQ3wAAyz7+Tm35wjVdsO9wI2OEZB5OFQH3FEAYk2pzJBNCoqmRHhQVFWHmzJn4/vvvceXKFZSUlMDHxwd9+vTBtGnTYGdnh2XLlmHRokXIzs7GK6+8gv79+2PQoEF49OgRXF1dAQDr1q3DjBkz8ODBA4SEhKBr166YM2eORiOh5ubmwsXFBd0QDisZv8QNwaphA2OHYHYKG9Q0dghmxeqju8YOwWyU5hchpdcq5OTkwNnZWS/nePI9EdJoAqwsq15BL1UU4cClZXqNtSrMKgGREiYghscExPCYgBgWExDDMWgC8tJ47ROQK3GSS0DMshMqERERGZdZ9QEhIiKqdrR9lFaiDR1MQIiIiCRN27E8pJmAsAmGiIiIDI4VECIiIiljEwwREREZnFJAq2YUpTQTEDbBEBERkcGxAkJERCRlQlk2abO/BDEBISIikjL2ASEiIiKDYx8QIiIiIt1gBYSIiEjK2ARDREREBiegZQKis0h0ik0wREREZHCsgBAREUkZm2CIiIjI4JRKAFqM5aGU5jggbIIhIiIig2MFhIiISMrYBENEREQGZ6IJCJtgiIiIyOBYASEiIpIyEx2KnQkIERGRhAmhhNDijbba7KtPTECIiIikTAjtqhjsA0JERERUhhUQIiIiKRNa9gGRaAWECQgREZGUKZWATIt+HBLtA8ImGCIiIjI4VkCIiIikjE0wREREZGhCqYTQoglGqo/hsgmGiIiIDI4VECIiIiljEwwREREZnFIAMtNLQNgEQ0RERAbHCggREZGUCQFAm3FApFkBYQJCREQkYUIpILRoghFMQIiIiEhjQgntKiB8DJeIiIiqic8++wwNGjSAra0t2rdvjxMnTuj0+ExAiIiIJEwohdaTprZu3YqJEydixowZOHXqFFq0aIHQ0FDcu3dPZ9fFBISIiEjKhFL7SUNLly7F8OHDMWTIEAQGBmL16tWwt7fHunXrdHZZ7ANiJE86BZWiRKvxZUgDyiJjR2B2SksLjR2CecnnZ9xQSguKARimg6e23xOlKAEA5Obmqi2Xy+WQy+Xlti8uLkZ6ejqmTp2qWmZhYYGQkBAcPXq06oE8hQmIkTx+/BgAcAR7jByJGblm7ADMEO+5YR00dgDm5/Hjx3BxcdHLsW1sbODp6Ykjd7T/nnB0dISPj4/ashkzZmDmzJnltr1//z4UCgVq166ttrx27dr47bfftI7lCSYgRuLl5YXMzEw4OTlBJpMZO5xKy83NhY+PDzIzM+Hs7GzscEwe77fh8Z4bVnW930IIPH78GF5eXno7h62tLa5du4bi4mKtjyWEKPddU1H1w5CYgBiJhYUF6tata+wwqszZ2bla/bKo7ni/DY/33LCq4/3WV+Xj72xtbWFra6v38/ydu7s7LC0tcffuXbXld+/ehaenp87Ow06oREREpGJjY4M2bdogOTlZtUypVCI5ORkdOnTQ2XlYASEiIiI1EydORGRkJNq2bYt27dohLi4O+fn5GDJkiM7OwQSENCKXyzFjxgyjtx2aC95vw+M9Nyzeb2nq27cvsrKyMH36dNy5cwctW7bE3r17y3VM1YZMSHWQeCIiIjJZ7ANCREREBscEhIiIiAyOCQgREREZHBMQIjILKSkpkMlkyM7ONmociYmJcHV1NWoM1RXvnWlhAmJGjh49CktLS/To0cPYoZiswYMHIyIiotxyqXz5VWeDBw+GTCaDTCaDtbU1fH19MWnSJBQW8n0zUpSVlYURI0agXr16kMvl8PT0RGhoKFJTU40dGkkEH8M1I/Hx8RgzZgzi4+Nx69YtvQ4hDJS90MjGxkav5yDzEhYWhoSEBJSUlCA9PR2RkZGQyWRYsGCBsUOjp/Tu3RvFxcVYv349GjZsiLt37yI5ORkPHjwwdmgkEayAmIm8vDxs3boVI0aMQI8ePZCYmKha9+Sv8+TkZLRt2xb29vbo2LEjMjIy1I4xd+5ceHh4wMnJCVFRUZgyZQpatmypWv/kr/958+bBy8sL/v7+mD17Npo1a1YunpYtWyImJkZflytpDx48QL9+/eDt7Q17e3sEBQVh8+bNatt069YNo0ePxujRo+Hi4gJ3d3fExMSovXmzQYMGmDNnDvr16wcHBwd4e3vjs88+U60fOnQoevbsqXbckpISeHh4ID4+Xr8XqSdP/pL28fFBREQEQkJCsH//fgBlIzXGxsbC19cXdnZ2aNGiBbZv3/7MY73o55CVlQVPT0/Mnz9ftSwtLQ02NjaqESKLiooQHR0Nb29vODg4oH379khJSVE7T2JiIurVqwd7e3u8+eabZvEFnJ2djcOHD2PBggUIDg5G/fr10a5dO0ydOhVvvPEGgLLXvQcFBcHBwQE+Pj4YOXIk8vLy1I5jjvfOrAgyC/Hx8aJt27ZCCCG+/fZb8dJLLwmlUimEEOLHH38UAET79u1FSkqK+OWXX0SXLl1Ex44dVfv/97//Fba2tmLdunUiIyNDzJo1Szg7O4sWLVqotomMjBSOjo5i4MCB4vz58+L8+fMiMzNTWFhYiBMnTqi2O3XqlJDJZOLKlSuGuXgDioyMFOHh4eWWP7nHjx49En/88YdYtGiROH36tLhy5YpYsWKFsLS0FMePH1dt37VrV+Ho6CjGjRsnfvvtN/Hf//5X2Nvbi88//1y1Tf369YWTk5OIjY0VGRkZquN8//33QgghUlNThaWlpbh165Zqn2+++UY4ODiIx48f6+8m6MnT9/bcuXPC09NTtG/fXgghxNy5c0WTJk3E3r17xZUrV0RCQoKQy+UiJSVFCKH+MxBCVOrnsHv3bmFtbS1++uknkZubKxo2bCgmTJigWh8VFSU6duwoDh06JC5fviwWLVok5HK5uHjxohBCiGPHjgkLCwuxYMECkZGRIZYvXy5cXV2Fi4uLfm+WkZWUlAhHR0cxfvx4UVhYWOE2y5YtEz/88IO4du2aSE5OFv7+/mLEiBGq9eZ678wJExAz0bFjRxEXFyeEKPvl4O7uLn788UchxF+/mA8cOKDafvfu3QKA+PPPP4UQQrRv316MGjVK7ZidOnUql4DUrl1bFBUVqW33z3/+U+0Xy5gxY0S3bt10eXmSERkZKSwtLYWDg4PaZGtrq/bl97QePXqIDz74QDXftWtXERAQoEoShRBi8uTJIiAgQDVfv359ERYWpnacvn37in/+85+q+cDAQLFgwQLVfK9evcTgwYO1vUyj+Pu9lcvlAoCwsLAQ27dvF4WFhcLe3l6kpaWp7TNs2DDRr18/IUT5BKQiT/8chBBi5MiRonHjxuK9994TQUFBqi/U33//XVhaWoqbN2+qbf/qq6+KqVOnCiGE6Nevn3j99dfV1vft29csvkS3b98u3NzchK2trejYsaOYOnWq+Pnnn5+5/VdffSVq1qypmjfne2cu2ARjBjIyMnDixAn069cPAGBlZYW+ffuWK8M3b95c9e86deoAAO7du6c6Rrt27dS2f3oeAIKCgsr1+xg+fDg2b96MwsJCFBcXY9OmTRg6dKj2FyZRwcHBOHPmjNq0du1a1XqFQoE5c+YgKCgINWrUgKOjI/bt24cbN26oHefll19We312hw4dcOnSJSgUCrVlf9ehQwdcuHBBNR8VFYWEhAQAZW+y/O6776r1vX9yb48fP47IyEgMGTIEvXv3xuXLl1FQUIDu3bvD0dFRNW3YsAFXrlyp8FiV/TksXrwYpaWl+Oqrr7Bx40bVkOHnzp2DQqFA48aN1c558OBB1TkvXLiA9u3bqx1Ply/zkrLevXvj1q1b2LVrF8LCwpCSkoLWrVurmn8PHDiAV199Fd7e3nBycsLAgQPx4MEDFBQUADDve2cu2AnVDMTHx6O0tFSt06kQAnK5HJ9++qlqmbW1terfT774lEqlRudycHAot6xXr16Qy+XYsWMHbGxsUFJSgrffflvTy6g2HBwc4Ofnp7bsjz/+UP170aJFWL58OeLi4lRt4OPHj0dxcbHOYxk0aBCmTJmCo0ePIi0tDb6+vujSpYvOz2Mof7+369atQ4sWLRAfH6/qZ7R79254e3ur7fOsd4xU9udw5coV3Lp1C0qlEtevX0dQUBCAsn5VlpaWSE9Ph6Wlpdo+jo6OOrne6s7W1hbdu3dH9+7dERMTg6ioKMyYMQPdunVDz549MWLECMybNw81atTAkSNHMGzYMBQXF8Pe3t7YoZMBMAExcaWlpdiwYQOWLFmC1157TW1dREQENm/ejCZNmrzwOP7+/vjpp58waNAg1bKffvqpUjFYWVkhMjISCQkJsLGxwbvvvgs7OzvNLsSEpKamIjw8HAMGDABQluRdvHgRgYGBatsdP35cbf7YsWNo1KiR2pfdsWPHym0TEBCgmq9ZsyYiIiKQkJCAo0eP6vRNlsZmYWGBadOmYeLEibh48SLkcjlu3LiBrl27Vmr/yvwciouLMWDAAPTt2xf+/v6IiorCuXPn4OHhgVatWkGhUODevXvPTOoCAgIq/Dmaq8DAQOzcuRPp6elQKpVYsmQJLCzKCvHbtm1T25b3zvQxATFxSUlJePToEYYNGwYXFxe1db1790Z8fDwWLVr0wuOMGTMGw4cPR9u2bdGxY0ds3boVZ8+eRcOGDSsVR1RUlOqL0dzHAWjUqBG2b9+OtLQ0uLm5YenSpbh79265BOTGjRuYOHEi/vWvf+HUqVNYuXIllixZorZNamoqFi5ciIiICOzfvx9fffUVdu/erbZNVFQUevbsCYVCgcjISL1fnyH16dMHH374IdasWYPo6GhMmDABSqUSnTt3Rk5ODlJTU+Hs7FzhdVfm5/DRRx8hJycHK1asgKOjI/bs2YOhQ4ciKSkJjRs3Rv/+/TFo0CAsWbIErVq1QlZWFpKTk9G8eXP06NEDY8eORadOnbB48WKEh4dj37592Lt3ryFvkVE8ePAAffr0wdChQ9G8eXM4OTnh5MmTWLhwIcLDw+Hn54eSkhKsXLkSvXr1QmpqKlavXq12DHO9d2bF2J1QSL969uxZriPXE8ePHxcAxPLly8t1zjt9+rQAIK5du6ZaNnv2bOHu7i4cHR3F0KFDxdixY8XLL7+sWv+sJ0Ce6NKli2jatKm2lyRplXkK5sGDByI8PFw4OjoKDw8P8fHHH4tBgwap7de1a1cxcuRI8e9//1s4OzsLNzc3MW3aNLVOqfXr1xezZs0Sffr0Efb29sLT01MsX7683LmVSqWoX7/+Mz8H1cWz7m1sbKyoVauWyMvLE3FxccLf319YW1uLWrVqidDQUHHw4EEhRPlOqC/6Ofz444/CyspKHD58WHWua9euCWdnZ/Gf//xHCCFEcXGxmD59umjQoIGwtrYWderUEW+++aY4e/asap/4+HhRt25dYWdnJ3r16iUWL15s8h0pCwsLxZQpU0Tr1q2Fi4uLsLe3F/7+/uLjjz8WBQUFQgghli5dKurUqSPs7OxEaGio2LBhQ7nfQ+Z478yJTIi/DSxApIHu3bvD09MTX3755Qu3FUKgUaNGGDlyJCZOnGiA6Kq3bt26oWXLloiLi3vmNg0aNMD48eMxfvz45x4rLy8P3t7eSEhIwFtvvaXbQImIqohNMFQpBQUFWL16NUJDQ2FpaYnNmzfjwIEDqkGgnicrKwtbtmzBnTt3TKoPgtQplUrcv38fS5Ysgaurq2oAKCIiKWACQpUik8mwZ88ezJs3D4WFhfD398fXX3+NkJCQF+7r4eEBd3d3fP7553BzczNAtASU9SHx9fVF3bp1kZiYCCsr/ncnIulgEwwREREZHAciIyIiIoNjAkJEREQGxwSEiIiIDI4JCBERERkcExAiMzZ48GBERESo5rt16/bCcUX0ISUlBTKZDNnZ2c/cRiaTYefOnZU+5syZM9GyZUut4rp+/TpkMhnOnDmj1XGIqDwmIEQSM3jwYMhkMshkMtjY2MDPzw+zZ89GaWmp3s/9zTffYM6cOZXatjJJAxHRs3BgACIJCgsLQ0JCAoqKirBnzx6MGjUK1tbWmDp1arlti4uLYWNjo5Pz1qhRQyfHISJ6EVZAiCRILpfD09MT9evXx4gRIxASEoJdu3YB+KvZZN68efDy8oK/vz8AIDMzE++88w5cXV1Ro0YNhIeH4/r166pjKhQKTJw4Ea6urqhZsyYmTZqEp4cBeroJpqioCJMnT4aPjw/kcjn8/PwQHx+P69evIzg4GADg5uYGmUyGwYMHAygbgTU2Nha+vr6ws7NDixYtsH37drXz7NmzB40bN4adnR2Cg4PV4qysyZMno3HjxrC3t0fDhg0RExODkpKSctutWbMGPj4+sLe3xzvvvIOcnBy19WvXrkVAQABsbW3RpEkT/Oc//9E4FiLSHBMQomrAzs4OxcXFqvnk5GRkZGRg//79SEpKQklJCUJDQ+Hk5ITDhw8jNTUVjo6OCAsLU+23ZMkSJCYmYt26dThy5AgePnyIHTt2PPe8gwYNwubNm7FixQpcuHABa9asgaOjI3x8fPD1118DADIyMnD79m0sX74cABAbG4sNGzZg9erV+OWXXzBhwgQMGDAABw8eBFCWKL311lvo1asXzpw5g6ioKEyZMkXje+Lk5ITExET8+uuvWL58Ob744gssW7ZMbZvLly9j27Zt+Pbbb7F3716cPn0aI0eOVK3fuHEjpk+fjnnz5uHChQuYP38+YmJisH79eo3jISINGfNNeERU3t/f+qpUKsX+/fuFXC4X0dHRqvW1a9cWRUVFqn2+/PJL4e/vr/a23KKiImFnZyf27dsnhBCiTp06YuHChar1JSUlom7duuXewjtu3DghhBAZGRkCgNi/f3+FcT79dlkhyt6Cam9vL9LS0tS2HTZsmOjXr58QQoipU6eKwMBAtfWTJ08ud6ynARA7dux45vpFixaJNm3aqOZnzJghLC0txR9//KFa9t133wkLCwtx+/ZtIYQQL730kti0aZPacebMmSM6dOgghCh7+y0Acfr06Weel4iqhn1AiCQoKSkJjo6OKCkpgVKpxHvvvYeZM2eq1gcFBan1+/j5559x+fJlODk5qR2nsLAQV65cQU5ODm7fvo327dur1llZWaFt27blmmGeOHPmDCwtLdG1a9dKx3358mUUFBSge/fuasuLi4vRqlUrAMCFCxfU4gCADh06VPocT2zduhUrVqzAlStXkJeXh9LSUjg7O6ttU69ePXh7e6udR6lUIiMjA05OTrhy5QqGDRuG4cOHq7YpLS2Fi4uLxvEQkWaYgBBJUHBwMFatWgUbGxt4eXmVe5Gcg4OD2nxeXh7atGmDjRs3ljtWrVq1qhSDnZ2dxvvk5eUBAHbv3q32xQ+U9WvRlaNHj6J///6YNWsWQkND4eLigi1btmDJkiUax/rFF1+US4gsLS11FisRVYwJCJEEOTg4wM/Pr9Lbt27dGlu3boWHh0e5KsATderUwfHjx/HKK68AKPtLPz09Ha1bt65w+6CgICiVShw8eLDCtx4/qcAoFArVssDAQMjlcty4ceOZlZOAgABVh9onjh079uKL/Ju0tDTUr18fH330kWrZ77//Xm67Gzdu4NatW/Dy8lKdx8LCAv7+/qhduza8vLxw9epV9O/fX6PzE5H22AmVyAT0798f7u7uCA8Px+HDh3Ht2jWkpKRg7Nix+OOPPwAA48aNwyeffIKdO3fit99+w8iRI587hkeDBg0QGRmJoUOHYufOnapjbtu2DQBQv359yGQyJCUlISsrC3l5eXByckJ0dDQmTJiA9evX48qVKzh16hRWrlyp6tj573//G5cuXcKHH36IjIwMbNq0CYmJiRpdb6NGjXDjxg1s2bIFV65cwYoVKyrsUGtra4vIyEj8/PPPOHz4MMaOHYt33nkHnp6eAIBZs2YhNjYWK1aswMWLF3Hu3DkkJCRg6dKlGsVDRJpjAkJkAuzt7XHo0CHUq1cPb731FgICAjBs2DAUFhaqKiIffPABBg4ciMjISHTo0AFOTk548803n3vcVatW4e2338bIkSPRpEkTDB8+HPn5+QAAb29vzJo1C1OmTEHt2rUxevRoAMCcOXMQExOD2NhYBAQEICwsDLt374avry+Asn4ZX3/9NXbu3IkWLVpg9erVmD9/vkbX+8Ybb2DChAkYPXo0WrZsibS0NMTExJTbzs/PD2+99RZef/11vPbaa2jevLnaY7ZRUVFYu3YtEhISEBQUhK5duyIxMVEVKxHpj0w8qwcaERERkZ6wAkJEREQGxwSEiIiIDI4JCBERERkcExAiIiIyOCYgREREZHBMQIiIiMjgmIAQERGRwTEBISIiIoNjAkJEREQGxwSEiIiIDI4JCBERERkcExAiIiIyuP8P+GipYuBo0fUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(y2_test, y_pred, target_names = ['Angry', 'Happy', 'Relaxed', 'Sad']))\n",
    "cm_display_1d.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0531d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
